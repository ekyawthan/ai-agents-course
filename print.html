<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>AI Agents: Zero to Hero</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/custom-6b8ad661.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-49812cde.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-7241d7cf.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>â†</kbd> or <kbd>â†’</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">AI Agents: Zero to Hero</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/ekyawthan/ai-agents-course" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="ai-agents-zero-to-hero"><a class="header" href="#ai-agents-zero-to-hero">AI Agents: Zero to Hero</a></h1>
<p>Welcome to the complete course on building AI agents from the ground up.</p>
<h2 id="course-overview"><a class="header" href="#course-overview">Course Overview</a></h2>
<p>This comprehensive course takes you from foundational concepts to cutting-edge implementations in AI agent development. Whether youâ€™re a beginner or an experienced developer, youâ€™ll gain practical skills to build, deploy, and scale intelligent agents.</p>
<h2 id="what-youll-learn"><a class="header" href="#what-youll-learn">What Youâ€™ll Learn</a></h2>
<ul>
<li>Core concepts of AI agents and their architecture</li>
<li>Building agents with reasoning and tool-use capabilities</li>
<li>Advanced patterns including planning, memory, and multi-agent systems</li>
<li>Production deployment, testing, and monitoring</li>
<li>Specialized agent types for coding, research, and automation</li>
<li>Enterprise-scale architecture and security considerations</li>
<li>Latest research and emerging paradigms</li>
</ul>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<ul>
<li>Basic Python programming</li>
<li>Understanding of APIs and HTTP</li>
<li>Familiarity with command line</li>
<li>Basic ML/AI concepts (helpful but not required)</li>
</ul>
<h2 id="learning-path"><a class="header" href="#learning-path">Learning Path</a></h2>
<ul>
<li><strong>Beginner</strong>: Chapters 1-2 (2-3 weeks)</li>
<li><strong>Intermediate</strong>: Chapters 3-5 (4-6 weeks)</li>
<li><strong>Advanced</strong>: Chapters 6-9 (6-8 weeks)</li>
<li><strong>Expert</strong>: Module 10 + Research (ongoing)</li>
</ul>
<h2 id="estimated-time"><a class="header" href="#estimated-time">Estimated Time</a></h2>
<p>Total: 12-16 weeks for complete mastery with hands-on projects throughout.</p>
<hr>
<p>Letâ€™s begin your journey to mastering AI agents!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h1>
<h2 id="required-knowledge"><a class="header" href="#required-knowledge">Required Knowledge</a></h2>
<h3 id="programming-fundamentals"><a class="header" href="#programming-fundamentals">Programming Fundamentals</a></h3>
<ul>
<li><strong>Python proficiency</strong>: Functions, classes, decorators, async/await</li>
<li><strong>Data structures</strong>: Lists, dicts, sets, queues</li>
<li><strong>Error handling</strong>: Try/except, custom exceptions</li>
<li><strong>File I/O</strong>: Reading/writing files</li>
</ul>
<h3 id="basic-concepts"><a class="header" href="#basic-concepts">Basic Concepts</a></h3>
<ul>
<li><strong>APIs</strong>: REST APIs, HTTP methods, JSON</li>
<li><strong>Command line</strong>: Basic bash/terminal commands</li>
<li><strong>Git</strong>: Version control basics</li>
<li><strong>Environment variables</strong>: Configuration management</li>
</ul>
<h3 id="recommended-not-required"><a class="header" href="#recommended-not-required">Recommended (Not Required)</a></h3>
<ul>
<li>Machine learning basics</li>
<li>Natural language processing concepts</li>
<li>Docker/containerization</li>
<li>Cloud platforms (AWS, Azure, GCP)</li>
</ul>
<h2 id="technical-requirements"><a class="header" href="#technical-requirements">Technical Requirements</a></h2>
<h3 id="software"><a class="header" href="#software">Software</a></h3>
<ul>
<li><strong>Python 3.9+</strong>: <a href="https://www.python.org/downloads/">Download</a></li>
<li><strong>pip</strong>: Package manager (comes with Python)</li>
<li><strong>Git</strong>: <a href="https://git-scm.com/downloads">Download</a></li>
<li><strong>Code editor</strong>: VS Code, PyCharm, or similar</li>
<li><strong>Terminal</strong>: Command line access</li>
</ul>
<h3 id="accounts"><a class="header" href="#accounts">Accounts</a></h3>
<ul>
<li><strong>OpenAI API key</strong>: <a href="https://platform.openai.com/api-keys">Get key</a>
<ul>
<li>Or Anthropic, AWS Bedrock, etc.</li>
</ul>
</li>
<li><strong>GitHub account</strong>: For version control</li>
<li><strong>Optional</strong>: Cloud provider account (AWS, GCP, Azure)</li>
</ul>
<h3 id="hardware"><a class="header" href="#hardware">Hardware</a></h3>
<ul>
<li><strong>Minimum</strong>: 8GB RAM, modern CPU</li>
<li><strong>Recommended</strong>: 16GB RAM, GPU for local models</li>
<li><strong>Internet</strong>: Stable connection for API calls</li>
</ul>
<h2 id="setup-instructions"><a class="header" href="#setup-instructions">Setup Instructions</a></h2>
<h3 id="1-install-python"><a class="header" href="#1-install-python">1. Install Python</a></h3>
<pre><code class="language-bash"># Check Python version
python --version  # Should be 3.9+

# Create virtual environment
python -m venv venv

# Activate (macOS/Linux)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate
</code></pre>
<h3 id="2-install-core-libraries"><a class="header" href="#2-install-core-libraries">2. Install Core Libraries</a></h3>
<pre><code class="language-bash">pip install openai langchain chromadb fastapi uvicorn pytest
</code></pre>
<h3 id="3-configure-api-keys"><a class="header" href="#3-configure-api-keys">3. Configure API Keys</a></h3>
<pre><code class="language-bash"># Create .env file
echo "OPENAI_API_KEY=your-key-here" &gt; .env

# Or export directly
export OPENAI_API_KEY="your-key-here"
</code></pre>
<h3 id="4-verify-setup"><a class="header" href="#4-verify-setup">4. Verify Setup</a></h3>
<pre><code class="language-python"># test_setup.py
from openai import OpenAI

client = OpenAI()
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Hello!"}]
)
print("âœ“ Setup successful!")
print(response.choices[0].message.content)
</code></pre>
<h2 id="time-commitment"><a class="header" href="#time-commitment">Time Commitment</a></h2>
<ul>
<li><strong>Total course</strong>: 40-60 hours</li>
<li><strong>Per chapter</strong>: 4-6 hours</li>
<li><strong>Capstone project</strong>: 10-15 hours</li>
</ul>
<p><strong>Recommended pace</strong>: 2-3 chapters per week</p>
<h2 id="learning-path-1"><a class="header" href="#learning-path-1">Learning Path</a></h2>
<h3 id="beginner-track-start-here"><a class="header" href="#beginner-track-start-here">Beginner Track (Start Here)</a></h3>
<ol>
<li>Module 1: Foundations</li>
<li>Module 2: Building Your First Agent</li>
<li>Module 4: Agent Tools &amp; Capabilities</li>
<li>Module 5: Production-Ready Agents</li>
</ol>
<h3 id="intermediate-track"><a class="header" href="#intermediate-track">Intermediate Track</a></h3>
<ol start="5">
<li>Module 3: Advanced Agent Patterns</li>
<li>Module 6: Specialized Agent Types</li>
<li>Module 7: Advanced Topics</li>
</ol>
<h3 id="advanced-track"><a class="header" href="#advanced-track">Advanced Track</a></h3>
<ol start="8">
<li>Module 8: Enterprise &amp; Scale</li>
<li>Module 9: Cutting-Edge Research</li>
<li>Module 10: Capstone Project</li>
</ol>
<h2 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h2>
<ul>
<li><strong>GitHub Issues</strong>: Report errors or ask questions</li>
<li><strong>Discussions</strong>: Share projects and get feedback</li>
<li><strong>Community</strong>: Join Discord/Slack communities (see Resources)</li>
</ul>
<h2 id="ready-to-start"><a class="header" href="#ready-to-start">Ready to Start?</a></h2>
<p>If you meet the prerequisites, youâ€™re ready to begin! Start with the <a href="#ai-agents-zero-to-hero">Introduction</a> and then dive into <a href="#what-are-ai-agents">Module 1</a>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="about-this-course"><a class="header" href="#about-this-course">About This Course</a></h1>
<h2 id="author"><a class="header" href="#author">Author</a></h2>
<p><strong>Kyaw Mong</strong> is a software engineer and AI practitioner with extensive experience building production AI systems. This course distills years of hands-on experience into a comprehensive learning path for aspiring agent developers.</p>
<h2 id="course-philosophy"><a class="header" href="#course-philosophy">Course Philosophy</a></h2>
<p>This course is built on three principles:</p>
<p><strong>1. Learn by Building</strong>
Every concept is accompanied by working code examples. Youâ€™ll build real agents, not just read about them.</p>
<p><strong>2. Production-First</strong>
We donâ€™t just teach toy examples. Youâ€™ll learn reliability, testing, monitoring, and deploymentâ€”everything needed for production systems.</p>
<p><strong>3. Comprehensive Coverage</strong>
From foundations to frontier research, this course covers the full spectrum of agent development in 21,000+ lines of detailed content.</p>
<h2 id="what-makes-this-course-different"><a class="header" href="#what-makes-this-course-different">What Makes This Course Different</a></h2>
<ul>
<li><strong>Complete working code</strong>: Every example runs and can be deployed</li>
<li><strong>Real-world focus</strong>: Patterns used in production systems</li>
<li><strong>Cutting-edge content</strong>: Latest research and techniques</li>
<li><strong>Hands-on capstone</strong>: Build a complete autonomous agent</li>
<li><strong>Free and open source</strong>: Available to everyone</li>
</ul>
<h2 id="course-structure"><a class="header" href="#course-structure">Course Structure</a></h2>
<p>The course follows a carefully designed progression:</p>
<p><strong>Foundations (Chapters 1-2)</strong>: Core concepts and first agent
<strong>Intermediate (Chapters 3-5)</strong>: Advanced patterns and production readiness<br><strong>Advanced (Chapters 6-8)</strong>: Specialized agents and enterprise scale
<strong>Expert (Chapters 9-10)</strong>: Research frontiers and capstone project</p>
<h2 id="acknowledgments"><a class="header" href="#acknowledgments">Acknowledgments</a></h2>
<p>This course builds on the incredible work of the AI research community. Special thanks to:</p>
<ul>
<li>OpenAI, Anthropic, and other AI labs for advancing the field</li>
<li>LangChain, AutoGPT, and framework creators</li>
<li>The open source community</li>
<li>Researchers publishing papers and sharing knowledge</li>
</ul>
<h2 id="version-history"><a class="header" href="#version-history">Version History</a></h2>
<p><strong>v1.0</strong> (February 2026)</p>
<ul>
<li>Initial release</li>
<li>10 complete chapters</li>
<li>Autonomous Software Engineering Agent capstone</li>
<li>21,000+ lines of content</li>
</ul>
<h2 id="contact--feedback"><a class="header" href="#contact--feedback">Contact &amp; Feedback</a></h2>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/ekyawthan/ai-agents-course">ekyawthan/ai-agents-course</a></li>
<li><strong>Issues</strong>: Report errors or suggest improvements</li>
<li><strong>Discussions</strong>: Share your projects and ask questions</li>
</ul>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>This course is released under the MIT License. Youâ€™re free to use, modify, and share the content with attribution.</p>
<hr>
<p>Ready to start learning? Head to <a href="#prerequisites-1">Prerequisites</a> to get set up!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="what-are-ai-agents"><a class="header" href="#what-are-ai-agents">What Are AI Agents?</a></h1>
<h2 id="module-1-learning-objectives"><a class="header" href="#module-1-learning-objectives">Module 1: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Define what AI agents are and how they differ from traditional software</li>
<li>âœ“ Identify different types of agents and their use cases</li>
<li>âœ“ Understand the perception-reasoning-action loop</li>
<li>âœ“ Explain how LLMs enable agentic behavior</li>
<li>âœ“ Recognize key components of agent architecture</li>
</ul>
<hr>
<h2 id="definition-and-core-concepts"><a class="header" href="#definition-and-core-concepts">Definition and Core Concepts</a></h2>
<p>An <strong>AI agent</strong> is an autonomous system that perceives its environment, reasons about it, and takes actions to achieve specific goals. Unlike simple chatbots that respond to queries, agents can:</p>
<ul>
<li>Break down complex tasks into steps</li>
<li>Use tools and external resources</li>
<li>Remember context across interactions</li>
<li>Adapt their approach based on feedback</li>
<li>Work independently toward objectives</li>
</ul>
<p>Think of an agent as a digital assistant that doesnâ€™t just answer questionsâ€”it gets things done.</p>
<h2 id="agent-vs-chatbot-vs-assistant"><a class="header" href="#agent-vs-chatbot-vs-assistant">Agent vs. Chatbot vs. Assistant</a></h2>
<h3 id="chatbot"><a class="header" href="#chatbot">Chatbot</a></h3>
<ul>
<li>Responds to direct queries</li>
<li>Stateless or minimal memory</li>
<li>No tool use</li>
<li>Example: Simple FAQ bot</li>
</ul>
<h3 id="assistant"><a class="header" href="#assistant">Assistant</a></h3>
<ul>
<li>Helps with tasks through conversation</li>
<li>Maintains conversation context</li>
<li>May access some information</li>
<li>Example: Basic voice assistants</li>
</ul>
<h3 id="agent"><a class="header" href="#agent">Agent</a></h3>
<ul>
<li>Autonomous task execution</li>
<li>Multi-step reasoning and planning</li>
<li>Uses multiple tools and APIs</li>
<li>Adapts strategy based on results</li>
<li>Example: Research agent that searches, analyzes, and synthesizes information</li>
</ul>
<h2 id="autonomy-reasoning-and-tool-use"><a class="header" href="#autonomy-reasoning-and-tool-use">Autonomy, Reasoning, and Tool Use</a></h2>
<h3 id="autonomy"><a class="header" href="#autonomy">Autonomy</a></h3>
<p>Agents operate with varying degrees of independence:</p>
<ul>
<li><strong>Supervised</strong>: Requires approval for each action</li>
<li><strong>Semi-autonomous</strong>: Asks for guidance on critical decisions</li>
<li><strong>Fully autonomous</strong>: Executes complete workflows independently</li>
</ul>
<h3 id="reasoning"><a class="header" href="#reasoning">Reasoning</a></h3>
<p>Agents think through problems using:</p>
<ul>
<li><strong>Chain-of-thought</strong>: Step-by-step logical reasoning</li>
<li><strong>Planning</strong>: Breaking goals into sub-tasks</li>
<li><strong>Reflection</strong>: Evaluating their own outputs</li>
<li><strong>Error recovery</strong>: Adapting when things go wrong</li>
</ul>
<h3 id="tool-use"><a class="header" href="#tool-use">Tool Use</a></h3>
<p>Modern agents extend their capabilities through tools:</p>
<ul>
<li>Web search and browsing</li>
<li>Code execution</li>
<li>Database queries</li>
<li>API calls</li>
<li>File operations</li>
<li>Calculator and data analysis</li>
</ul>
<h2 id="real-world-applications-and-use-cases"><a class="header" href="#real-world-applications-and-use-cases">Real-World Applications and Use Cases</a></h2>
<h3 id="software-development"><a class="header" href="#software-development">Software Development</a></h3>
<ul>
<li>Code generation and refactoring</li>
<li>Bug detection and fixing</li>
<li>Documentation writing</li>
<li>Test generation</li>
</ul>
<h3 id="research-and-analysis"><a class="header" href="#research-and-analysis">Research and Analysis</a></h3>
<ul>
<li>Literature reviews</li>
<li>Market research</li>
<li>Competitive analysis</li>
<li>Data synthesis</li>
</ul>
<h3 id="business-automation"><a class="header" href="#business-automation">Business Automation</a></h3>
<ul>
<li>Customer support</li>
<li>Data entry and processing</li>
<li>Report generation</li>
<li>Workflow orchestration</li>
</ul>
<h3 id="personal-productivity"><a class="header" href="#personal-productivity">Personal Productivity</a></h3>
<ul>
<li>Email management</li>
<li>Calendar scheduling</li>
<li>Travel planning</li>
<li>Information gathering</li>
</ul>
<h3 id="creative-work"><a class="header" href="#creative-work">Creative Work</a></h3>
<ul>
<li>Content creation</li>
<li>Design assistance</li>
<li>Brainstorming</li>
<li>Editing and refinement</li>
</ul>
<h2 id="key-characteristics-of-effective-agents"><a class="header" href="#key-characteristics-of-effective-agents">Key Characteristics of Effective Agents</a></h2>
<ol>
<li><strong>Goal-oriented</strong>: Clear objectives drive behavior</li>
<li><strong>Adaptive</strong>: Adjust approach based on feedback</li>
<li><strong>Transparent</strong>: Explain reasoning and actions</li>
<li><strong>Reliable</strong>: Handle errors gracefully</li>
<li><strong>Efficient</strong>: Minimize unnecessary steps</li>
<li><strong>Safe</strong>: Respect boundaries and constraints</li>
</ol>
<h2 id="the-agent-loop"><a class="header" href="#the-agent-loop">The Agent Loop</a></h2>
<p>At their core, agents follow a continuous cycle:</p>
<pre><code class="language-mermaid">graph LR
    A[Perceive] --&gt; B[Reason]
    B --&gt; C[Act]
    C --&gt; D[Observe]
    D --&gt; A
    style A fill:#dbeafe
    style B fill:#fef3c7
    style C fill:#d1fae5
    style D fill:#e0e7ff
</code></pre>
<p><strong>The Perception-Reasoning-Action Loop:</strong></p>
<ol>
<li><strong>Perceive</strong> â†’ Observe the current state</li>
<li><strong>Reason</strong> â†’ Decide what to do next</li>
<li><strong>Act</strong> â†’ Execute the chosen action</li>
<li><strong>Observe</strong> â†’ See the results</li>
<li><strong>Repeat</strong> â†’ Continue until goal is achieved</li>
</ol>
<p>This loop enables agents to navigate complex, multi-step tasks that would be difficult to hardcode.</p>
<h2 id="what-makes-agents-possible-now"><a class="header" href="#what-makes-agents-possible-now">What Makes Agents Possible Now?</a></h2>
<p>Recent advances have made practical agents feasible:</p>
<ul>
<li><strong>Large Language Models</strong>: Provide reasoning and language understanding</li>
<li><strong>Function Calling</strong>: LLMs can reliably invoke tools with structured parameters</li>
<li><strong>Context Windows</strong>: Models can maintain longer conversations and more context</li>
<li><strong>Improved Reliability</strong>: Better instruction following and fewer hallucinations</li>
<li><strong>Ecosystem</strong>: Frameworks and tools for building agents quickly</li>
</ul>
<blockquote>
<p><strong>ğŸ’¡ Key Insight</strong></p>
<p>The combination of LLMs with tool-calling capabilities is what makes modern AI agents fundamentally different from previous approaches. LLMs provide the â€œreasoning engineâ€ while tools provide the â€œhandsâ€ to interact with the world.</p>
</blockquote>
<h2 id="looking-ahead"><a class="header" href="#looking-ahead">Looking Ahead</a></h2>
<p>As you progress through this course, youâ€™ll learn to build agents that combine these concepts into practical, production-ready systems. Weâ€™ll start simple and gradually add sophistication.</p>
<hr>
<blockquote>
<p><strong>âœ… Key Takeaways</strong></p>
<ul>
<li>AI agents are autonomous systems that perceive, reason, and act to achieve goals</li>
<li>Agents differ from chatbots by using tools, planning, and maintaining memory</li>
<li>The perception-reasoning-action loop is the core pattern</li>
<li>Modern LLMs enable practical agent development through reasoning and tool use</li>
<li>Agents can be simple (single-task) or complex (multi-agent systems)</li>
</ul>
</blockquote>
<p>In the next section, weâ€™ll explore agent architecture and how these components fit together.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="agent-architecture-basics"><a class="header" href="#agent-architecture-basics">Agent Architecture Basics</a></h1>
<h2 id="the-perception-reasoning-action-loop"><a class="header" href="#the-perception-reasoning-action-loop">The Perception-Reasoning-Action Loop</a></h2>
<p>Every agent operates on a fundamental cycle that mirrors how humans approach tasks:</p>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PERCEIVE   â”‚ â† Gather information about current state
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REASON    â”‚ â† Decide what to do next
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ACT      â”‚ â† Execute the chosen action
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â”€â”€â”€â”€â”€â†’ (back to PERCEIVE)
</code></pre>
<h3 id="perceive"><a class="header" href="#perceive">Perceive</a></h3>
<p>The agent observes its environment:</p>
<ul>
<li>User input and instructions</li>
<li>Tool outputs and results</li>
<li>Current state and context</li>
<li>Available resources</li>
</ul>
<h3 id="reason"><a class="header" href="#reason">Reason</a></h3>
<p>The agent decides on the next action:</p>
<ul>
<li>Analyze the current situation</li>
<li>Consider available options</li>
<li>Plan the next step</li>
<li>Evaluate potential outcomes</li>
</ul>
<h3 id="act"><a class="header" href="#act">Act</a></h3>
<p>The agent executes its decision:</p>
<ul>
<li>Call a tool or function</li>
<li>Generate a response</li>
<li>Update internal state</li>
<li>Request more information</li>
</ul>
<h2 id="memory-systems"><a class="header" href="#memory-systems">Memory Systems</a></h2>
<p>Agents need memory to maintain context and learn from experience. There are two primary types:</p>
<h3 id="short-term-memory-working-memory"><a class="header" href="#short-term-memory-working-memory">Short-Term Memory (Working Memory)</a></h3>
<p>Holds information for the current task:</p>
<ul>
<li><strong>Conversation history</strong>: Recent messages and responses</li>
<li><strong>Intermediate results</strong>: Outputs from previous steps</li>
<li><strong>Current plan</strong>: What the agent is trying to accomplish</li>
<li><strong>Execution state</strong>: Where the agent is in the workflow</li>
</ul>
<p><strong>Implementation</strong>: Typically stored in the LLMâ€™s context window</p>
<p><strong>Limitations</strong>:</p>
<ul>
<li>Fixed size (token limits)</li>
<li>Cleared when task completes</li>
<li>Can become cluttered</li>
</ul>
<h3 id="long-term-memory-persistent-memory"><a class="header" href="#long-term-memory-persistent-memory">Long-Term Memory (Persistent Memory)</a></h3>
<p>Retains information across sessions:</p>
<ul>
<li><strong>Facts and knowledge</strong>: Learned information about the user or domain</li>
<li><strong>Past interactions</strong>: Historical conversations</li>
<li><strong>Successful strategies</strong>: What worked before</li>
<li><strong>User preferences</strong>: Personalization data</li>
</ul>
<p><strong>Implementation</strong>:</p>
<ul>
<li>Vector databases (semantic search)</li>
<li>Traditional databases (structured data)</li>
<li>File systems (documents, logs)</li>
</ul>
<p><strong>Key Operations</strong>:</p>
<ul>
<li><strong>Store</strong>: Save important information</li>
<li><strong>Retrieve</strong>: Find relevant past information</li>
<li><strong>Update</strong>: Modify existing memories</li>
<li><strong>Forget</strong>: Remove outdated information</li>
</ul>
<h2 id="planning-and-goal-oriented-behavior"><a class="header" href="#planning-and-goal-oriented-behavior">Planning and Goal-Oriented Behavior</a></h2>
<p>Agents donâ€™t just reactâ€”they plan ahead to achieve goals efficiently.</p>
<h3 id="goal-decomposition"><a class="header" href="#goal-decomposition">Goal Decomposition</a></h3>
<p>Breaking complex goals into manageable sub-goals:</p>
<pre><code>Goal: "Research and summarize recent AI papers"
  â”œâ”€ Sub-goal 1: Search for relevant papers
  â”œâ”€ Sub-goal 2: Read and extract key points
  â”œâ”€ Sub-goal 3: Synthesize findings
  â””â”€ Sub-goal 4: Format summary
</code></pre>
<h3 id="planning-strategies"><a class="header" href="#planning-strategies">Planning Strategies</a></h3>
<p><strong>Reactive Planning</strong>: Decide next step based on current state</p>
<ul>
<li>Simple and fast</li>
<li>Good for straightforward tasks</li>
<li>Limited lookahead</li>
</ul>
<p><strong>Proactive Planning</strong>: Create full plan upfront, then execute</p>
<ul>
<li>Better for complex tasks</li>
<li>Can optimize entire workflow</li>
<li>May need replanning if things change</li>
</ul>
<p><strong>Hybrid Planning</strong>: Plan a few steps ahead, adapt as needed</p>
<ul>
<li>Balances flexibility and efficiency</li>
<li>Most common in practice</li>
</ul>
<h3 id="plan-representation"><a class="header" href="#plan-representation">Plan Representation</a></h3>
<p>Plans can be represented as:</p>
<ul>
<li><strong>Linear sequences</strong>: Step 1 â†’ Step 2 â†’ Step 3</li>
<li><strong>Trees</strong>: Branching based on conditions</li>
<li><strong>Graphs</strong>: Complex dependencies between steps</li>
<li><strong>Natural language</strong>: Human-readable descriptions</li>
</ul>
<h2 id="multi-step-task-execution"><a class="header" href="#multi-step-task-execution">Multi-Step Task Execution</a></h2>
<p>Agents excel at tasks requiring multiple actions:</p>
<h3 id="execution-patterns"><a class="header" href="#execution-patterns">Execution Patterns</a></h3>
<p><strong>Sequential Execution</strong></p>
<pre><code>Step 1 â†’ Step 2 â†’ Step 3 â†’ Done
</code></pre>
<p>Each step depends on the previous one.</p>
<p><strong>Parallel Execution</strong></p>
<pre><code>Step 1a â”€â”
Step 1b â”€â”¼â†’ Combine â†’ Done
Step 1c â”€â”˜
</code></pre>
<p>Independent steps run simultaneously.</p>
<p><strong>Conditional Execution</strong></p>
<pre><code>Step 1 â†’ Decision
         â”œâ”€ If A â†’ Step 2a â†’ Done
         â””â”€ If B â†’ Step 2b â†’ Done
</code></pre>
<p>Path depends on intermediate results.</p>
<p><strong>Iterative Execution</strong></p>
<pre><code>Step 1 â†’ Step 2 â†’ Check
         â†‘         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (repeat if needed)
</code></pre>
<p>Loop until condition is met.</p>
<h3 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h3>
<p>Robust agents handle failures gracefully:</p>
<ol>
<li><strong>Detect</strong>: Recognize when something went wrong</li>
<li><strong>Diagnose</strong>: Understand the cause</li>
<li><strong>Recover</strong>: Try alternative approaches</li>
<li><strong>Escalate</strong>: Ask for help if stuck</li>
</ol>
<h3 id="progress-tracking"><a class="header" href="#progress-tracking">Progress Tracking</a></h3>
<p>Agents monitor their progress:</p>
<ul>
<li><strong>Checkpoints</strong>: Mark completed sub-goals</li>
<li><strong>State management</strong>: Track whatâ€™s been done</li>
<li><strong>Backtracking</strong>: Undo steps if needed</li>
<li><strong>Resumption</strong>: Continue after interruption</li>
</ul>
<h2 id="core-components-of-agent-architecture"><a class="header" href="#core-components-of-agent-architecture">Core Components of Agent Architecture</a></h2>
<h3 id="1-controller-brain"><a class="header" href="#1-controller-brain">1. Controller (Brain)</a></h3>
<p>The central decision-making component:</p>
<ul>
<li>Interprets user goals</li>
<li>Manages the reasoning loop</li>
<li>Coordinates other components</li>
<li>Handles control flow</li>
</ul>
<h3 id="2-memory-manager"><a class="header" href="#2-memory-manager">2. Memory Manager</a></h3>
<p>Manages information storage and retrieval:</p>
<ul>
<li>Maintains conversation context</li>
<li>Stores and retrieves long-term memories</li>
<li>Decides what to remember/forget</li>
<li>Optimizes memory usage</li>
</ul>
<h3 id="3-tool-interface"><a class="header" href="#3-tool-interface">3. Tool Interface</a></h3>
<p>Connects agent to external capabilities:</p>
<ul>
<li>Defines available tools</li>
<li>Handles tool invocation</li>
<li>Parses tool outputs</li>
<li>Manages tool errors</li>
</ul>
<h3 id="4-planner"><a class="header" href="#4-planner">4. Planner</a></h3>
<p>Develops strategies for achieving goals:</p>
<ul>
<li>Decomposes complex tasks</li>
<li>Generates action sequences</li>
<li>Optimizes execution order</li>
<li>Adapts plans based on results</li>
</ul>
<h3 id="5-executor"><a class="header" href="#5-executor">5. Executor</a></h3>
<p>Carries out planned actions:</p>
<ul>
<li>Invokes tools with correct parameters</li>
<li>Monitors execution</li>
<li>Collects results</li>
<li>Reports status</li>
</ul>
<h2 id="putting-it-together"><a class="header" href="#putting-it-together">Putting It Together</a></h2>
<p>A complete agent architecture integrates these components:</p>
<pre><code>User Input
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CONTROLLER              â”‚
â”‚  (Orchestrates everything)      â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”‚                        â”‚
     â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MEMORY  â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ PLANNER â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â†‘                        â”‚
     â”‚                        â–¼
     â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚EXECUTOR â”‚
                        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  TOOLS  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
                         Results
</code></pre>
<h2 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h2>
<p>When architecting agents, follow these principles:</p>
<ol>
<li><strong>Modularity</strong>: Separate concerns into distinct components</li>
<li><strong>Observability</strong>: Make agent reasoning transparent</li>
<li><strong>Flexibility</strong>: Allow easy addition of new tools and capabilities</li>
<li><strong>Robustness</strong>: Handle errors and edge cases gracefully</li>
<li><strong>Efficiency</strong>: Minimize unnecessary steps and API calls</li>
<li><strong>Safety</strong>: Validate inputs and outputs, respect boundaries</li>
</ol>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>Now that you understand the basic architecture, weâ€™ll explore how LLMs power these components in the next section on LLM Fundamentals for Agents.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="llm-fundamentals-for-agents"><a class="header" href="#llm-fundamentals-for-agents">LLM Fundamentals for Agents</a></h1>
<h2 id="how-language-models-work"><a class="header" href="#how-language-models-work">How Language Models Work</a></h2>
<p>Large Language Models (LLMs) are the â€œbrainâ€ of modern AI agents. Understanding how they work helps you build better agents.</p>
<h3 id="the-basics"><a class="header" href="#the-basics">The Basics</a></h3>
<p>LLMs are trained to predict the next token (word or word piece) given previous tokens:</p>
<pre><code>Input:  "The capital of France is"
Output: "Paris" (most likely next token)
</code></pre>
<p>This simple mechanism enables:</p>
<ul>
<li>Text generation</li>
<li>Question answering</li>
<li>Reasoning</li>
<li>Code generation</li>
<li>Tool use</li>
</ul>
<h3 id="from-prediction-to-reasoning"><a class="header" href="#from-prediction-to-reasoning">From Prediction to Reasoning</a></h3>
<p>Modern LLMs donâ€™t just predictâ€”they reason:</p>
<p><strong>Chain-of-Thought</strong>: Breaking down problems step by step</p>
<pre><code>Question: "If I have 3 apples and buy 2 more, then give away 1, how many do I have?"

LLM reasoning:
1. Start with 3 apples
2. Buy 2 more: 3 + 2 = 5
3. Give away 1: 5 - 1 = 4
Answer: 4 apples
</code></pre>
<p><strong>Tool Use</strong>: Recognizing when to call external functions</p>
<pre><code>User: "What's the weather in Tokyo?"
LLM: I should use the weather_api tool with location="Tokyo"
</code></pre>
<h3 id="key-capabilities-for-agents"><a class="header" href="#key-capabilities-for-agents">Key Capabilities for Agents</a></h3>
<ul>
<li><strong>Instruction following</strong>: Understanding and executing commands</li>
<li><strong>Context understanding</strong>: Maintaining awareness of conversation history</li>
<li><strong>Function calling</strong>: Invoking tools with correct parameters</li>
<li><strong>Error recovery</strong>: Adapting when things go wrong</li>
<li><strong>Self-reflection</strong>: Evaluating own outputs</li>
</ul>
<h2 id="prompting-strategies-for-agents"><a class="header" href="#prompting-strategies-for-agents">Prompting Strategies for Agents</a></h2>
<p>How you prompt an LLM dramatically affects agent performance.</p>
<h3 id="system-prompts"><a class="header" href="#system-prompts">System Prompts</a></h3>
<p>Define the agentâ€™s role, capabilities, and constraints:</p>
<pre><code>You are a research assistant agent. Your goal is to help users 
find and synthesize information from multiple sources.

Available tools:
- web_search(query): Search the internet
- read_url(url): Extract content from a webpage
- summarize(text): Create concise summaries

Always:
1. Break complex requests into steps
2. Verify information from multiple sources
3. Cite your sources
4. Ask for clarification if needed
</code></pre>
<h3 id="few-shot-examples"><a class="header" href="#few-shot-examples">Few-Shot Examples</a></h3>
<p>Show the agent how to behave through examples:</p>
<pre><code>Example 1:
User: "Find recent news about AI"
Agent: I'll search for recent AI news.
Action: web_search("AI news 2026")
Result: [search results]
Agent: Here are the top 3 recent AI developments...

Example 2:
User: "What's on that page?"
Agent: I need a URL to read a page. Could you provide the link?
</code></pre>
<h3 id="react-pattern"><a class="header" href="#react-pattern">ReAct Pattern</a></h3>
<p>The most common prompting pattern for agents:</p>
<pre><code>Thought: What do I need to do?
Action: [tool_name](parameters)
Observation: [result from tool]
Thought: What does this mean?
Action: [next tool or final answer]
</code></pre>
<h3 id="structured-outputs"><a class="header" href="#structured-outputs">Structured Outputs</a></h3>
<p>Guide the LLM to produce consistent formats:</p>
<pre><code>Respond in this format:
{
  "reasoning": "Your thought process",
  "action": "tool_name",
  "parameters": {"param": "value"},
  "confidence": 0.95
}
</code></pre>
<h2 id="context-windows-and-token-limits"><a class="header" href="#context-windows-and-token-limits">Context Windows and Token Limits</a></h2>
<p>Every LLM has a maximum context windowâ€”the amount of text it can process at once.</p>
<h3 id="common-context-sizes"><a class="header" href="#common-context-sizes">Common Context Sizes</a></h3>
<ul>
<li><strong>GPT-4</strong>: 8K, 32K, 128K tokens</li>
<li><strong>Claude</strong>: 200K tokens</li>
<li><strong>Gemini</strong>: 1M+ tokens</li>
</ul>
<h3 id="what-fits-in-context"><a class="header" href="#what-fits-in-context">What Fits in Context?</a></h3>
<p>Approximate token counts:</p>
<ul>
<li>1 token â‰ˆ 4 characters</li>
<li>1 token â‰ˆ 0.75 words</li>
<li>100 tokens â‰ˆ 75 words</li>
<li>1,000 tokens â‰ˆ 750 words</li>
</ul>
<h3 id="context-management-strategies"><a class="header" href="#context-management-strategies">Context Management Strategies</a></h3>
<p><strong>1. Summarization</strong>
Compress old conversation history:</p>
<pre><code>[Full conversation history]
    â†“
[Summary of key points] + [Recent messages]
</code></pre>
<p><strong>2. Sliding Window</strong>
Keep only the most recent N messages:</p>
<pre><code>Message 1, 2, 3, 4, 5, 6, 7, 8
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (keep last 4)
</code></pre>
<p><strong>3. Selective Retention</strong>
Keep important messages, discard routine ones:</p>
<pre><code>System prompt + Key decisions + Recent context
</code></pre>
<p><strong>4. External Memory</strong>
Store information outside context, retrieve as needed:</p>
<pre><code>Context: [Current task]
Memory DB: [All past information]
           â†“ (retrieve relevant)
Context: [Current task] + [Relevant memories]
</code></pre>
<h3 id="token-budget-management"><a class="header" href="#token-budget-management">Token Budget Management</a></h3>
<p>For agents, allocate tokens wisely:</p>
<pre><code>System prompt:     500 tokens
Tools definition:  1,000 tokens
Conversation:      5,000 tokens
Working memory:    1,500 tokens
Reserve:           1,000 tokens (for response)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:             9,000 tokens (fits in 8K with buffer)
</code></pre>
<h2 id="temperature-top-p-and-sampling-parameters"><a class="header" href="#temperature-top-p-and-sampling-parameters">Temperature, Top-p, and Sampling Parameters</a></h2>
<p>These parameters control how the LLM generates text.</p>
<h3 id="temperature"><a class="header" href="#temperature">Temperature</a></h3>
<p>Controls randomness (0.0 to 2.0):</p>
<p><strong>Low temperature (0.0 - 0.3)</strong>: Deterministic, focused</p>
<pre><code>Temperature: 0.1
"The capital of France is Paris" (always)
</code></pre>
<p><strong>Use for</strong>: Tool calling, structured tasks, factual responses</p>
<p><strong>Medium temperature (0.5 - 0.8)</strong>: Balanced</p>
<pre><code>Temperature: 0.7
"The capital of France is Paris, a beautiful city known for..."
</code></pre>
<p><strong>Use for</strong>: General agent behavior, conversational responses</p>
<p><strong>High temperature (1.0 - 2.0)</strong>: Creative, random</p>
<pre><code>Temperature: 1.5
"The capital of France? Ah, the magnificent Paris, where..."
</code></pre>
<p><strong>Use for</strong>: Creative tasks, brainstorming, diverse outputs</p>
<h3 id="top-p-nucleus-sampling"><a class="header" href="#top-p-nucleus-sampling">Top-p (Nucleus Sampling)</a></h3>
<p>Controls diversity by probability mass (0.0 to 1.0):</p>
<p><strong>Low top-p (0.1 - 0.5)</strong>: Conservative choices</p>
<ul>
<li>Considers only the most likely tokens</li>
<li>More focused and consistent</li>
</ul>
<p><strong>High top-p (0.9 - 1.0)</strong>: Diverse choices</p>
<ul>
<li>Considers a wider range of tokens</li>
<li>More varied and creative</li>
</ul>
<p><strong>Typical for agents</strong>: 0.9-0.95</p>
<h3 id="top-k"><a class="header" href="#top-k">Top-k</a></h3>
<p>Limits to top K most likely tokens:</p>
<ul>
<li><strong>top-k=1</strong>: Always pick most likely (deterministic)</li>
<li><strong>top-k=10</strong>: Choose from 10 most likely</li>
<li><strong>top-k=50</strong>: More diversity</li>
</ul>
<h3 id="practical-guidelines-for-agents"><a class="header" href="#practical-guidelines-for-agents">Practical Guidelines for Agents</a></h3>
<p><strong>For tool calling and structured tasks:</strong></p>
<pre><code class="language-python">temperature = 0.1
top_p = 0.9
</code></pre>
<p><strong>For conversational responses:</strong></p>
<pre><code class="language-python">temperature = 0.7
top_p = 0.95
</code></pre>
<p><strong>For creative tasks:</strong></p>
<pre><code class="language-python">temperature = 1.0
top_p = 0.95
</code></pre>
<h2 id="other-important-parameters"><a class="header" href="#other-important-parameters">Other Important Parameters</a></h2>
<h3 id="max-tokens"><a class="header" href="#max-tokens">Max Tokens</a></h3>
<p>Maximum length of generated response:</p>
<ul>
<li>Set based on expected output length</li>
<li>Leave room for tool calls and reasoning</li>
<li>Typical: 500-2000 for agent responses</li>
</ul>
<h3 id="stop-sequences"><a class="header" href="#stop-sequences">Stop Sequences</a></h3>
<p>Tokens that halt generation:</p>
<pre><code class="language-python">stop_sequences = ["&lt;/tool&gt;", "DONE", "\n\nUser:"]
</code></pre>
<p>Useful for controlling agent output format.</p>
<h3 id="frequencypresence-penalty"><a class="header" href="#frequencypresence-penalty">Frequency/Presence Penalty</a></h3>
<p>Reduce repetition:</p>
<ul>
<li><strong>Frequency penalty</strong>: Penalize tokens based on how often they appear</li>
<li><strong>Presence penalty</strong>: Penalize tokens that have appeared at all</li>
<li>Typical: 0.0-0.5 for agents</li>
</ul>
<h2 id="prompt-engineering-best-practices"><a class="header" href="#prompt-engineering-best-practices">Prompt Engineering Best Practices</a></h2>
<h3 id="1-be-specific"><a class="header" href="#1-be-specific">1. Be Specific</a></h3>
<p>âŒ â€œHelp me with thisâ€
âœ… â€œSearch for recent papers on transformer architectures and summarize the key innovationsâ€</p>
<h3 id="2-provide-context"><a class="header" href="#2-provide-context">2. Provide Context</a></h3>
<pre><code>You are helping a software engineer debug a Python application.
The user has intermediate Python knowledge.
Focus on practical solutions.
</code></pre>
<h3 id="3-use-delimiters"><a class="header" href="#3-use-delimiters">3. Use Delimiters</a></h3>
<pre><code>User input: """
{user_message}
"""

Available tools: ###
{tool_definitions}
###
</code></pre>
<h3 id="4-specify-output-format"><a class="header" href="#4-specify-output-format">4. Specify Output Format</a></h3>
<pre><code>Respond with:
1. Your reasoning
2. The action to take
3. Expected outcome
</code></pre>
<h3 id="5-handle-edge-cases"><a class="header" href="#5-handle-edge-cases">5. Handle Edge Cases</a></h3>
<pre><code>If the user's request is unclear, ask for clarification.
If a tool fails, try an alternative approach.
If you cannot complete the task, explain why.
</code></pre>
<h2 id="testing-and-iteration"><a class="header" href="#testing-and-iteration">Testing and Iteration</a></h2>
<h3 id="evaluate-prompts-systematically"><a class="header" href="#evaluate-prompts-systematically">Evaluate Prompts Systematically</a></h3>
<ol>
<li><strong>Create test cases</strong>: Common scenarios your agent should handle</li>
<li><strong>Run experiments</strong>: Try different prompts and parameters</li>
<li><strong>Measure performance</strong>: Success rate, quality, efficiency</li>
<li><strong>Iterate</strong>: Refine based on results</li>
</ol>
<h3 id="common-issues-and-fixes"><a class="header" href="#common-issues-and-fixes">Common Issues and Fixes</a></h3>
<p><strong>Issue</strong>: Agent doesnâ€™t use tools
<strong>Fix</strong>: Add explicit examples of tool usage</p>
<p><strong>Issue</strong>: Agent is too verbose
<strong>Fix</strong>: Lower temperature, add â€œbe conciseâ€ instruction</p>
<p><strong>Issue</strong>: Agent hallucinates
<strong>Fix</strong>: Emphasize â€œonly use provided toolsâ€, add verification steps</p>
<p><strong>Issue</strong>: Agent gets stuck in loops
<strong>Fix</strong>: Add step counter, max iterations limit</p>
<h2 id="choosing-the-right-model"><a class="header" href="#choosing-the-right-model">Choosing the Right Model</a></h2>
<p>Different models for different needs:</p>
<h3 id="for-agents"><a class="header" href="#for-agents">For Agents</a></h3>
<p><strong>GPT-4 / GPT-4 Turbo</strong></p>
<ul>
<li>Excellent reasoning</li>
<li>Reliable tool calling</li>
<li>Good for complex tasks</li>
</ul>
<p><strong>Claude 3 (Opus/Sonnet)</strong></p>
<ul>
<li>Long context (200K)</li>
<li>Strong reasoning</li>
<li>Good safety features</li>
</ul>
<p><strong>GPT-3.5 Turbo</strong></p>
<ul>
<li>Fast and cheap</li>
<li>Good for simple agents</li>
<li>Lower reasoning capability</li>
</ul>
<h3 id="trade-offs"><a class="header" href="#trade-offs">Trade-offs</a></h3>
<ul>
<li><strong>Cost vs. Capability</strong>: Stronger models cost more</li>
<li><strong>Speed vs. Quality</strong>: Faster models may be less accurate</li>
<li><strong>Context vs. Price</strong>: Longer context costs more</li>
</ul>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>With these LLM fundamentals, youâ€™re ready to build your first agent! In Chapter 2, weâ€™ll implement a simple ReAct agent that puts these concepts into practice.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="simple-react-agent"><a class="header" href="#simple-react-agent">Simple ReAct Agent</a></h1>
<h2 id="module-2-learning-objectives"><a class="header" href="#module-2-learning-objectives">Module 2: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Implement a ReAct agent from scratch</li>
<li>âœ“ Integrate external tools with function calling</li>
<li>âœ“ Handle errors and retries gracefully</li>
<li>âœ“ Build a complete shopping research assistant</li>
<li>âœ“ Understand tool schemas and validation</li>
</ul>
<hr>
<h2 id="introduction-to-react"><a class="header" href="#introduction-to-react">Introduction to ReAct</a></h2>
<p><strong>ReAct</strong> (Reasoning + Acting) is the most popular pattern for building AI agents. It combines:</p>
<ul>
<li><strong>Reasoning</strong>: Thinking through what to do</li>
<li><strong>Acting</strong>: Taking actions via tools</li>
</ul>
<p>The agent alternates between thinking and acting until it solves the task.</p>
<h2 id="the-react-pattern"><a class="header" href="#the-react-pattern">The ReAct Pattern</a></h2>
<pre><code class="language-mermaid">graph TD
    A[User Query] --&gt; B[Thought: Reason]
    B --&gt; C{Need Tool?}
    C --&gt;|Yes| D[Action: Use Tool]
    C --&gt;|No| E[Answer: Respond]
    D --&gt; F[Observation: Result]
    F --&gt; B
    E --&gt; G[Done]
    style B fill:#fef3c7
    style D fill:#d1fae5
    style F fill:#dbeafe
    style E fill:#f0fdf4
</code></pre>
<p><strong>The ReAct Loop:</strong></p>
<pre><code>Thought: I need to figure out what to do
Action: tool_name(parameters)
Observation: [result from the tool]
Thought: Based on this result, I should...
Action: another_tool(parameters)
Observation: [another result]
Thought: Now I have enough information
Answer: [final response to user]
</code></pre>
<h3 id="why-react-works"><a class="header" href="#why-react-works">Why ReAct Works</a></h3>
<ol>
<li><strong>Transparency</strong>: You can see the agentâ€™s reasoning</li>
<li><strong>Debuggability</strong>: Easy to identify where things go wrong</li>
<li><strong>Flexibility</strong>: Works for many types of tasks</li>
<li><strong>Simplicity</strong>: Easy to implement and understand</li>
</ol>
<blockquote>
<p><strong>âš ï¸ Important</strong></p>
<p>ReAct agents can get stuck in loops or make poor decisions. Always implement max step limits and validation to prevent runaway execution.</p>
</blockquote>
<h2 id="building-your-first-react-agent"><a class="header" href="#building-your-first-react-agent">Building Your First ReAct Agent</a></h2>
<p>Letâ€™s build a simple agent step by step.</p>
<h3 id="step-1-define-the-agent-loop"><a class="header" href="#step-1-define-the-agent-loop">Step 1: Define the Agent Loop</a></h3>
<pre><code class="language-python">def react_agent(user_input, max_steps=10):
    """Simple ReAct agent loop"""
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_input}
    ]
    
    for step in range(max_steps):
        # Get LLM response
        response = llm.generate(messages)
        
        # Parse response
        if is_final_answer(response):
            return response
        
        # Execute action
        action, params = parse_action(response)
        result = execute_tool(action, params)
        
        # Add to conversation
        messages.append({"role": "assistant", "content": response})
        messages.append({"role": "user", "content": f"Observation: {result}"})
    
    return "Max steps reached"
</code></pre>
<h3 id="step-2-create-the-system-prompt"><a class="header" href="#step-2-create-the-system-prompt">Step 2: Create the System Prompt</a></h3>
<pre><code class="language-python">SYSTEM_PROMPT = """You are a helpful AI agent that can use tools to answer questions.

Available tools:
- search(query): Search the internet for information
- calculate(expression): Evaluate mathematical expressions
- get_time(): Get the current time

Use this format:
Thought: [your reasoning about what to do]
Action: tool_name(parameters)

When you have the final answer:
Answer: [your response to the user]

Example:
User: What is 25 * 17?
Thought: I need to calculate this multiplication
Action: calculate("25 * 17")
Observation: 425
Thought: I have the result
Answer: 25 * 17 equals 425
"""
</code></pre>
<h3 id="step-3-implement-tool-execution"><a class="header" href="#step-3-implement-tool-execution">Step 3: Implement Tool Execution</a></h3>
<pre><code class="language-python">def execute_tool(action, params):
    """Execute a tool and return the result"""
    tools = {
        "search": search_tool,
        "calculate": calculate_tool,
        "get_time": get_time_tool
    }
    
    if action not in tools:
        return f"Error: Unknown tool '{action}'"
    
    try:
        result = tools[action](params)
        return result
    except Exception as e:
        return f"Error: {str(e)}"
</code></pre>
<h3 id="step-4-parse-agent-output"><a class="header" href="#step-4-parse-agent-output">Step 4: Parse Agent Output</a></h3>
<pre><code class="language-python">import re

def parse_action(response):
    """Extract action and parameters from agent response"""
    # Look for Action: tool_name(params)
    match = re.search(r'Action:\s*(\w+)\((.*?)\)', response)
    
    if match:
        action = match.group(1)
        params = match.group(2).strip('"\'')
        return action, params
    
    return None, None

def is_final_answer(response):
    """Check if response contains final answer"""
    return "Answer:" in response
</code></pre>
<h2 id="complete-working-example"><a class="header" href="#complete-working-example">Complete Working Example</a></h2>
<pre><code class="language-python">import openai
import re
from datetime import datetime

# Initialize OpenAI
client = openai.OpenAI()

# System prompt
SYSTEM_PROMPT = """You are a helpful AI agent with access to tools.

Tools:
- calculate(expression): Evaluate math expressions
- get_time(): Get current time

Format:
Thought: [reasoning]
Action: tool_name(parameters)

When done:
Answer: [final response]
"""

# Tool implementations
def calculate_tool(expression):
    """Safely evaluate math expressions"""
    try:
        # Only allow safe operations
        allowed = set('0123456789+-*/()., ')
        if not all(c in allowed for c in expression):
            return "Error: Invalid characters in expression"
        return str(eval(expression))
    except Exception as e:
        return f"Error: {str(e)}"

def get_time_tool(_):
    """Get current time"""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Tool registry
TOOLS = {
    "calculate": calculate_tool,
    "get_time": get_time_tool
}

# Parsing functions
def parse_action(text):
    """Extract action from agent response"""
    match = re.search(r'Action:\s*(\w+)\((.*?)\)', text)
    if match:
        return match.group(1), match.group(2).strip('"\'')
    return None, None

def is_final_answer(text):
    """Check if agent provided final answer"""
    return "Answer:" in text

# Main agent loop
def react_agent(user_input, max_steps=10):
    """ReAct agent implementation"""
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_input}
    ]
    
    print(f"User: {user_input}\n")
    
    for step in range(max_steps):
        # Get LLM response
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.1
        )
        
        agent_response = response.choices[0].message.content
        print(f"Agent: {agent_response}\n")
        
        # Check if done
        if is_final_answer(agent_response):
            # Extract final answer
            answer = agent_response.split("Answer:")[1].strip()
            return answer
        
        # Parse and execute action
        action, params = parse_action(agent_response)
        
        if action and action in TOOLS:
            result = TOOLS[action](params)
            observation = f"Observation: {result}"
            print(f"{observation}\n")
            
            # Add to conversation
            messages.append({"role": "assistant", "content": agent_response})
            messages.append({"role": "user", "content": observation})
        else:
            return "Error: Could not parse action or unknown tool"
    
    return "Max steps reached without answer"

# Test the agent
if __name__ == "__main__":
    result = react_agent("What is 123 * 456?")
    print(f"Final Answer: {result}")
</code></pre>
<h2 id="thought-action-observation-cycles"><a class="header" href="#thought-action-observation-cycles">Thought-Action-Observation Cycles</a></h2>
<p>Letâ€™s trace through an example:</p>
<p><strong>User</strong>: â€œWhatâ€™s 15% of 240?â€</p>
<p><strong>Cycle 1:</strong></p>
<pre><code>Thought: I need to calculate 15% of 240, which is 0.15 * 240
Action: calculate("0.15 * 240")
Observation: 36.0
</code></pre>
<p><strong>Cycle 2:</strong></p>
<pre><code>Thought: I have the result
Answer: 15% of 240 is 36
</code></pre>
<h3 id="multiple-steps-example"><a class="header" href="#multiple-steps-example">Multiple Steps Example</a></h3>
<p><strong>User</strong>: â€œWhat time is it and whatâ€™s 100 + 50?â€</p>
<p><strong>Cycle 1:</strong></p>
<pre><code>Thought: I need to get the current time first
Action: get_time()
Observation: 2026-02-24 11:19:00
</code></pre>
<p><strong>Cycle 2:</strong></p>
<pre><code>Thought: Now I need to calculate 100 + 50
Action: calculate("100 + 50")
Observation: 150
</code></pre>
<p><strong>Cycle 3:</strong></p>
<pre><code>Thought: I have both pieces of information
Answer: The current time is 2026-02-24 11:19:00, and 100 + 50 equals 150
</code></pre>
<h2 id="basic-tool-calling"><a class="header" href="#basic-tool-calling">Basic Tool Calling</a></h2>
<h3 id="tool-definition"><a class="header" href="#tool-definition">Tool Definition</a></h3>
<p>Define tools with clear descriptions:</p>
<pre><code class="language-python">TOOLS = {
    "search": {
        "function": search_tool,
        "description": "Search the internet for information",
        "parameters": {
            "query": "The search query string"
        }
    },
    "calculate": {
        "function": calculate_tool,
        "description": "Evaluate mathematical expressions",
        "parameters": {
            "expression": "Math expression to evaluate (e.g., '2 + 2')"
        }
    }
}
</code></pre>
<h3 id="tool-implementation-best-practices"><a class="header" href="#tool-implementation-best-practices">Tool Implementation Best Practices</a></h3>
<ol>
<li><strong>Validate inputs</strong>: Check parameters before execution</li>
<li><strong>Handle errors</strong>: Return error messages, donâ€™t crash</li>
<li><strong>Return strings</strong>: Consistent output format</li>
<li><strong>Be deterministic</strong>: Same input â†’ same output</li>
<li><strong>Add timeouts</strong>: Prevent hanging operations</li>
</ol>
<pre><code class="language-python">def search_tool(query):
    """Search tool with validation and error handling"""
    # Validate
    if not query or len(query) &lt; 2:
        return "Error: Query too short"
    
    # Execute with timeout
    try:
        results = search_api(query, timeout=5)
        return format_results(results)
    except TimeoutError:
        return "Error: Search timed out"
    except Exception as e:
        return f"Error: {str(e)}"
</code></pre>
<h2 id="error-handling-and-retries"><a class="header" href="#error-handling-and-retries">Error Handling and Retries</a></h2>
<p>Agents need to handle failures gracefully.</p>
<h3 id="detecting-errors"><a class="header" href="#detecting-errors">Detecting Errors</a></h3>
<pre><code class="language-python">def is_error(observation):
    """Check if tool execution resulted in error"""
    return observation.startswith("Error:")
</code></pre>
<h3 id="retry-logic"><a class="header" href="#retry-logic">Retry Logic</a></h3>
<pre><code class="language-python">def react_agent_with_retry(user_input, max_steps=10, max_retries=3):
    """ReAct agent with retry logic"""
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_input}
    ]
    
    retry_count = 0
    
    for step in range(max_steps):
        response = get_llm_response(messages)
        
        if is_final_answer(response):
            return extract_answer(response)
        
        action, params = parse_action(response)
        result = execute_tool(action, params)
        
        # Handle errors
        if is_error(result) and retry_count &lt; max_retries:
            retry_count += 1
            messages.append({
                "role": "user", 
                "content": f"{result}\nPlease try a different approach."
            })
            continue
        
        retry_count = 0  # Reset on success
        messages.append({"role": "assistant", "content": response})
        messages.append({"role": "user", "content": f"Observation: {result}"})
    
    return "Max steps reached"
</code></pre>
<h3 id="graceful-degradation"><a class="header" href="#graceful-degradation">Graceful Degradation</a></h3>
<pre><code class="language-python"># Add to system prompt
"""
If a tool fails:
1. Try an alternative approach
2. If no alternative exists, explain the limitation
3. Provide the best answer you can with available information
"""
</code></pre>
<h2 id="common-pitfalls-and-solutions"><a class="header" href="#common-pitfalls-and-solutions">Common Pitfalls and Solutions</a></h2>
<h3 id="pitfall-1-infinite-loops"><a class="header" href="#pitfall-1-infinite-loops">Pitfall 1: Infinite Loops</a></h3>
<p><strong>Problem</strong>: Agent repeats the same action
<strong>Solution</strong>: Track action history, limit repetitions</p>
<pre><code class="language-python">action_history = []

if action in action_history[-3:]:  # Same action 3 times
    return "Agent stuck in loop, stopping"
    
action_history.append(action)
</code></pre>
<h3 id="pitfall-2-hallucinated-tools"><a class="header" href="#pitfall-2-hallucinated-tools">Pitfall 2: Hallucinated Tools</a></h3>
<p><strong>Problem</strong>: Agent invents non-existent tools
<strong>Solution</strong>: Strict validation, clear error messages</p>
<pre><code class="language-python">if action not in TOOLS:
    observation = f"Error: Tool '{action}' does not exist. Available tools: {list(TOOLS.keys())}"
</code></pre>
<h3 id="pitfall-3-malformed-actions"><a class="header" href="#pitfall-3-malformed-actions">Pitfall 3: Malformed Actions</a></h3>
<p><strong>Problem</strong>: Agent doesnâ€™t follow format
<strong>Solution</strong>: Better prompting, examples, parsing fallbacks</p>
<pre><code class="language-python"># Add to system prompt
"""
IMPORTANT: Always use exact format:
Action: tool_name(parameters)

Incorrect: "I'll use search tool with query X"
Correct: Action: search("query X")
"""
</code></pre>
<h3 id="pitfall-4-premature-answers"><a class="header" href="#pitfall-4-premature-answers">Pitfall 4: Premature Answers</a></h3>
<p><strong>Problem</strong>: Agent answers before using tools
<strong>Solution</strong>: Emphasize tool usage in prompt</p>
<pre><code class="language-python">"""
You MUST use tools to answer questions. Do not guess or use prior knowledge.
Always verify information using available tools.
"""
</code></pre>
<h2 id="testing-your-agent"><a class="header" href="#testing-your-agent">Testing Your Agent</a></h2>
<pre><code class="language-python"># Test cases
test_cases = [
    ("What is 50 * 20?", "1000"),
    ("What time is it?", None),  # Time varies
    ("Calculate 100 / 4", "25"),
]

for question, expected in test_cases:
    result = react_agent(question)
    if expected:
        assert expected in result, f"Failed: {question}"
    print(f"âœ“ {question}")
</code></pre>
<blockquote>
<p><strong>ğŸ’¡ Pro Tip</strong></p>
<p>Start with simple test cases and gradually increase complexity. Log all reasoning traces to understand how your agent makes decisions.</p>
</blockquote>
<hr>
<blockquote>
<p><strong>âœ… Key Takeaways</strong></p>
<ul>
<li>ReAct combines reasoning (thinking) with acting (tool use)</li>
<li>The agent alternates between Thought, Action, and Observation</li>
<li>Always implement max steps to prevent infinite loops</li>
<li>Use structured prompts to guide agent behavior</li>
<li>Validate tool calls before execution</li>
<li>Common pitfalls: loops, hallucinations, premature answers</li>
</ul>
</blockquote>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<p>You now have a working ReAct agent! In the next section, weâ€™ll explore tool integration in depth, including:</p>
<ul>
<li>Function calling APIs</li>
<li>Complex tool schemas</li>
<li>Parameter validation</li>
<li>Response parsing strategies</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="tool-integration"><a class="header" href="#tool-integration">Tool Integration</a></h1>
<h2 id="function-calling-apis"><a class="header" href="#function-calling-apis">Function Calling APIs</a></h2>
<p>Modern LLMs support native function calling, making tool integration more reliable than text parsing.</p>
<h3 id="openai-function-calling"><a class="header" href="#openai-function-calling">OpenAI Function Calling</a></h3>
<pre><code class="language-python">import openai

client = openai.OpenAI()

# Define tools
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get the current weather for a location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "City name, e.g., 'San Francisco'"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "Temperature unit"
                    }
                },
                "required": ["location"]
            }
        }
    }
]

# Call LLM with tools
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "What's the weather in Tokyo?"}],
    tools=tools,
    tool_choice="auto"  # Let model decide when to use tools
)

# Check if model wants to call a function
message = response.choices[0].message
if message.tool_calls:
    tool_call = message.tool_calls[0]
    function_name = tool_call.function.name
    arguments = json.loads(tool_call.function.arguments)
    print(f"Calling: {function_name}({arguments})")
</code></pre>
<h3 id="anthropic-tool-use"><a class="header" href="#anthropic-tool-use">Anthropic Tool Use</a></h3>
<pre><code class="language-python">import anthropic

client = anthropic.Anthropic()

tools = [
    {
        "name": "get_weather",
        "description": "Get current weather for a location",
        "input_schema": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "City name"
                }
            },
            "required": ["location"]
        }
    }
]

response = client.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=1024,
    tools=tools,
    messages=[{"role": "user", "content": "Weather in Paris?"}]
)

# Check for tool use
for block in response.content:
    if block.type == "tool_use":
        print(f"Tool: {block.name}")
        print(f"Input: {block.input}")
</code></pre>
<h3 id="benefits-of-native-function-calling"><a class="header" href="#benefits-of-native-function-calling">Benefits of Native Function Calling</a></h3>
<ol>
<li><strong>Structured output</strong>: JSON instead of text parsing</li>
<li><strong>Type safety</strong>: Parameters validated by LLM</li>
<li><strong>Reliability</strong>: Less prone to format errors</li>
<li><strong>Parallel calls</strong>: Multiple tools at once</li>
</ol>
<h2 id="tool-schemas-and-descriptions"><a class="header" href="#tool-schemas-and-descriptions">Tool Schemas and Descriptions</a></h2>
<p>Good tool definitions are critical for agent performance.</p>
<h3 id="anatomy-of-a-tool-schema"><a class="header" href="#anatomy-of-a-tool-schema">Anatomy of a Tool Schema</a></h3>
<pre><code class="language-python">{
    "name": "search_database",  # Clear, descriptive name
    "description": "Search the product database for items matching criteria. Returns up to 10 results.",  # When and why to use
    "parameters": {
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "Search query (e.g., 'red shoes size 10')"
            },
            "category": {
                "type": "string",
                "enum": ["electronics", "clothing", "books"],
                "description": "Product category to search within"
            },
            "max_price": {
                "type": "number",
                "description": "Maximum price in USD"
            }
        },
        "required": ["query"]  # Only query is mandatory
    }
}
</code></pre>
<h3 id="writing-effective-descriptions"><a class="header" href="#writing-effective-descriptions">Writing Effective Descriptions</a></h3>
<p><strong>Bad</strong>: â€œSearch functionâ€
<strong>Good</strong>: â€œSearch the product database for items. Use when user asks about products, availability, or prices.â€</p>
<p><strong>Bad</strong>: â€œGets dataâ€
<strong>Good</strong>: â€œRetrieve user profile data including name, email, and preferences. Use for personalization or account queries.â€</p>
<h3 id="description-best-practices"><a class="header" href="#description-best-practices">Description Best Practices</a></h3>
<ol>
<li><strong>Be specific</strong>: Explain exactly what the tool does</li>
<li><strong>Include examples</strong>: Show typical parameter values</li>
<li><strong>State limitations</strong>: Mention constraints or edge cases</li>
<li><strong>Clarify use cases</strong>: When should this tool be used?</li>
<li><strong>Avoid ambiguity</strong>: Use precise language</li>
</ol>
<pre><code class="language-python"># Good example
{
    "name": "calculate_shipping",
    "description": """Calculate shipping cost for an order.
    
    Use when: User asks about shipping costs or delivery fees
    Returns: Cost in USD and estimated delivery days
    Limitations: Only works for US addresses
    
    Example: calculate_shipping(weight=2.5, zip_code="94102")
    """,
    "parameters": {
        "type": "object",
        "properties": {
            "weight": {
                "type": "number",
                "description": "Package weight in pounds (e.g., 2.5)"
            },
            "zip_code": {
                "type": "string",
                "description": "5-digit US ZIP code (e.g., '94102')"
            }
        },
        "required": ["weight", "zip_code"]
    }
}
</code></pre>
<h2 id="parameter-validation"><a class="header" href="#parameter-validation">Parameter Validation</a></h2>
<p>Always validate parameters before execution.</p>
<h3 id="basic-validation"><a class="header" href="#basic-validation">Basic Validation</a></h3>
<pre><code class="language-python">def validate_parameters(tool_name, params):
    """Validate tool parameters"""
    validators = {
        "search": validate_search,
        "calculate": validate_calculate,
        "send_email": validate_email
    }
    
    if tool_name not in validators:
        return False, f"Unknown tool: {tool_name}"
    
    return validators[tool_name](params)

def validate_search(params):
    """Validate search parameters"""
    if "query" not in params:
        return False, "Missing required parameter: query"
    
    if not isinstance(params["query"], str):
        return False, "Query must be a string"
    
    if len(params["query"]) &lt; 2:
        return False, "Query too short (minimum 2 characters)"
    
    if len(params["query"]) &gt; 200:
        return False, "Query too long (maximum 200 characters)"
    
    return True, "Valid"
</code></pre>
<h3 id="type-validation"><a class="header" href="#type-validation">Type Validation</a></h3>
<pre><code class="language-python">def validate_type(value, expected_type):
    """Validate parameter type"""
    type_map = {
        "string": str,
        "number": (int, float),
        "boolean": bool,
        "array": list,
        "object": dict
    }
    
    expected = type_map.get(expected_type)
    if not isinstance(value, expected):
        return False, f"Expected {expected_type}, got {type(value).__name__}"
    
    return True, "Valid"
</code></pre>
<h3 id="schema-based-validation"><a class="header" href="#schema-based-validation">Schema-Based Validation</a></h3>
<pre><code class="language-python">import jsonschema

def validate_with_schema(params, schema):
    """Validate parameters against JSON schema"""
    try:
        jsonschema.validate(instance=params, schema=schema)
        return True, "Valid"
    except jsonschema.ValidationError as e:
        return False, str(e)

# Example usage
schema = {
    "type": "object",
    "properties": {
        "email": {
            "type": "string",
            "format": "email"
        },
        "age": {
            "type": "integer",
            "minimum": 0,
            "maximum": 150
        }
    },
    "required": ["email"]
}

valid, message = validate_with_schema(
    {"email": "user@example.com", "age": 25},
    schema
)
</code></pre>
<h3 id="sanitization"><a class="header" href="#sanitization">Sanitization</a></h3>
<p>Clean inputs before use:</p>
<pre><code class="language-python">def sanitize_string(s, max_length=1000):
    """Sanitize string input"""
    # Remove null bytes
    s = s.replace('\x00', '')
    
    # Trim whitespace
    s = s.strip()
    
    # Limit length
    s = s[:max_length]
    
    return s

def sanitize_sql_input(s):
    """Prevent SQL injection"""
    # Use parameterized queries instead
    # This is just for demonstration
    dangerous = ["'", '"', ';', '--', '/*', '*/']
    for char in dangerous:
        s = s.replace(char, '')
    return s
</code></pre>
<h2 id="response-parsing"><a class="header" href="#response-parsing">Response Parsing</a></h2>
<p>Handle tool outputs consistently.</p>
<h3 id="structured-responses"><a class="header" href="#structured-responses">Structured Responses</a></h3>
<pre><code class="language-python">from dataclasses import dataclass
from typing import Optional

@dataclass
class ToolResponse:
    """Standardized tool response"""
    success: bool
    data: Optional[dict] = None
    error: Optional[str] = None
    metadata: Optional[dict] = None

def execute_tool(tool_name, params):
    """Execute tool and return structured response"""
    try:
        result = TOOLS[tool_name](params)
        return ToolResponse(
            success=True,
            data=result,
            metadata={"tool": tool_name, "timestamp": time.time()}
        )
    except Exception as e:
        return ToolResponse(
            success=False,
            error=str(e),
            metadata={"tool": tool_name}
        )
</code></pre>
<h3 id="formatting-for-llm"><a class="header" href="#formatting-for-llm">Formatting for LLM</a></h3>
<pre><code class="language-python">def format_tool_response(response: ToolResponse) -&gt; str:
    """Format tool response for LLM consumption"""
    if response.success:
        return f"Success: {json.dumps(response.data, indent=2)}"
    else:
        return f"Error: {response.error}"

# Usage in agent loop
result = execute_tool("search", {"query": "AI agents"})
observation = format_tool_response(result)
messages.append({"role": "user", "content": f"Observation: {observation}"})
</code></pre>
<h3 id="handling-different-response-types"><a class="header" href="#handling-different-response-types">Handling Different Response Types</a></h3>
<pre><code class="language-python">def parse_tool_output(output, expected_type="string"):
    """Parse and validate tool output"""
    if expected_type == "json":
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            return {"error": "Invalid JSON response"}
    
    elif expected_type == "number":
        try:
            return float(output)
        except ValueError:
            return None
    
    elif expected_type == "boolean":
        return output.lower() in ["true", "yes", "1"]
    
    else:  # string
        return str(output)
</code></pre>
<h2 id="building-a-tool-registry"><a class="header" href="#building-a-tool-registry">Building a Tool Registry</a></h2>
<p>Organize tools for easy management.</p>
<h3 id="simple-registry"><a class="header" href="#simple-registry">Simple Registry</a></h3>
<pre><code class="language-python">class ToolRegistry:
    """Manage available tools"""
    
    def __init__(self):
        self.tools = {}
    
    def register(self, name, function, schema):
        """Register a new tool"""
        self.tools[name] = {
            "function": function,
            "schema": schema
        }
    
    def get_tool(self, name):
        """Get tool by name"""
        return self.tools.get(name)
    
    def list_tools(self):
        """List all available tools"""
        return list(self.tools.keys())
    
    def get_schemas(self):
        """Get all tool schemas for LLM"""
        return [tool["schema"] for tool in self.tools.values()]
    
    def execute(self, name, params):
        """Execute a tool"""
        tool = self.get_tool(name)
        if not tool:
            raise ValueError(f"Tool not found: {name}")
        
        return tool["function"](params)

# Usage
registry = ToolRegistry()

# Register tools
registry.register(
    name="search",
    function=search_function,
    schema={
        "name": "search",
        "description": "Search the web",
        "parameters": {...}
    }
)

# Use in agent
schemas = registry.get_schemas()
result = registry.execute("search", {"query": "AI"})
</code></pre>
<h3 id="advanced-registry-with-decorators"><a class="header" href="#advanced-registry-with-decorators">Advanced Registry with Decorators</a></h3>
<pre><code class="language-python">class ToolRegistry:
    def __init__(self):
        self.tools = {}
    
    def tool(self, name, description, parameters):
        """Decorator to register tools"""
        def decorator(func):
            self.tools[name] = {
                "function": func,
                "schema": {
                    "name": name,
                    "description": description,
                    "parameters": parameters
                }
            }
            return func
        return decorator

# Create registry
registry = ToolRegistry()

# Register tools with decorator
@registry.tool(
    name="calculate",
    description="Evaluate mathematical expressions",
    parameters={
        "type": "object",
        "properties": {
            "expression": {"type": "string"}
        },
        "required": ["expression"]
    }
)
def calculate(expression):
    """Calculate mathematical expression"""
    return eval(expression)

@registry.tool(
    name="get_time",
    description="Get current time",
    parameters={"type": "object", "properties": {}}
)
def get_time():
    """Get current time"""
    from datetime import datetime
    return datetime.now().isoformat()
</code></pre>
<h2 id="complete-tool-integration-example"><a class="header" href="#complete-tool-integration-example">Complete Tool Integration Example</a></h2>
<pre><code class="language-python">import openai
import json
from typing import Dict, Any, List

class Agent:
    """Agent with integrated tool system"""
    
    def __init__(self, model="gpt-4"):
        self.client = openai.OpenAI()
        self.model = model
        self.registry = ToolRegistry()
        self._register_default_tools()
    
    def _register_default_tools(self):
        """Register built-in tools"""
        @self.registry.tool(
            name="search",
            description="Search for information",
            parameters={
                "type": "object",
                "properties": {
                    "query": {"type": "string"}
                },
                "required": ["query"]
            }
        )
        def search(query):
            # Implement search
            return f"Search results for: {query}"
        
        @self.registry.tool(
            name="calculate",
            description="Evaluate math expressions",
            parameters={
                "type": "object",
                "properties": {
                    "expression": {"type": "string"}
                },
                "required": ["expression"]
            }
        )
        def calculate(expression):
            try:
                return str(eval(expression))
            except Exception as e:
                return f"Error: {str(e)}"
    
    def run(self, user_input: str, max_steps: int = 10) -&gt; str:
        """Run agent with tool integration"""
        messages = [
            {"role": "system", "content": "You are a helpful assistant with access to tools."},
            {"role": "user", "content": user_input}
        ]
        
        for step in range(max_steps):
            # Call LLM with tools
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.registry.get_schemas(),
                tool_choice="auto"
            )
            
            message = response.choices[0].message
            messages.append(message)
            
            # Check if done
            if not message.tool_calls:
                return message.content
            
            # Execute tool calls
            for tool_call in message.tool_calls:
                function_name = tool_call.function.name
                arguments = json.loads(tool_call.function.arguments)
                
                # Execute tool
                result = self.registry.execute(function_name, arguments)
                
                # Add result to messages
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": str(result)
                })
        
        return "Max steps reached"

# Usage
agent = Agent()
response = agent.run("What is 25 * 17?")
print(response)
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<ol>
<li><strong>Clear naming</strong>: Use descriptive, unambiguous tool names</li>
<li><strong>Comprehensive descriptions</strong>: Help the LLM understand when to use each tool</li>
<li><strong>Validate everything</strong>: Check parameters before execution</li>
<li><strong>Handle errors gracefully</strong>: Return useful error messages</li>
<li><strong>Keep tools focused</strong>: One tool, one purpose</li>
<li><strong>Document examples</strong>: Show typical usage in descriptions</li>
<li><strong>Version your tools</strong>: Track changes to tool interfaces</li>
<li><strong>Test thoroughly</strong>: Verify tools work with various inputs</li>
</ol>
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<h3 id="conditional-tool-access"><a class="header" href="#conditional-tool-access">Conditional Tool Access</a></h3>
<pre><code class="language-python">def get_available_tools(user_role):
    """Return tools based on user permissions"""
    base_tools = ["search", "calculate"]
    
    if user_role == "admin":
        base_tools.extend(["delete_data", "modify_settings"])
    
    return [registry.get_tool(name) for name in base_tools]
</code></pre>
<h3 id="tool-chaining"><a class="header" href="#tool-chaining">Tool Chaining</a></h3>
<pre><code class="language-python"># Tools can call other tools
@registry.tool(name="research", ...)
def research(topic):
    # Search for information
    results = registry.execute("search", {"query": topic})
    
    # Summarize results
    summary = registry.execute("summarize", {"text": results})
    
    return summary
</code></pre>
<h3 id="async-tool-execution"><a class="header" href="#async-tool-execution">Async Tool Execution</a></h3>
<pre><code class="language-python">import asyncio

async def execute_tool_async(tool_name, params):
    """Execute tool asynchronously"""
    tool = registry.get_tool(tool_name)
    return await tool["function"](params)

# Execute multiple tools in parallel
results = await asyncio.gather(
    execute_tool_async("search", {"query": "AI"}),
    execute_tool_async("search", {"query": "ML"}),
    execute_tool_async("search", {"query": "agents"})
)
</code></pre>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<p>Now that you understand tool integration, letâ€™s build a complete hands-on project in the next section where youâ€™ll create a research assistant agent with multiple tools!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="hands-on-project-shopping-research-assistant"><a class="header" href="#hands-on-project-shopping-research-assistant">Hands-On Project: Shopping Research Assistant</a></h1>
<h2 id="project-overview"><a class="header" href="#project-overview">Project Overview</a></h2>
<p>Build a <strong>Shopping Research Assistant</strong> that helps users make informed purchasing decisions by:</p>
<ul>
<li>Searching for products across multiple sources</li>
<li>Comparing prices and features</li>
<li>Reading product reviews</li>
<li>Summarizing pros and cons</li>
<li>Providing recommendations with reasoning</li>
</ul>
<p>This project combines everything youâ€™ve learned: ReAct pattern, tool integration, multi-step reasoning, and error handling.</p>
<h2 id="what-youll-build"><a class="header" href="#what-youll-build">What Youâ€™ll Build</a></h2>
<p>An agent that can handle queries like:</p>
<ul>
<li>â€œFind the best laptop under $1000 for programmingâ€</li>
<li>â€œCompare noise-canceling headphonesâ€</li>
<li>â€œWhat are the top-rated coffee makers?â€</li>
<li>â€œShould I buy the iPhone 15 or Samsung S24?â€</li>
</ul>
<h2 id="project-setup"><a class="header" href="#project-setup">Project Setup</a></h2>
<h3 id="dependencies"><a class="header" href="#dependencies">Dependencies</a></h3>
<pre><code class="language-bash">pip install openai requests beautifulsoup4 python-dotenv
</code></pre>
<h3 id="project-structure"><a class="header" href="#project-structure">Project Structure</a></h3>
<pre><code>shopping_agent/
â”œâ”€â”€ agent.py           # Main agent implementation
â”œâ”€â”€ tools.py           # Tool definitions
â”œâ”€â”€ config.py          # Configuration
â”œâ”€â”€ .env              # API keys
â””â”€â”€ test_agent.py     # Test cases
</code></pre>
<h3 id="configuration"><a class="header" href="#configuration">Configuration</a></h3>
<pre><code class="language-python"># config.py
import os
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL = "gpt-4"
MAX_STEPS = 15
TEMPERATURE = 0.7
</code></pre>
<h2 id="implement-the-tools"><a class="header" href="#implement-the-tools">Implement the Tools</a></h2>
<h3 id="tool-1-product-search"><a class="header" href="#tool-1-product-search">Tool 1: Product Search</a></h3>
<pre><code class="language-python"># tools.py
import requests
from typing import Dict, List

def search_products(query: str, max_results: int = 5) -&gt; str:
    """
    Search for products matching the query.
    Returns product names, prices, and URLs.
    """
    try:
        # Using a mock API for demonstration
        # In production, use real APIs like Amazon Product API, eBay, etc.
        
        # Simulate search results
        results = [
            {
                "name": f"Product {i+1} for {query}",
                "price": f"${100 + i*50}",
                "rating": f"{4.0 + i*0.2:.1f}/5.0",
                "url": f"https://example.com/product-{i+1}"
            }
            for i in range(max_results)
        ]
        
        # Format results
        output = f"Found {len(results)} products:\n\n"
        for i, product in enumerate(results, 1):
            output += f"{i}. {product['name']}\n"
            output += f"   Price: {product['price']}\n"
            output += f"   Rating: {product['rating']}\n"
            output += f"   URL: {product['url']}\n\n"
        
        return output
    
    except Exception as e:
        return f"Error searching products: {str(e)}"


def search_products_real(query: str, max_results: int = 5) -&gt; str:
    """
    Real implementation using web search.
    Searches Google Shopping or similar.
    """
    try:
        # Example with Google Custom Search API
        api_key = os.getenv("GOOGLE_API_KEY")
        search_engine_id = os.getenv("GOOGLE_SEARCH_ENGINE_ID")
        
        url = "https://www.googleapis.com/customsearch/v1"
        params = {
            "key": api_key,
            "cx": search_engine_id,
            "q": query + " buy price",
            "num": max_results
        }
        
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        items = data.get("items", [])
        
        output = f"Found {len(items)} products:\n\n"
        for i, item in enumerate(items, 1):
            output += f"{i}. {item['title']}\n"
            output += f"   {item['snippet']}\n"
            output += f"   URL: {item['link']}\n\n"
        
        return output
    
    except Exception as e:
        return f"Error: {str(e)}"
</code></pre>
<h3 id="tool-2-get-product-details"><a class="header" href="#tool-2-get-product-details">Tool 2: Get Product Details</a></h3>
<pre><code class="language-python">from bs4 import BeautifulSoup

def get_product_details(url: str) -&gt; str:
    """
    Extract detailed information from a product page.
    Returns specs, description, and reviews summary.
    """
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Extract text (simplified)
        # In production, use specific selectors for each site
        text = soup.get_text(separator='\n', strip=True)
        
        # Limit length
        max_length = 2000
        if len(text) &gt; max_length:
            text = text[:max_length] + "..."
        
        return f"Product details from {url}:\n\n{text}"
    
    except Exception as e:
        return f"Error fetching product details: {str(e)}"
</code></pre>
<h3 id="tool-3-compare-products"><a class="header" href="#tool-3-compare-products">Tool 3: Compare Products</a></h3>
<pre><code class="language-python">def compare_products(product_list: str) -&gt; str:
    """
    Compare multiple products based on provided information.
    Input: Comma-separated product names or descriptions.
    Returns: Comparison table.
    """
    try:
        products = [p.strip() for p in product_list.split(',')]
        
        if len(products) &lt; 2:
            return "Error: Need at least 2 products to compare"
        
        output = "Product Comparison:\n\n"
        output += "To compare these products effectively, I need their details.\n"
        output += "Please use get_product_details for each product first.\n\n"
        output += f"Products to compare: {', '.join(products)}"
        
        return output
    
    except Exception as e:
        return f"Error comparing products: {str(e)}"
</code></pre>
<h3 id="tool-4-get-reviews-summary"><a class="header" href="#tool-4-get-reviews-summary">Tool 4: Get Reviews Summary</a></h3>
<pre><code class="language-python">def get_reviews_summary(product_name: str) -&gt; str:
    """
    Get a summary of customer reviews for a product.
    Returns common pros, cons, and overall sentiment.
    """
    try:
        # Mock implementation
        # In production, scrape from Amazon, Reddit, review sites
        
        reviews = {
            "overall_rating": "4.3/5.0",
            "total_reviews": 1247,
            "pros": [
                "Excellent build quality",
                "Great performance",
                "Good value for money"
            ],
            "cons": [
                "Battery life could be better",
                "Slightly heavy",
                "Limited color options"
            ],
            "common_themes": [
                "Users love the performance",
                "Some complaints about weight",
                "Generally recommended"
            ]
        }
        
        output = f"Reviews Summary for {product_name}:\n\n"
        output += f"Overall Rating: {reviews['overall_rating']} ({reviews['total_reviews']} reviews)\n\n"
        output += "Pros:\n"
        for pro in reviews['pros']:
            output += f"  âœ“ {pro}\n"
        output += "\nCons:\n"
        for con in reviews['cons']:
            output += f"  âœ— {con}\n"
        output += "\nCommon Themes:\n"
        for theme in reviews['common_themes']:
            output += f"  â€¢ {theme}\n"
        
        return output
    
    except Exception as e:
        return f"Error getting reviews: {str(e)}"
</code></pre>
<h3 id="tool-5-price-history"><a class="header" href="#tool-5-price-history">Tool 5: Price History</a></h3>
<pre><code class="language-python">def get_price_history(product_name: str) -&gt; str:
    """
    Get price history and trends for a product.
    Helps determine if current price is good.
    """
    try:
        # Mock implementation
        # In production, use CamelCamelCamel API, Keepa, etc.
        
        history = {
            "current_price": "$899",
            "lowest_price": "$799 (3 months ago)",
            "highest_price": "$999 (6 months ago)",
            "average_price": "$879",
            "trend": "stable",
            "recommendation": "Current price is close to average. Good time to buy."
        }
        
        output = f"Price History for {product_name}:\n\n"
        output += f"Current Price: {history['current_price']}\n"
        output += f"Lowest Price: {history['lowest_price']}\n"
        output += f"Highest Price: {history['highest_price']}\n"
        output += f"Average Price: {history['average_price']}\n"
        output += f"Trend: {history['trend']}\n\n"
        output += f"ğŸ’¡ {history['recommendation']}"
        
        return output
    
    except Exception as e:
        return f"Error getting price history: {str(e)}"
</code></pre>
<h2 id="build-the-agent"><a class="header" href="#build-the-agent">Build the Agent</a></h2>
<h3 id="tool-registry"><a class="header" href="#tool-registry">Tool Registry</a></h3>
<pre><code class="language-python"># agent.py
from tools import (
    search_products,
    get_product_details,
    compare_products,
    get_reviews_summary,
    get_price_history
)

class ShoppingAgent:
    """Shopping Research Assistant Agent"""
    
    def __init__(self):
        self.tools = self._create_tool_schemas()
        self.client = openai.OpenAI()
    
    def _create_tool_schemas(self):
        """Define tool schemas for OpenAI function calling"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "search_products",
                    "description": "Search for products matching a query. Use when user asks to find or search for products.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "Product search query (e.g., 'laptop under $1000')"
                            },
                            "max_results": {
                                "type": "integer",
                                "description": "Maximum number of results (default: 5)",
                                "default": 5
                            }
                        },
                        "required": ["query"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_product_details",
                    "description": "Get detailed information about a specific product from its URL.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "url": {
                                "type": "string",
                                "description": "Product page URL"
                            }
                        },
                        "required": ["url"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_reviews_summary",
                    "description": "Get summary of customer reviews including pros, cons, and ratings.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "product_name": {
                                "type": "string",
                                "description": "Product name"
                            }
                        },
                        "required": ["product_name"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_price_history",
                    "description": "Get price history and determine if current price is good.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "product_name": {
                                "type": "string",
                                "description": "Product name"
                            }
                        },
                        "required": ["product_name"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "compare_products",
                    "description": "Compare multiple products. Use after gathering details about each product.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "product_list": {
                                "type": "string",
                                "description": "Comma-separated list of product names"
                            }
                        },
                        "required": ["product_list"]
                    }
                }
            }
        ]
    
    def _execute_tool(self, tool_name: str, arguments: dict) -&gt; str:
        """Execute a tool and return result"""
        tool_map = {
            "search_products": search_products,
            "get_product_details": get_product_details,
            "compare_products": compare_products,
            "get_reviews_summary": get_reviews_summary,
            "get_price_history": get_price_history
        }
        
        if tool_name not in tool_map:
            return f"Error: Unknown tool {tool_name}"
        
        try:
            result = tool_map[tool_name](**arguments)
            return result
        except Exception as e:
            return f"Error executing {tool_name}: {str(e)}"
    
    def run(self, user_query: str, max_steps: int = 15) -&gt; str:
        """Run the shopping assistant agent"""
        messages = [
            {
                "role": "system",
                "content": """You are a helpful shopping research assistant. 
                
Your goal is to help users make informed purchasing decisions by:
1. Searching for relevant products
2. Gathering detailed information and reviews
3. Comparing options
4. Providing clear recommendations with reasoning

Always:
- Search for products before making recommendations
- Check reviews and ratings
- Consider price history when available
- Compare multiple options when relevant
- Cite specific information from your research
- Be honest about limitations

Format your final recommendation clearly with pros, cons, and reasoning."""
            },
            {"role": "user", "content": user_query}
        ]
        
        print(f"ğŸ›ï¸  User: {user_query}\n")
        
        for step in range(max_steps):
            # Get LLM response
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                tools=self.tools,
                tool_choice="auto",
                temperature=0.7
            )
            
            message = response.choices[0].message
            
            # If no tool calls, we're done
            if not message.tool_calls:
                print(f"ğŸ¤– Assistant: {message.content}\n")
                return message.content
            
            # Add assistant message
            messages.append(message)
            
            # Execute tool calls
            for tool_call in message.tool_calls:
                function_name = tool_call.function.name
                arguments = json.loads(tool_call.function.arguments)
                
                print(f"ğŸ”§ Using tool: {function_name}({arguments})")
                
                # Execute tool
                result = self._execute_tool(function_name, arguments)
                print(f"ğŸ“Š Result: {result[:200]}...\n")
                
                # Add tool result to messages
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": result
                })
        
        return "âš ï¸  Max steps reached without completing the task"
</code></pre>
<h2 id="complete-implementation"><a class="header" href="#complete-implementation">Complete Implementation</a></h2>
<pre><code class="language-python"># agent.py (complete file)
import openai
import json
from config import OPENAI_API_KEY, MODEL
from tools import (
    search_products,
    get_product_details,
    compare_products,
    get_reviews_summary,
    get_price_history
)

openai.api_key = OPENAI_API_KEY

# [ShoppingAgent class from above]

def main():
    """Test the shopping agent"""
    agent = ShoppingAgent()
    
    # Example queries
    queries = [
        "Find the best noise-canceling headphones under $300",
        "Compare iPhone 15 Pro and Samsung Galaxy S24",
        "What's a good coffee maker for home use?"
    ]
    
    for query in queries:
        print("=" * 60)
        result = agent.run(query)
        print("=" * 60)
        print()

if __name__ == "__main__":
    main()
</code></pre>
<h2 id="test-cases"><a class="header" href="#test-cases">Test Cases</a></h2>
<pre><code class="language-python"># test_agent.py
from agent import ShoppingAgent

def test_product_search():
    """Test basic product search"""
    agent = ShoppingAgent()
    result = agent.run("Find wireless keyboards under $50")
    assert "Product" in result or "keyboard" in result.lower()
    print("âœ“ Product search test passed")

def test_comparison():
    """Test product comparison"""
    agent = ShoppingAgent()
    result = agent.run("Compare MacBook Air vs Dell XPS 13")
    assert len(result) &gt; 100  # Should have substantial response
    print("âœ“ Comparison test passed")

def test_reviews():
    """Test review gathering"""
    agent = ShoppingAgent()
    result = agent.run("What do people say about AirPods Pro?")
    assert "review" in result.lower() or "rating" in result.lower()
    print("âœ“ Reviews test passed")

if __name__ == "__main__":
    test_product_search()
    test_comparison()
    test_reviews()
    print("\nâœ… All tests passed!")
</code></pre>
<h2 id="debug-common-issues"><a class="header" href="#debug-common-issues">Debug Common Issues</a></h2>
<h3 id="issue-1-agent-doesnt-use-tools"><a class="header" href="#issue-1-agent-doesnt-use-tools">Issue 1: Agent Doesnâ€™t Use Tools</a></h3>
<p><strong>Problem</strong>: Agent responds without searching</p>
<p><strong>Solution</strong>: Strengthen system prompt</p>
<pre><code class="language-python">"You MUST use the search_products tool before making any recommendations.
Never rely on prior knowledge about products or prices."
</code></pre>
<h3 id="issue-2-infinite-search-loop"><a class="header" href="#issue-2-infinite-search-loop">Issue 2: Infinite Search Loop</a></h3>
<p><strong>Problem</strong>: Agent keeps searching without concluding</p>
<p><strong>Solution</strong>: Add step tracking and guidance</p>
<pre><code class="language-python"># Track tool usage
tool_usage = {}
if tool_name in tool_usage:
    tool_usage[tool_name] += 1
    if tool_usage[tool_name] &gt; 3:
        return "You've used this tool multiple times. Please synthesize your findings."
</code></pre>
<h3 id="issue-3-hallucinated-product-info"><a class="header" href="#issue-3-hallucinated-product-info">Issue 3: Hallucinated Product Info</a></h3>
<p><strong>Problem</strong>: Agent invents product details</p>
<p><strong>Solution</strong>: Emphasize tool-only information</p>
<pre><code class="language-python">"CRITICAL: Only use information from tool results. 
If a tool doesn't return information, say so explicitly.
Never make up product names, prices, or specifications."
</code></pre>
<h3 id="issue-4-poor-recommendations"><a class="header" href="#issue-4-poor-recommendations">Issue 4: Poor Recommendations</a></h3>
<p><strong>Problem</strong>: Recommendations lack depth</p>
<p><strong>Solution</strong>: Add structured output requirement</p>
<pre><code class="language-python">"Format your final recommendation as:

**Recommendation**: [Product name]

**Why**: [2-3 key reasons]

**Pros**:
- [Pro 1]
- [Pro 2]

**Cons**:
- [Con 1]
- [Con 2]

**Price**: [Current price and value assessment]"
</code></pre>
<h2 id="enhancements"><a class="header" href="#enhancements">Enhancements</a></h2>
<h3 id="1-add-budget-tracking"><a class="header" href="#1-add-budget-tracking">1. Add Budget Tracking</a></h3>
<pre><code class="language-python">def check_budget(price: str, budget: float) -&gt; bool:
    """Check if price is within budget"""
    # Extract numeric price
    price_num = float(price.replace('$', '').replace(',', ''))
    return price_num &lt;= budget
</code></pre>
<h3 id="2-save-research-sessions"><a class="header" href="#2-save-research-sessions">2. Save Research Sessions</a></h3>
<pre><code class="language-python">def save_research(query: str, results: str):
    """Save research for later reference"""
    with open(f"research_{timestamp}.txt", "w") as f:
        f.write(f"Query: {query}\n\n{results}")
</code></pre>
<h3 id="3-multi-store-price-comparison"><a class="header" href="#3-multi-store-price-comparison">3. Multi-Store Price Comparison</a></h3>
<pre><code class="language-python">def compare_prices_across_stores(product: str) -&gt; dict:
    """Check prices at Amazon, Walmart, Best Buy, etc."""
    stores = ["Amazon", "Walmart", "Best Buy"]
    prices = {}
    for store in stores:
        prices[store] = search_store_price(store, product)
    return prices
</code></pre>
<h3 id="4-deal-alerts"><a class="header" href="#4-deal-alerts">4. Deal Alerts</a></h3>
<pre><code class="language-python">def check_for_deals(product: str) -&gt; str:
    """Check if product is on sale or has coupons"""
    # Check deal sites, coupon codes, etc.
    pass
</code></pre>
<h3 id="5-personalization"><a class="header" href="#5-personalization">5. Personalization</a></h3>
<pre><code class="language-python">def get_user_preferences() -&gt; dict:
    """Load user preferences (brands, price range, features)"""
    return {
        "preferred_brands": ["Sony", "Apple"],
        "max_price": 500,
        "must_have_features": ["wireless", "noise-canceling"]
    }
</code></pre>
<h2 id="next-steps-4"><a class="header" href="#next-steps-4">Next Steps</a></h2>
<p>Congratulations! Youâ€™ve built a complete shopping research assistant. You now understand:</p>
<ul>
<li>âœ… ReAct pattern implementation</li>
<li>âœ… Tool integration and validation</li>
<li>âœ… Multi-step reasoning</li>
<li>âœ… Error handling and debugging</li>
<li>âœ… Real-world agent applications</li>
</ul>
<p>In Chapter 3, weâ€™ll explore advanced agent patterns including planning, memory systems, and multi-agent collaboration!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="planning-agents"><a class="header" href="#planning-agents">Planning Agents</a></h1>
<h2 id="module-3-learning-objectives"><a class="header" href="#module-3-learning-objectives">Module 3: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Implement planning algorithms (Chain-of-Thought, task decomposition)</li>
<li>âœ“ Build memory systems (short-term, long-term, semantic)</li>
<li>âœ“ Create multi-agent systems with collaboration patterns</li>
<li>âœ“ Understand when to use planning vs reactive approaches</li>
<li>âœ“ Design agent communication protocols</li>
</ul>
<hr>
<h2 id="introduction-to-planning"><a class="header" href="#introduction-to-planning">Introduction to Planning</a></h2>
<p>Simple ReAct agents decide one step at a time. <strong>Planning agents</strong> think aheadâ€”they create a multi-step plan before executing, leading to more efficient and coherent task completion.</p>
<h3 id="why-planning-matters"><a class="header" href="#why-planning-matters">Why Planning Matters</a></h3>
<pre><code class="language-mermaid">graph TB
    subgraph "Without Planning"
    A1[Search flights] --&gt; A2[Search hotels]
    A2 --&gt; A3[Dates don't match!]
    A3 --&gt; A4[Search flights again]
    A4 --&gt; A5[Search hotels again]
    end
    
    subgraph "With Planning"
    B1[Plan all steps] --&gt; B2[Determine dates]
    B2 --&gt; B3[Search flights]
    B3 --&gt; B4[Search hotels]
    B4 --&gt; B5[Done efficiently]
    end
    
    style A3 fill:#fee2e2
    style B5 fill:#d1fae5
</code></pre>
<p><strong>Without Planning (Reactive)</strong>:</p>
<ul>
<li>Search flights â†’ Search hotels â†’ Dates mismatch â†’ Redo everything</li>
<li>Inefficient, multiple retries</li>
</ul>
<p><strong>With Planning (Proactive)</strong>:</p>
<ul>
<li>Plan: dates â†’ flights â†’ hotels â†’ booking</li>
<li>Execute efficiently in one pass</li>
</ul>
<blockquote>
<p><strong>âš ï¸ When to Use Planning</strong></p>
<p>Use planning for:</p>
<ul>
<li>Multi-step tasks with dependencies</li>
<li>Tasks requiring coordination</li>
<li>Resource-constrained scenarios</li>
</ul>
<p>Skip planning for:</p>
<ul>
<li>Simple single-step tasks</li>
<li>Highly dynamic environments</li>
<li>When speed is critical</li>
</ul>
</blockquote>
<h2 id="chain-of-thought-reasoning"><a class="header" href="#chain-of-thought-reasoning">Chain-of-Thought Reasoning</a></h2>
<p>Chain-of-Thought (CoT) prompting encourages step-by-step reasoning.</p>
<h3 id="basic-cot"><a class="header" href="#basic-cot">Basic CoT</a></h3>
<pre><code class="language-python">SYSTEM_PROMPT = """When solving problems, think step by step:

1. Understand the problem
2. Break it into sub-problems
3. Solve each sub-problem
4. Combine solutions

Example:
User: "I need to prepare for a camping trip next weekend"

Thought: Let me break this down:
1. Determine what items are needed for camping
2. Check what the user already has
3. Create a shopping list for missing items
4. Suggest where to buy them

Now I'll execute this plan..."""
</code></pre>
<h3 id="zero-shot-cot"><a class="header" href="#zero-shot-cot">Zero-Shot CoT</a></h3>
<p>Simply add â€œLetâ€™s think step by stepâ€:</p>
<pre><code class="language-python">def zero_shot_cot(query):
    """Use zero-shot chain of thought"""
    prompt = f"{query}\n\nLet's think step by step:"
    return llm.generate(prompt)
</code></pre>
<h3 id="few-shot-cot"><a class="header" href="#few-shot-cot">Few-Shot CoT</a></h3>
<p>Provide examples of step-by-step reasoning:</p>
<pre><code class="language-python">FEW_SHOT_EXAMPLES = """
Example 1:
User: "Plan a birthday party for 20 people"
Reasoning:
1. Determine budget and venue
2. Create guest list (20 people)
3. Choose date and send invitations
4. Plan menu and order food
5. Arrange entertainment and decorations
6. Prepare day-of schedule

Example 2:
User: "Debug why my website is slow"
Reasoning:
1. Measure current performance metrics
2. Identify bottlenecks (database, network, code)
3. Prioritize issues by impact
4. Fix highest-impact issues first
5. Re-measure to verify improvements
"""
</code></pre>
<h2 id="task-decomposition"><a class="header" href="#task-decomposition">Task Decomposition</a></h2>
<p>Breaking complex tasks into manageable subtasks.</p>
<h3 id="hierarchical-decomposition"><a class="header" href="#hierarchical-decomposition">Hierarchical Decomposition</a></h3>
<pre><code class="language-python">def decompose_task(task: str) -&gt; dict:
    """Decompose task into hierarchy"""
    prompt = f"""Break down this task into subtasks:

Task: {task}

Format as:
Main Goal: [goal]
Subtasks:
1. [subtask 1]
   1.1 [sub-subtask]
   1.2 [sub-subtask]
2. [subtask 2]
3. [subtask 3]
"""
    
    response = llm.generate(prompt)
    return parse_task_hierarchy(response)

# Example output
{
    "goal": "Launch a new product",
    "subtasks": [
        {
            "id": 1,
            "task": "Market research",
            "subtasks": [
                {"id": 1.1, "task": "Identify target audience"},
                {"id": 1.2, "task": "Analyze competitors"}
            ]
        },
        {
            "id": 2,
            "task": "Product development"
        },
        {
            "id": 3,
            "task": "Marketing campaign"
        }
    ]
}
</code></pre>
<h3 id="dependency-aware-decomposition"><a class="header" href="#dependency-aware-decomposition">Dependency-Aware Decomposition</a></h3>
<pre><code class="language-python">class Task:
    def __init__(self, name, dependencies=None):
        self.name = name
        self.dependencies = dependencies or []
        self.status = "pending"

def create_task_graph(goal: str) -&gt; List[Task]:
    """Create task graph with dependencies"""
    tasks = [
        Task("Research market", dependencies=[]),
        Task("Design product", dependencies=["Research market"]),
        Task("Build prototype", dependencies=["Design product"]),
        Task("Test prototype", dependencies=["Build prototype"]),
        Task("Launch", dependencies=["Test prototype", "Marketing ready"])
    ]
    return tasks

def get_executable_tasks(tasks: List[Task]) -&gt; List[Task]:
    """Get tasks that can be executed now"""
    return [
        task for task in tasks
        if task.status == "pending" and
        all(dep.status == "completed" for dep in task.dependencies)
    ]
</code></pre>
<h2 id="plan-and-execute-frameworks"><a class="header" href="#plan-and-execute-frameworks">Plan-and-Execute Frameworks</a></h2>
<p>Separate planning from execution for better control.</p>
<h3 id="basic-plan-and-execute"><a class="header" href="#basic-plan-and-execute">Basic Plan-and-Execute</a></h3>
<pre><code class="language-python">class PlanExecuteAgent:
    """Agent that plans first, then executes"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.tools = self._load_tools()
    
    def plan(self, goal: str) -&gt; List[str]:
        """Create execution plan"""
        prompt = f"""Create a detailed plan to accomplish this goal:

Goal: {goal}

Available tools: {', '.join(self.tools.keys())}

Provide a numbered list of steps. Each step should:
- Be specific and actionable
- Use available tools
- Build on previous steps

Plan:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        plan_text = response.choices[0].message.content
        steps = self._parse_plan(plan_text)
        return steps
    
    def execute(self, steps: List[str]) -&gt; str:
        """Execute plan steps"""
        results = []
        
        for i, step in enumerate(steps, 1):
            print(f"Executing step {i}: {step}")
            
            # Use ReAct agent to execute each step
            result = self._execute_step(step)
            results.append(result)
            
            # Check if we should continue
            if self._should_replan(result):
                print("Replanning needed...")
                remaining = steps[i:]
                new_plan = self.plan(f"Complete: {', '.join(remaining)}")
                steps = steps[:i] + new_plan
        
        return self._synthesize_results(results)
    
    def run(self, goal: str) -&gt; str:
        """Plan and execute"""
        print(f"Goal: {goal}\n")
        
        # Create plan
        plan = self.plan(goal)
        print("Plan:")
        for i, step in enumerate(plan, 1):
            print(f"  {i}. {step}")
        print()
        
        # Execute plan
        result = self.execute(plan)
        return result
</code></pre>
<h3 id="example-usage"><a class="header" href="#example-usage">Example Usage</a></h3>
<pre><code class="language-python">agent = PlanExecuteAgent()

result = agent.run(
    "Research electric cars under $40k and create a comparison report"
)

# Output:
# Goal: Research electric cars under $40k and create a comparison report
# 
# Plan:
#   1. Search for electric cars priced under $40,000
#   2. Get detailed specs for top 5 models
#   3. Compare range, charging time, and features
#   4. Check customer reviews for each model
#   5. Create structured comparison report
#
# Executing step 1: Search for electric cars...
# Executing step 2: Get detailed specs...
# ...
</code></pre>
<h2 id="replanning-and-adaptation"><a class="header" href="#replanning-and-adaptation">Replanning and Adaptation</a></h2>
<p>Plans often need adjustment based on results.</p>
<h3 id="when-to-replan"><a class="header" href="#when-to-replan">When to Replan</a></h3>
<pre><code class="language-python">def should_replan(step_result: str, original_plan: List[str]) -&gt; bool:
    """Determine if replanning is needed"""
    
    # Error occurred
    if "error" in step_result.lower():
        return True
    
    # Unexpected result
    if "not found" in step_result.lower():
        return True
    
    # New information changes approach
    if "alternative" in step_result.lower():
        return True
    
    return False
</code></pre>
<h3 id="replanning-strategies"><a class="header" href="#replanning-strategies">Replanning Strategies</a></h3>
<p><strong>1. Full Replan</strong>: Start over with new information</p>
<pre><code class="language-python">def full_replan(goal: str, context: str) -&gt; List[str]:
    """Create entirely new plan"""
    prompt = f"""Original goal: {goal}
    
Context from execution so far:
{context}

Create a new plan considering this context:"""
    
    return create_plan(prompt)
</code></pre>
<p><strong>2. Partial Replan</strong>: Adjust remaining steps</p>
<pre><code class="language-python">def partial_replan(remaining_steps: List[str], issue: str) -&gt; List[str]:
    """Adjust remaining steps"""
    prompt = f"""We encountered an issue: {issue}
    
Remaining steps were:
{format_steps(remaining_steps)}

Adjust the plan to work around this issue:"""
    
    return create_plan(prompt)
</code></pre>
<p><strong>3. Alternative Path</strong>: Try different approach</p>
<pre><code class="language-python">def find_alternative(failed_step: str, goal: str) -&gt; str:
    """Find alternative way to accomplish step"""
    prompt = f"""This step failed: {failed_step}
    
Goal: {goal}

Suggest an alternative approach:"""
    
    return llm.generate(prompt)
</code></pre>
<h3 id="adaptive-planning-agent"><a class="header" href="#adaptive-planning-agent">Adaptive Planning Agent</a></h3>
<pre><code class="language-python">class AdaptivePlanningAgent:
    """Agent that adapts plan based on execution"""
    
    def __init__(self, max_replans=3):
        self.max_replans = max_replans
        self.replan_count = 0
    
    def execute_with_adaptation(self, goal: str) -&gt; str:
        """Execute with adaptive replanning"""
        plan = self.plan(goal)
        context = []
        
        i = 0
        while i &lt; len(plan):
            step = plan[i]
            
            # Execute step
            result = self.execute_step(step)
            context.append({"step": step, "result": result})
            
            # Check if replanning needed
            if self.should_replan(result):
                if self.replan_count &gt;= self.max_replans:
                    return "Max replans reached. Unable to complete goal."
                
                # Replan remaining steps
                remaining_goal = self.extract_remaining_goal(plan[i+1:])
                new_steps = self.replan(remaining_goal, context)
                
                # Update plan
                plan = plan[:i+1] + new_steps
                self.replan_count += 1
                
                print(f"ğŸ”„ Replanned ({self.replan_count}/{self.max_replans})")
            
            i += 1
        
        return self.synthesize_results(context)
</code></pre>
<h2 id="plan-representation-1"><a class="header" href="#plan-representation-1">Plan Representation</a></h2>
<p>Different ways to represent plans.</p>
<h3 id="linear-plan"><a class="header" href="#linear-plan">Linear Plan</a></h3>
<pre><code class="language-python">plan = [
    "Step 1: Search for products",
    "Step 2: Compare prices",
    "Step 3: Read reviews",
    "Step 4: Make recommendation"
]
</code></pre>
<h3 id="tree-plan"><a class="header" href="#tree-plan">Tree Plan</a></h3>
<pre><code class="language-python">plan = {
    "root": "Research product",
    "branches": [
        {
            "node": "Gather information",
            "branches": [
                {"node": "Search products"},
                {"node": "Get specifications"}
            ]
        },
        {
            "node": "Analyze",
            "branches": [
                {"node": "Compare features"},
                {"node": "Check reviews"}
            ]
        },
        {
            "node": "Recommend"}
    ]
}
</code></pre>
<h3 id="graph-plan"><a class="header" href="#graph-plan">Graph Plan</a></h3>
<pre><code class="language-python">from dataclasses import dataclass
from typing import List, Set

@dataclass
class PlanNode:
    id: str
    action: str
    dependencies: Set[str]
    status: str = "pending"

plan_graph = [
    PlanNode("1", "Search products", set()),
    PlanNode("2", "Get details A", {"1"}),
    PlanNode("3", "Get details B", {"1"}),
    PlanNode("4", "Compare", {"2", "3"}),
    PlanNode("5", "Recommend", {"4"})
]

def get_ready_nodes(graph: List[PlanNode]) -&gt; List[PlanNode]:
    """Get nodes ready to execute"""
    completed = {n.id for n in graph if n.status == "completed"}
    
    return [
        node for node in graph
        if node.status == "pending" and
        node.dependencies.issubset(completed)
    ]
</code></pre>
<h2 id="advanced-planning-techniques"><a class="header" href="#advanced-planning-techniques">Advanced Planning Techniques</a></h2>
<h3 id="backward-chaining"><a class="header" href="#backward-chaining">Backward Chaining</a></h3>
<p>Start from goal and work backwards:</p>
<pre><code class="language-python">def backward_chain(goal: str, current_state: dict) -&gt; List[str]:
    """Plan by working backwards from goal"""
    
    plan = []
    current_goal = goal
    
    while not is_satisfied(current_goal, current_state):
        # What's needed to achieve current_goal?
        prerequisite = find_prerequisite(current_goal)
        plan.insert(0, prerequisite)
        current_goal = prerequisite
    
    return plan

# Example
goal = "Have dinner ready"
# Backward chain:
# "Have dinner ready" requires "Food is cooked"
# "Food is cooked" requires "Ingredients prepared"
# "Ingredients prepared" requires "Groceries purchased"
# Plan: [Buy groceries, Prepare ingredients, Cook food]
</code></pre>
<h3 id="hierarchical-task-network-htn"><a class="header" href="#hierarchical-task-network-htn">Hierarchical Task Network (HTN)</a></h3>
<pre><code class="language-python">class HTNPlanner:
    """Hierarchical Task Network planner"""
    
    def __init__(self):
        self.methods = {
            "travel_to_city": [
                ["book_flight", "take_flight"],
                ["book_train", "take_train"],
                ["rent_car", "drive"]
            ],
            "book_flight": [
                ["search_flights", "select_flight", "pay"]
            ]
        }
    
    def decompose(self, task: str) -&gt; List[str]:
        """Decompose high-level task"""
        if task not in self.methods:
            return [task]  # Primitive task
        
        # Choose best method
        method = self.select_method(task)
        
        # Recursively decompose
        plan = []
        for subtask in method:
            plan.extend(self.decompose(subtask))
        
        return plan
</code></pre>
<h3 id="monte-carlo-tree-search-mcts-for-planning"><a class="header" href="#monte-carlo-tree-search-mcts-for-planning">Monte Carlo Tree Search (MCTS) for Planning</a></h3>
<pre><code class="language-python">class MCTSPlanner:
    """Use MCTS to find optimal plan"""
    
    def plan(self, goal: str, num_simulations: int = 100):
        """Find plan using MCTS"""
        root = Node(state=initial_state, goal=goal)
        
        for _ in range(num_simulations):
            # Selection
            node = self.select(root)
            
            # Expansion
            if not node.is_terminal():
                node = self.expand(node)
            
            # Simulation
            reward = self.simulate(node)
            
            # Backpropagation
            self.backpropagate(node, reward)
        
        # Return best path
        return self.best_path(root)
</code></pre>
<h2 id="practical-planning-agent"><a class="header" href="#practical-planning-agent">Practical Planning Agent</a></h2>
<pre><code class="language-python">class PracticalPlanningAgent:
    """Production-ready planning agent"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.max_steps = 20
        self.max_replans = 3
    
    def run(self, goal: str) -&gt; str:
        """Execute goal with planning"""
        
        # 1. Create initial plan
        plan = self.create_plan(goal)
        print("ğŸ“‹ Initial Plan:")
        for i, step in enumerate(plan, 1):
            print(f"   {i}. {step}")
        print()
        
        # 2. Execute with monitoring
        results = []
        replan_count = 0
        
        for i, step in enumerate(plan):
            print(f"â–¶ï¸  Step {i+1}/{len(plan)}: {step}")
            
            # Execute step
            result = self.execute_step(step, results)
            results.append({"step": step, "result": result})
            
            # Check success
            if self.is_failure(result):
                if replan_count &gt;= self.max_replans:
                    return self.handle_failure(goal, results)
                
                # Replan
                print(f"âš ï¸  Step failed, replanning...")
                new_plan = self.replan(goal, plan[i+1:], results)
                plan = plan[:i+1] + new_plan
                replan_count += 1
            
            print(f"âœ“ Completed\n")
        
        # 3. Synthesize final result
        return self.synthesize(goal, results)
    
    def create_plan(self, goal: str) -&gt; List[str]:
        """Create execution plan"""
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"""Create a step-by-step plan for: {goal}

Requirements:
- Each step should be specific and actionable
- Steps should build on each other logically
- Include verification steps
- Keep it concise (max 10 steps)

Format as numbered list."""
            }],
            temperature=0.3
        )
        
        return self.parse_plan(response.choices[0].message.content)
</code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<ol>
<li><strong>Plan at the right level</strong>: Not too detailed, not too vague</li>
<li><strong>Include verification</strong>: Check if steps succeeded</li>
<li><strong>Be flexible</strong>: Allow replanning when needed</li>
<li><strong>Consider dependencies</strong>: Respect task ordering</li>
<li><strong>Set limits</strong>: Max steps, max replans</li>
<li><strong>Monitor progress</strong>: Track whatâ€™s completed</li>
<li><strong>Learn from failures</strong>: Improve planning over time</li>
</ol>
<hr>
<blockquote>
<p><strong>âœ… Key Takeaways</strong></p>
<ul>
<li>Planning agents create multi-step plans before executing</li>
<li>Chain-of-Thought enables step-by-step reasoning</li>
<li>Task decomposition breaks complex goals into manageable steps</li>
<li>Plan-and-Execute pattern separates planning from execution</li>
<li>Replanning allows adaptation when plans fail</li>
<li>Use planning for complex, multi-step tasks with dependencies</li>
</ul>
</blockquote>
<h2 id="next-steps-5"><a class="header" href="#next-steps-5">Next Steps</a></h2>
<p>You now understand planning agents! Next, weâ€™ll explore memory systems that allow agents to remember and learn from past interactions.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="memory-systems-1"><a class="header" href="#memory-systems-1">Memory Systems</a></h1>
<h2 id="why-agents-need-memory"><a class="header" href="#why-agents-need-memory">Why Agents Need Memory</a></h2>
<p>Without memory, agents are like people with amnesiaâ€”they canâ€™t learn from experience, maintain context, or build on previous interactions.</p>
<p><strong>Without Memory</strong>:</p>
<pre><code>User: "My name is Alice"
Agent: "Nice to meet you!"
[Later]
User: "What's my name?"
Agent: "I don't know your name."
</code></pre>
<p><strong>With Memory</strong>:</p>
<pre><code>User: "My name is Alice"
Agent: "Nice to meet you, Alice!" [stores: user_name = "Alice"]
[Later]
User: "What's my name?"
Agent: "Your name is Alice." [retrieves: user_name]
</code></pre>
<h2 id="types-of-memory"><a class="header" href="#types-of-memory">Types of Memory</a></h2>
<h3 id="short-term-memory-working-memory-1"><a class="header" href="#short-term-memory-working-memory-1">Short-Term Memory (Working Memory)</a></h3>
<p>Temporary storage for the current task.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Limited capacity (context window)</li>
<li>Cleared after task completion</li>
<li>Fast access</li>
<li>Stored in conversation history</li>
</ul>
<p><strong>What to store</strong>:</p>
<ul>
<li>Current conversation</li>
<li>Intermediate results</li>
<li>Active plan</li>
<li>Tool outputs</li>
</ul>
<h3 id="long-term-memory-persistent-memory-1"><a class="header" href="#long-term-memory-persistent-memory-1">Long-Term Memory (Persistent Memory)</a></h3>
<p>Permanent storage across sessions.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Unlimited capacity (database)</li>
<li>Persists across sessions</li>
<li>Slower access (requires retrieval)</li>
<li>Stored in external systems</li>
</ul>
<p><strong>What to store</strong>:</p>
<ul>
<li>User preferences</li>
<li>Past conversations</li>
<li>Learned facts</li>
<li>Successful strategies</li>
</ul>
<h2 id="conversation-history-management"><a class="header" href="#conversation-history-management">Conversation History Management</a></h2>
<p>Managing the conversation context efficiently.</p>
<h3 id="basic-history-tracking"><a class="header" href="#basic-history-tracking">Basic History Tracking</a></h3>
<pre><code class="language-python">class ConversationMemory:
    """Simple conversation history"""
    
    def __init__(self, max_messages=20):
        self.messages = []
        self.max_messages = max_messages
    
    def add_message(self, role: str, content: str):
        """Add message to history"""
        self.messages.append({
            "role": role,
            "content": content,
            "timestamp": time.time()
        })
        
        # Trim if too long
        if len(self.messages) &gt; self.max_messages:
            self.messages = self.messages[-self.max_messages:]
    
    def get_messages(self) -&gt; List[dict]:
        """Get conversation history"""
        return self.messages
    
    def clear(self):
        """Clear history"""
        self.messages = []
</code></pre>
<h3 id="sliding-window"><a class="header" href="#sliding-window">Sliding Window</a></h3>
<p>Keep only recent messages:</p>
<pre><code class="language-python">class SlidingWindowMemory:
    """Keep last N messages"""
    
    def __init__(self, window_size=10):
        self.window_size = window_size
        self.messages = []
    
    def add(self, message: dict):
        """Add message and maintain window"""
        self.messages.append(message)
        
        # Keep only last N messages
        if len(self.messages) &gt; self.window_size:
            self.messages = self.messages[-self.window_size:]
    
    def get_context(self) -&gt; List[dict]:
        """Get current window"""
        return self.messages
</code></pre>
<h3 id="token-based-truncation"><a class="header" href="#token-based-truncation">Token-Based Truncation</a></h3>
<p>Manage by token count instead of message count:</p>
<pre><code class="language-python">import tiktoken

class TokenAwareMemory:
    """Manage memory by token budget"""
    
    def __init__(self, max_tokens=4000, model="gpt-4"):
        self.max_tokens = max_tokens
        self.messages = []
        self.encoding = tiktoken.encoding_for_model(model)
    
    def count_tokens(self, text: str) -&gt; int:
        """Count tokens in text"""
        return len(self.encoding.encode(text))
    
    def get_total_tokens(self) -&gt; int:
        """Count total tokens in history"""
        total = 0
        for msg in self.messages:
            total += self.count_tokens(msg["content"])
        return total
    
    def add(self, message: dict):
        """Add message and trim if needed"""
        self.messages.append(message)
        
        # Trim oldest messages if over budget
        while self.get_total_tokens() &gt; self.max_tokens and len(self.messages) &gt; 1:
            self.messages.pop(0)  # Remove oldest
    
    def get_context(self) -&gt; List[dict]:
        """Get messages within token budget"""
        return self.messages
</code></pre>
<h3 id="summarization-strategy"><a class="header" href="#summarization-strategy">Summarization Strategy</a></h3>
<p>Compress old messages:</p>
<pre><code class="language-python">class SummarizingMemory:
    """Summarize old conversations"""
    
    def __init__(self, summary_threshold=20):
        self.messages = []
        self.summary = None
        self.summary_threshold = summary_threshold
    
    def add(self, message: dict):
        """Add message and summarize if needed"""
        self.messages.append(message)
        
        if len(self.messages) &gt; self.summary_threshold:
            self.summarize_old_messages()
    
    def summarize_old_messages(self):
        """Summarize and compress old messages"""
        # Take first half of messages
        to_summarize = self.messages[:len(self.messages)//2]
        
        # Create summary
        summary_text = self.create_summary(to_summarize)
        
        # Update summary
        if self.summary:
            self.summary += f"\n\n{summary_text}"
        else:
            self.summary = summary_text
        
        # Keep only recent messages
        self.messages = self.messages[len(self.messages)//2:]
    
    def create_summary(self, messages: List[dict]) -&gt; str:
        """Generate summary of messages"""
        conversation = "\n".join([
            f"{m['role']}: {m['content']}" for m in messages
        ])
        
        prompt = f"""Summarize this conversation concisely:

{conversation}

Summary:"""
        
        return llm.generate(prompt)
    
    def get_context(self) -&gt; List[dict]:
        """Get context with summary"""
        context = []
        
        if self.summary:
            context.append({
                "role": "system",
                "content": f"Previous conversation summary:\n{self.summary}"
            })
        
        context.extend(self.messages)
        return context
</code></pre>
<h2 id="vector-databases-for-semantic-memory"><a class="header" href="#vector-databases-for-semantic-memory">Vector Databases for Semantic Memory</a></h2>
<p>Store and retrieve information by meaning, not just keywords.</p>
<h3 id="why-vector-databases"><a class="header" href="#why-vector-databases">Why Vector Databases?</a></h3>
<p>Traditional search: â€œFind messages containing â€˜Pythonâ€™â€
Semantic search: â€œFind messages about programming languagesâ€</p>
<h3 id="basic-vector-memory"><a class="header" href="#basic-vector-memory">Basic Vector Memory</a></h3>
<pre><code class="language-python">import numpy as np
from typing import List, Tuple

class VectorMemory:
    """Simple vector-based memory"""
    
    def __init__(self):
        self.memories = []
        self.embeddings = []
    
    def add(self, text: str, metadata: dict = None):
        """Store memory with embedding"""
        # Get embedding
        embedding = self.get_embedding(text)
        
        self.memories.append({
            "text": text,
            "metadata": metadata or {},
            "timestamp": time.time()
        })
        self.embeddings.append(embedding)
    
    def get_embedding(self, text: str) -&gt; np.ndarray:
        """Get embedding for text"""
        # Using OpenAI embeddings
        response = openai.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return np.array(response.data[0].embedding)
    
    def search(self, query: str, top_k: int = 5) -&gt; List[dict]:
        """Search for relevant memories"""
        if not self.memories:
            return []
        
        # Get query embedding
        query_embedding = self.get_embedding(query)
        
        # Calculate similarities
        similarities = []
        for i, emb in enumerate(self.embeddings):
            similarity = self.cosine_similarity(query_embedding, emb)
            similarities.append((i, similarity))
        
        # Sort by similarity
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # Return top k
        results = []
        for i, score in similarities[:top_k]:
            result = self.memories[i].copy()
            result["similarity"] = score
            results.append(result)
        
        return results
    
    def cosine_similarity(self, a: np.ndarray, b: np.ndarray) -&gt; float:
        """Calculate cosine similarity"""
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
</code></pre>
<h3 id="using-chroma"><a class="header" href="#using-chroma">Using Chroma</a></h3>
<pre><code class="language-python">import chromadb
from chromadb.config import Settings

class ChromaMemory:
    """Memory using ChromaDB"""
    
    def __init__(self, collection_name="agent_memory"):
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory="./chroma_db"
        ))
        
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"description": "Agent memory storage"}
        )
    
    def add(self, text: str, metadata: dict = None):
        """Add memory"""
        doc_id = f"mem_{int(time.time() * 1000)}"
        
        self.collection.add(
            documents=[text],
            metadatas=[metadata or {}],
            ids=[doc_id]
        )
    
    def search(self, query: str, n_results: int = 5) -&gt; List[dict]:
        """Search memories"""
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results
        )
        
        memories = []
        for i in range(len(results['documents'][0])):
            memories.append({
                "text": results['documents'][0][i],
                "metadata": results['metadatas'][0][i],
                "distance": results['distances'][0][i]
            })
        
        return memories
    
    def delete_all(self):
        """Clear all memories"""
        self.client.delete_collection(self.collection.name)
</code></pre>
<h3 id="using-pinecone"><a class="header" href="#using-pinecone">Using Pinecone</a></h3>
<pre><code class="language-python">import pinecone

class PineconeMemory:
    """Memory using Pinecone"""
    
    def __init__(self, index_name="agent-memory"):
        pinecone.init(
            api_key=os.getenv("PINECONE_API_KEY"),
            environment=os.getenv("PINECONE_ENV")
        )
        
        # Create index if doesn't exist
        if index_name not in pinecone.list_indexes():
            pinecone.create_index(
                name=index_name,
                dimension=1536,  # OpenAI embedding size
                metric="cosine"
            )
        
        self.index = pinecone.Index(index_name)
    
    def add(self, text: str, metadata: dict = None):
        """Add memory"""
        # Get embedding
        embedding = self.get_embedding(text)
        
        # Generate ID
        doc_id = f"mem_{int(time.time() * 1000)}"
        
        # Upsert to Pinecone
        self.index.upsert([(
            doc_id,
            embedding,
            {
                "text": text,
                **(metadata or {})
            }
        )])
    
    def search(self, query: str, top_k: int = 5) -&gt; List[dict]:
        """Search memories"""
        query_embedding = self.get_embedding(query)
        
        results = self.index.query(
            vector=query_embedding,
            top_k=top_k,
            include_metadata=True
        )
        
        memories = []
        for match in results['matches']:
            memories.append({
                "text": match['metadata']['text'],
                "score": match['score'],
                "metadata": match['metadata']
            })
        
        return memories
</code></pre>
<h2 id="entity-tracking-and-state-management"><a class="header" href="#entity-tracking-and-state-management">Entity Tracking and State Management</a></h2>
<p>Track entities (people, places, things) mentioned in conversations.</p>
<h3 id="entity-extraction"><a class="header" href="#entity-extraction">Entity Extraction</a></h3>
<pre><code class="language-python">class EntityTracker:
    """Track entities across conversation"""
    
    def __init__(self):
        self.entities = {}
    
    def extract_entities(self, text: str) -&gt; dict:
        """Extract entities from text"""
        prompt = f"""Extract entities from this text:

Text: {text}

Return as JSON:
{{
  "people": ["name1", "name2"],
  "places": ["place1"],
  "organizations": ["org1"],
  "dates": ["date1"],
  "other": ["thing1"]
}}"""
        
        response = llm.generate(prompt)
        return json.loads(response)
    
    def update(self, text: str):
        """Update entity tracking"""
        entities = self.extract_entities(text)
        
        for entity_type, items in entities.items():
            if entity_type not in self.entities:
                self.entities[entity_type] = {}
            
            for item in items:
                if item not in self.entities[entity_type]:
                    self.entities[entity_type][item] = {
                        "first_seen": time.time(),
                        "mentions": 0,
                        "context": []
                    }
                
                self.entities[entity_type][item]["mentions"] += 1
                self.entities[entity_type][item]["context"].append(text)
    
    def get_entity_info(self, entity: str) -&gt; dict:
        """Get information about an entity"""
        for entity_type, items in self.entities.items():
            if entity in items:
                return {
                    "type": entity_type,
                    **items[entity]
                }
        return None
</code></pre>
<h3 id="state-management"><a class="header" href="#state-management">State Management</a></h3>
<pre><code class="language-python">class StateManager:
    """Manage agent state"""
    
    def __init__(self):
        self.state = {
            "user_info": {},
            "current_task": None,
            "preferences": {},
            "context": {}
        }
    
    def update(self, key: str, value: any):
        """Update state"""
        keys = key.split('.')
        current = self.state
        
        for k in keys[:-1]:
            if k not in current:
                current[k] = {}
            current = current[k]
        
        current[keys[-1]] = value
    
    def get(self, key: str, default=None):
        """Get state value"""
        keys = key.split('.')
        current = self.state
        
        for k in keys:
            if k not in current:
                return default
            current = current[k]
        
        return current
    
    def save(self, filepath: str):
        """Save state to file"""
        with open(filepath, 'w') as f:
            json.dump(self.state, f, indent=2)
    
    def load(self, filepath: str):
        """Load state from file"""
        with open(filepath, 'r') as f:
            self.state = json.load(f)
</code></pre>
<h2 id="memory-retrieval-strategies"><a class="header" href="#memory-retrieval-strategies">Memory Retrieval Strategies</a></h2>
<p>How to find relevant memories efficiently.</p>
<h3 id="recency-based-retrieval"><a class="header" href="#recency-based-retrieval">Recency-Based Retrieval</a></h3>
<pre><code class="language-python">def get_recent_memories(memories: List[dict], n: int = 5) -&gt; List[dict]:
    """Get most recent memories"""
    sorted_memories = sorted(
        memories,
        key=lambda x: x.get('timestamp', 0),
        reverse=True
    )
    return sorted_memories[:n]
</code></pre>
<h3 id="relevance-based-retrieval"><a class="header" href="#relevance-based-retrieval">Relevance-Based Retrieval</a></h3>
<pre><code class="language-python">def get_relevant_memories(
    query: str,
    memories: List[dict],
    n: int = 5
) -&gt; List[dict]:
    """Get most relevant memories using embeddings"""
    query_embedding = get_embedding(query)
    
    scored_memories = []
    for memory in memories:
        memory_embedding = memory.get('embedding')
        if memory_embedding:
            score = cosine_similarity(query_embedding, memory_embedding)
            scored_memories.append((memory, score))
    
    scored_memories.sort(key=lambda x: x[1], reverse=True)
    return [m for m, s in scored_memories[:n]]
</code></pre>
<h3 id="hybrid-retrieval"><a class="header" href="#hybrid-retrieval">Hybrid Retrieval</a></h3>
<p>Combine multiple factors:</p>
<pre><code class="language-python">def hybrid_retrieval(
    query: str,
    memories: List[dict],
    n: int = 5,
    recency_weight: float = 0.3,
    relevance_weight: float = 0.7
) -&gt; List[dict]:
    """Combine recency and relevance"""
    
    query_embedding = get_embedding(query)
    current_time = time.time()
    
    scored_memories = []
    for memory in memories:
        # Relevance score
        relevance = cosine_similarity(
            query_embedding,
            memory['embedding']
        )
        
        # Recency score (decay over time)
        age = current_time - memory['timestamp']
        recency = np.exp(-age / (24 * 3600))  # Decay over days
        
        # Combined score
        score = (
            relevance_weight * relevance +
            recency_weight * recency
        )
        
        scored_memories.append((memory, score))
    
    scored_memories.sort(key=lambda x: x[1], reverse=True)
    return [m for m, s in scored_memories[:n]]
</code></pre>
<h3 id="importance-based-retrieval"><a class="header" href="#importance-based-retrieval">Importance-Based Retrieval</a></h3>
<pre><code class="language-python">def get_important_memories(
    memories: List[dict],
    n: int = 5
) -&gt; List[dict]:
    """Get memories marked as important"""
    
    # Score by importance
    scored = []
    for memory in memories:
        importance = memory.get('importance', 0)
        scored.append((memory, importance))
    
    scored.sort(key=lambda x: x[1], reverse=True)
    return [m for m, s in scored[:n]]

def calculate_importance(memory: dict) -&gt; float:
    """Calculate memory importance"""
    prompt = f"""Rate the importance of remembering this information (0-10):

{memory['text']}

Consider:
- Is it about user preferences?
- Is it a key fact?
- Will it be useful later?

Importance (0-10):"""
    
    response = llm.generate(prompt)
    return float(response.strip())
</code></pre>
<h2 id="complete-memory-system"><a class="header" href="#complete-memory-system">Complete Memory System</a></h2>
<pre><code class="language-python">class ComprehensiveMemory:
    """Full-featured memory system"""
    
    def __init__(self):
        # Short-term memory
        self.conversation = TokenAwareMemory(max_tokens=4000)
        
        # Long-term memory
        self.long_term = ChromaMemory()
        
        # Entity tracking
        self.entities = EntityTracker()
        
        # State management
        self.state = StateManager()
    
    def add_message(self, role: str, content: str):
        """Add message to conversation"""
        message = {
            "role": role,
            "content": content,
            "timestamp": time.time()
        }
        
        # Add to short-term
        self.conversation.add(message)
        
        # Extract and track entities
        if role == "user":
            self.entities.update(content)
        
        # Store important messages in long-term
        if self.is_important(content):
            self.long_term.add(
                content,
                metadata={
                    "role": role,
                    "timestamp": time.time()
                }
            )
    
    def is_important(self, text: str) -&gt; bool:
        """Determine if message should be stored long-term"""
        keywords = [
            "my name is", "i prefer", "remember",
            "always", "never", "i like", "i don't like"
        ]
        return any(kw in text.lower() for kw in keywords)
    
    def get_context(self, query: str = None) -&gt; List[dict]:
        """Get relevant context for current query"""
        context = []
        
        # Add relevant long-term memories
        if query:
            relevant = self.long_term.search(query, n_results=3)
            if relevant:
                context.append({
                    "role": "system",
                    "content": "Relevant information from past:\n" +
                               "\n".join([m['text'] for m in relevant])
                })
        
        # Add recent conversation
        context.extend(self.conversation.get_context())
        
        return context
    
    def save(self, filepath: str):
        """Save memory state"""
        data = {
            "entities": self.entities.entities,
            "state": self.state.state,
            "timestamp": time.time()
        }
        
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2)
    
    def load(self, filepath: str):
        """Load memory state"""
        with open(filepath, 'r') as f:
            data = json.load(f)
        
        self.entities.entities = data.get('entities', {})
        self.state.state = data.get('state', {})
</code></pre>
<h2 id="using-memory-in-agents"><a class="header" href="#using-memory-in-agents">Using Memory in Agents</a></h2>
<pre><code class="language-python">class MemoryAgent:
    """Agent with comprehensive memory"""
    
    def __init__(self):
        self.memory = ComprehensiveMemory()
        self.client = openai.OpenAI()
    
    def chat(self, user_input: str) -&gt; str:
        """Chat with memory"""
        
        # Add user message to memory
        self.memory.add_message("user", user_input)
        
        # Get context with relevant memories
        context = self.memory.get_context(query=user_input)
        
        # Generate response
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=context
        )
        
        assistant_message = response.choices[0].message.content
        
        # Add assistant response to memory
        self.memory.add_message("assistant", assistant_message)
        
        return assistant_message
    
    def save_session(self):
        """Save memory for later"""
        self.memory.save("session_memory.json")
    
    def load_session(self):
        """Load previous session"""
        self.memory.load("session_memory.json")
</code></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<ol>
<li><strong>Separate short and long-term</strong>: Different storage for different needs</li>
<li><strong>Be selective</strong>: Donâ€™t store everything</li>
<li><strong>Use semantic search</strong>: Find by meaning, not keywords</li>
<li><strong>Track importance</strong>: Prioritize valuable information</li>
<li><strong>Manage token budgets</strong>: Donâ€™t overflow context</li>
<li><strong>Summarize old conversations</strong>: Compress history</li>
<li><strong>Update entities</strong>: Track whatâ€™s mentioned</li>
<li><strong>Persist critical data</strong>: Save to disk/database</li>
<li><strong>Retrieve strategically</strong>: Balance recency, relevance, importance</li>
<li><strong>Test retrieval</strong>: Ensure you find what you need</li>
</ol>
<h2 id="next-steps-6"><a class="header" href="#next-steps-6">Next Steps</a></h2>
<p>With memory systems in place, agents can maintain context and learn from experience. Next, weâ€™ll explore multi-agent systems where multiple agents collaborate!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="multi-agent-systems"><a class="header" href="#multi-agent-systems">Multi-Agent Systems</a></h1>
<h2 id="why-multiple-agents"><a class="header" href="#why-multiple-agents">Why Multiple Agents?</a></h2>
<p>Single agents have limitations. Multiple specialized agents working together can:</p>
<ul>
<li>Handle complex tasks requiring diverse expertise</li>
<li>Work in parallel for faster completion</li>
<li>Provide checks and balances</li>
<li>Scale better than monolithic agents</li>
</ul>
<pre><code class="language-mermaid">graph LR
    subgraph "Single Agent"
    S[Task] --&gt; SA[Agent] --&gt; SR[Result]
    end
    
    subgraph "Multi-Agent System"
    M[Task] --&gt; MA1[Designer]
    M --&gt; MA2[Developer]
    M --&gt; MA3[Tester]
    MA1 --&gt; MC[Coordinator]
    MA2 --&gt; MC
    MA3 --&gt; MC
    MC --&gt; MR[Result]
    end
    
    style SA fill:#dbeafe
    style MA1 fill:#d1fae5
    style MA2 fill:#d1fae5
    style MA3 fill:#d1fae5
    style MC fill:#fef3c7
</code></pre>
<p><strong>Example</strong>: Building a website</p>
<ul>
<li><strong>Designer Agent</strong>: Creates UI/UX mockups</li>
<li><strong>Developer Agent</strong>: Writes code</li>
<li><strong>Tester Agent</strong>: Finds bugs</li>
<li><strong>Reviewer Agent</strong>: Ensures quality</li>
</ul>
<blockquote>
<p><strong>ğŸ’¡ When to Use Multi-Agent Systems</strong></p>
<p>Use multiple agents when:</p>
<ul>
<li>Task requires diverse expertise</li>
<li>Parallel processing is beneficial</li>
<li>Checks and balances are needed</li>
<li>Scaling beyond single agent capacity</li>
</ul>
<p>Stick with single agent when:</p>
<ul>
<li>Task is simple and focused</li>
<li>Coordination overhead isnâ€™t worth it</li>
<li>Real-time response is critical</li>
</ul>
</blockquote>
<h2 id="agent-collaboration-patterns"><a class="header" href="#agent-collaboration-patterns">Agent Collaboration Patterns</a></h2>
<h3 id="1-sequential-pipeline"><a class="header" href="#1-sequential-pipeline">1. Sequential (Pipeline)</a></h3>
<p>Agents work one after another:</p>
<pre><code>Agent A â†’ Agent B â†’ Agent C â†’ Result
</code></pre>
<pre><code class="language-python">class SequentialAgents:
    """Agents work in sequence"""
    
    def __init__(self, agents: List):
        self.agents = agents
    
    def run(self, task: str) -&gt; str:
        """Execute agents sequentially"""
        result = task
        
        for agent in self.agents:
            print(f"â†’ {agent.name} processing...")
            result = agent.process(result)
        
        return result

# Example
pipeline = SequentialAgents([
    ResearchAgent(),
    AnalysisAgent(),
    WriterAgent()
])

result = pipeline.run("Write a report on AI trends")
# Research â†’ Analysis â†’ Writing
</code></pre>
<h3 id="2-parallel-concurrent"><a class="header" href="#2-parallel-concurrent">2. Parallel (Concurrent)</a></h3>
<p>Agents work simultaneously:</p>
<pre><code>        â”Œâ”€ Agent A â”€â”
Task â”€â”€â”€â”¼â”€ Agent B â”€â”¼â”€â†’ Combine â†’ Result
        â””â”€ Agent C â”€â”˜
</code></pre>
<pre><code class="language-python">import asyncio

class ParallelAgents:
    """Agents work in parallel"""
    
    def __init__(self, agents: List):
        self.agents = agents
    
    async def run(self, task: str) -&gt; str:
        """Execute agents in parallel"""
        # Run all agents concurrently
        tasks = [agent.process_async(task) for agent in self.agents]
        results = await asyncio.gather(*tasks)
        
        # Combine results
        return self.combine_results(results)
    
    def combine_results(self, results: List[str]) -&gt; str:
        """Merge results from multiple agents"""
        prompt = f"""Combine these results into a coherent response:

{chr(10).join([f"Agent {i+1}: {r}" for i, r in enumerate(results)])}

Combined result:"""
        
        return llm.generate(prompt)

# Example
parallel = ParallelAgents([
    SearchAgent(),
    DatabaseAgent(),
    APIAgent()
])

result = await parallel.run("Find information about user X")
# All agents search simultaneously
</code></pre>
<h3 id="3-hierarchical-manager-worker"><a class="header" href="#3-hierarchical-manager-worker">3. Hierarchical (Manager-Worker)</a></h3>
<p>Manager delegates to workers:</p>
<pre><code>      Manager
     /   |   \
Worker1 Worker2 Worker3
</code></pre>
<pre><code class="language-python">class ManagerAgent:
    """Manages and delegates to worker agents"""
    
    def __init__(self, workers: List):
        self.workers = workers
    
    def run(self, task: str) -&gt; str:
        """Delegate and coordinate"""
        # Break down task
        subtasks = self.decompose_task(task)
        
        # Assign to workers
        assignments = self.assign_tasks(subtasks)
        
        # Collect results
        results = []
        for worker, subtask in assignments:
            result = worker.execute(subtask)
            results.append(result)
        
        # Synthesize final result
        return self.synthesize(results)
    
    def decompose_task(self, task: str) -&gt; List[str]:
        """Break task into subtasks"""
        prompt = f"""Break this task into 3-5 subtasks:

Task: {task}

Subtasks:"""
        
        response = llm.generate(prompt)
        return self.parse_subtasks(response)
    
    def assign_tasks(self, subtasks: List[str]) -&gt; List[tuple]:
        """Assign subtasks to workers"""
        assignments = []
        
        for i, subtask in enumerate(subtasks):
            # Round-robin assignment
            worker = self.workers[i % len(self.workers)]
            assignments.append((worker, subtask))
        
        return assignments
</code></pre>
<h3 id="4-debate-adversarial"><a class="header" href="#4-debate-adversarial">4. Debate (Adversarial)</a></h3>
<p>Agents debate to reach better conclusions:</p>
<pre><code class="language-python">class DebateSystem:
    """Agents debate to find best answer"""
    
    def __init__(self, agents: List, rounds: int = 3):
        self.agents = agents
        self.rounds = rounds
    
    def run(self, question: str) -&gt; str:
        """Run debate"""
        positions = []
        
        # Initial positions
        for agent in self.agents:
            position = agent.initial_position(question)
            positions.append(position)
        
        # Debate rounds
        for round_num in range(self.rounds):
            print(f"\n--- Round {round_num + 1} ---")
            
            new_positions = []
            for i, agent in enumerate(self.agents):
                # Show other positions
                other_positions = [p for j, p in enumerate(positions) if j != i]
                
                # Agent responds
                response = agent.respond(question, other_positions)
                new_positions.append(response)
                print(f"{agent.name}: {response[:100]}...")
            
            positions = new_positions
        
        # Judge decides winner
        return self.judge(question, positions)
    
    def judge(self, question: str, positions: List[str]) -&gt; str:
        """Determine best answer"""
        prompt = f"""Question: {question}

Positions:
{chr(10).join([f"{i+1}. {p}" for i, p in enumerate(positions)])}

Which position is most convincing and why?"""
        
        return llm.generate(prompt)
</code></pre>
<h3 id="5-collaborative-peer-to-peer"><a class="header" href="#5-collaborative-peer-to-peer">5. Collaborative (Peer-to-Peer)</a></h3>
<p>Agents work together as equals:</p>
<pre><code class="language-python">class CollaborativeAgents:
    """Agents collaborate as peers"""
    
    def __init__(self, agents: List):
        self.agents = agents
        self.shared_context = {}
    
    def run(self, task: str) -&gt; str:
        """Collaborative execution"""
        self.shared_context['task'] = task
        self.shared_context['contributions'] = []
        
        # Each agent contributes
        for agent in self.agents:
            contribution = agent.contribute(self.shared_context)
            self.shared_context['contributions'].append({
                'agent': agent.name,
                'content': contribution
            })
            
            # Other agents can see and build on this
            print(f"âœ“ {agent.name} contributed")
        
        # Synthesize all contributions
        return self.synthesize_contributions()
    
    def synthesize_contributions(self) -&gt; str:
        """Combine all contributions"""
        contributions = self.shared_context['contributions']
        
        prompt = f"""Synthesize these contributions into a final result:

Task: {self.shared_context['task']}

Contributions:
{chr(10).join([f"- {c['agent']}: {c['content']}" for c in contributions])}

Final result:"""
        
        return llm.generate(prompt)
</code></pre>
<h2 id="delegation-and-orchestration"><a class="header" href="#delegation-and-orchestration">Delegation and Orchestration</a></h2>
<h3 id="simple-orchestrator"><a class="header" href="#simple-orchestrator">Simple Orchestrator</a></h3>
<pre><code class="language-python">class Orchestrator:
    """Coordinates multiple agents"""
    
    def __init__(self):
        self.agents = {}
    
    def register_agent(self, name: str, agent):
        """Register an agent"""
        self.agents[name] = agent
    
    def delegate(self, task: str) -&gt; str:
        """Delegate task to appropriate agent"""
        # Determine which agent should handle this
        agent_name = self.select_agent(task)
        
        if agent_name not in self.agents:
            return f"No agent available for: {task}"
        
        # Delegate to agent
        agent = self.agents[agent_name]
        return agent.execute(task)
    
    def select_agent(self, task: str) -&gt; str:
        """Select best agent for task"""
        prompt = f"""Which agent should handle this task?

Task: {task}

Available agents:
{chr(10).join([f"- {name}: {agent.description}" for name, agent in self.agents.items()])}

Best agent:"""
        
        response = llm.generate(prompt)
        return response.strip()
</code></pre>
<h3 id="advanced-orchestrator-with-routing"><a class="header" href="#advanced-orchestrator-with-routing">Advanced Orchestrator with Routing</a></h3>
<pre><code class="language-python">class SmartOrchestrator:
    """Intelligent task routing"""
    
    def __init__(self):
        self.agents = {}
        self.routing_history = []
    
    def register_agent(self, name: str, agent, capabilities: List[str]):
        """Register agent with capabilities"""
        self.agents[name] = {
            'agent': agent,
            'capabilities': capabilities,
            'success_rate': 1.0
        }
    
    def route_task(self, task: str) -&gt; str:
        """Route task to best agent"""
        # Score each agent
        scores = {}
        for name, info in self.agents.items():
            score = self.score_agent(task, info)
            scores[name] = score
        
        # Select best agent
        best_agent = max(scores, key=scores.get)
        
        # Execute
        result = self.agents[best_agent]['agent'].execute(task)
        
        # Update success rate
        self.update_success_rate(best_agent, result)
        
        return result
    
    def score_agent(self, task: str, agent_info: dict) -&gt; float:
        """Score agent suitability"""
        # Check capability match
        capability_score = self.match_capabilities(task, agent_info['capabilities'])
        
        # Consider past success
        success_score = agent_info['success_rate']
        
        # Combined score
        return 0.7 * capability_score + 0.3 * success_score
</code></pre>
<h2 id="consensus-and-voting-mechanisms"><a class="header" href="#consensus-and-voting-mechanisms">Consensus and Voting Mechanisms</a></h2>
<h3 id="simple-voting"><a class="header" href="#simple-voting">Simple Voting</a></h3>
<pre><code class="language-python">class VotingSystem:
    """Agents vote on decisions"""
    
    def __init__(self, agents: List):
        self.agents = agents
    
    def decide(self, question: str, options: List[str]) -&gt; str:
        """Agents vote on options"""
        votes = {}
        
        for agent in self.agents:
            vote = agent.vote(question, options)
            votes[vote] = votes.get(vote, 0) + 1
        
        # Return option with most votes
        winner = max(votes, key=votes.get)
        return winner

# Example
voters = VotingSystem([
    Agent1(), Agent2(), Agent3()
])

decision = voters.decide(
    "Which framework should we use?",
    ["React", "Vue", "Angular"]
)
</code></pre>
<h3 id="weighted-voting"><a class="header" href="#weighted-voting">Weighted Voting</a></h3>
<pre><code class="language-python">class WeightedVoting:
    """Agents vote with different weights"""
    
    def __init__(self, agents: List[tuple]):
        # agents = [(agent, weight), ...]
        self.agents = agents
    
    def decide(self, question: str, options: List[str]) -&gt; str:
        """Weighted voting"""
        scores = {option: 0.0 for option in options}
        
        for agent, weight in self.agents:
            vote = agent.vote(question, options)
            scores[vote] += weight
        
        return max(scores, key=scores.get)

# Example
weighted = WeightedVoting([
    (ExpertAgent(), 2.0),    # Expert has 2x weight
    (JuniorAgent(), 1.0),
    (JuniorAgent(), 1.0)
])
</code></pre>
<h3 id="consensus-building"><a class="header" href="#consensus-building">Consensus Building</a></h3>
<pre><code class="language-python">class ConsensusBuilder:
    """Build consensus among agents"""
    
    def __init__(self, agents: List, threshold: float = 0.8):
        self.agents = agents
        self.threshold = threshold
    
    def reach_consensus(self, question: str, max_rounds: int = 5) -&gt; str:
        """Iteratively build consensus"""
        
        for round_num in range(max_rounds):
            # Get opinions
            opinions = [agent.opinion(question) for agent in self.agents]
            
            # Check agreement
            agreement = self.measure_agreement(opinions)
            
            if agreement &gt;= self.threshold:
                return self.synthesize_consensus(opinions)
            
            # Share opinions and iterate
            for agent in self.agents:
                agent.see_opinions(opinions)
        
        return "No consensus reached"
    
    def measure_agreement(self, opinions: List[str]) -&gt; float:
        """Measure how much agents agree"""
        # Use embeddings to measure similarity
        embeddings = [get_embedding(op) for op in opinions]
        
        # Calculate pairwise similarities
        similarities = []
        for i in range(len(embeddings)):
            for j in range(i+1, len(embeddings)):
                sim = cosine_similarity(embeddings[i], embeddings[j])
                similarities.append(sim)
        
        return np.mean(similarities)
</code></pre>
<h2 id="communication-protocols"><a class="header" href="#communication-protocols">Communication Protocols</a></h2>
<h3 id="message-passing"><a class="header" href="#message-passing">Message Passing</a></h3>
<pre><code class="language-python">class MessageBus:
    """Central message bus for agent communication"""
    
    def __init__(self):
        self.subscribers = {}
        self.messages = []
    
    def subscribe(self, agent_id: str, topics: List[str]):
        """Agent subscribes to topics"""
        for topic in topics:
            if topic not in self.subscribers:
                self.subscribers[topic] = []
            self.subscribers[topic].append(agent_id)
    
    def publish(self, topic: str, message: dict):
        """Publish message to topic"""
        self.messages.append({
            'topic': topic,
            'message': message,
            'timestamp': time.time()
        })
        
        # Notify subscribers
        if topic in self.subscribers:
            for agent_id in self.subscribers[topic]:
                self.deliver(agent_id, message)
    
    def deliver(self, agent_id: str, message: dict):
        """Deliver message to agent"""
        # Implementation depends on agent architecture
        pass
</code></pre>
<h3 id="direct-communication"><a class="header" href="#direct-communication">Direct Communication</a></h3>
<pre><code class="language-python">class Agent:
    """Agent with communication capabilities"""
    
    def __init__(self, name: str):
        self.name = name
        self.inbox = []
        self.peers = {}
    
    def send_message(self, recipient: str, message: str):
        """Send message to another agent"""
        if recipient in self.peers:
            self.peers[recipient].receive_message(self.name, message)
    
    def receive_message(self, sender: str, message: str):
        """Receive message from another agent"""
        self.inbox.append({
            'from': sender,
            'message': message,
            'timestamp': time.time()
        })
    
    def broadcast(self, message: str):
        """Send message to all peers"""
        for peer_name, peer in self.peers.items():
            peer.receive_message(self.name, message)
    
    def add_peer(self, name: str, agent):
        """Add peer agent"""
        self.peers[name] = agent
</code></pre>
<h2 id="complete-multi-agent-system"><a class="header" href="#complete-multi-agent-system">Complete Multi-Agent System</a></h2>
<pre><code class="language-python">class MultiAgentSystem:
    """Complete multi-agent system"""
    
    def __init__(self):
        self.agents = {}
        self.message_bus = MessageBus()
        self.orchestrator = Orchestrator()
    
    def add_agent(self, name: str, agent, role: str):
        """Add agent to system"""
        self.agents[name] = {
            'agent': agent,
            'role': role,
            'status': 'idle'
        }
        self.orchestrator.register_agent(name, agent)
    
    def execute_task(self, task: str, strategy: str = 'auto') -&gt; str:
        """Execute task using appropriate strategy"""
        
        if strategy == 'sequential':
            return self.execute_sequential(task)
        elif strategy == 'parallel':
            return self.execute_parallel(task)
        elif strategy == 'hierarchical':
            return self.execute_hierarchical(task)
        else:
            return self.execute_auto(task)
    
    def execute_sequential(self, task: str) -&gt; str:
        """Sequential execution"""
        result = task
        
        for name, info in self.agents.items():
            agent = info['agent']
            result = agent.process(result)
        
        return result
    
    async def execute_parallel(self, task: str) -&gt; str:
        """Parallel execution"""
        tasks = []
        
        for name, info in self.agents.items():
            agent = info['agent']
            tasks.append(agent.process_async(task))
        
        results = await asyncio.gather(*tasks)
        return self.combine_results(results)
    
    def execute_hierarchical(self, task: str) -&gt; str:
        """Hierarchical execution with manager"""
        # Find manager agent
        manager = self.find_manager()
        
        if not manager:
            return "No manager agent available"
        
        # Manager coordinates workers
        return manager.coordinate(task, self.agents)
    
    def execute_auto(self, task: str) -&gt; str:
        """Automatically choose best strategy"""
        # Analyze task complexity
        complexity = self.analyze_task(task)
        
        if complexity['parallel_potential'] &gt; 0.7:
            return asyncio.run(self.execute_parallel(task))
        elif complexity['requires_coordination']:
            return self.execute_hierarchical(task)
        else:
            return self.execute_sequential(task)
</code></pre>
<h2 id="example-research-team"><a class="header" href="#example-research-team">Example: Research Team</a></h2>
<pre><code class="language-python">class ResearchTeam:
    """Multi-agent research team"""
    
    def __init__(self):
        self.researcher = ResearchAgent()
        self.analyst = AnalystAgent()
        self.writer = WriterAgent()
        self.reviewer = ReviewerAgent()
    
    def research_topic(self, topic: str) -&gt; str:
        """Collaborative research"""
        
        # 1. Researcher gathers information
        print("ğŸ“š Researcher gathering information...")
        raw_data = self.researcher.gather(topic)
        
        # 2. Analyst analyzes data
        print("ğŸ“Š Analyst analyzing data...")
        analysis = self.analyst.analyze(raw_data)
        
        # 3. Writer creates report
        print("âœï¸  Writer creating report...")
        draft = self.writer.write(analysis)
        
        # 4. Reviewer provides feedback
        print("ğŸ‘€ Reviewer checking quality...")
        feedback = self.reviewer.review(draft)
        
        # 5. Writer revises based on feedback
        if feedback['needs_revision']:
            print("ğŸ”„ Writer revising...")
            final = self.writer.revise(draft, feedback)
        else:
            final = draft
        
        return final

# Usage
team = ResearchTeam()
report = team.research_topic("AI Agent Architectures")
</code></pre>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<ol>
<li><strong>Clear roles</strong>: Each agent should have a specific purpose</li>
<li><strong>Defined interfaces</strong>: Standardize communication</li>
<li><strong>Avoid bottlenecks</strong>: Donâ€™t make everything go through one agent</li>
<li><strong>Handle failures</strong>: One agent failing shouldnâ€™t crash the system</li>
<li><strong>Monitor coordination</strong>: Track how agents interact</li>
<li><strong>Balance autonomy</strong>: Agents should be independent but coordinated</li>
<li><strong>Prevent conflicts</strong>: Resolve disagreements systematically</li>
<li><strong>Scale gradually</strong>: Start simple, add complexity as needed</li>
<li><strong>Test interactions</strong>: Verify agents work well together</li>
<li><strong>Document protocols</strong>: Clear communication standards</li>
</ol>
<h2 id="common-pitfalls"><a class="header" href="#common-pitfalls">Common Pitfalls</a></h2>
<h3 id="pitfall-1-over-coordination"><a class="header" href="#pitfall-1-over-coordination">Pitfall 1: Over-coordination</a></h3>
<p><strong>Problem</strong>: Too much communication overhead
<strong>Solution</strong>: Let agents work independently when possible</p>
<h3 id="pitfall-2-conflicting-goals"><a class="header" href="#pitfall-2-conflicting-goals">Pitfall 2: Conflicting Goals</a></h3>
<p><strong>Problem</strong>: Agents work against each other
<strong>Solution</strong>: Align objectives and add conflict resolution</p>
<h3 id="pitfall-3-infinite-loops"><a class="header" href="#pitfall-3-infinite-loops">Pitfall 3: Infinite Loops</a></h3>
<p><strong>Problem</strong>: Agents keep delegating to each other
<strong>Solution</strong>: Add delegation limits and cycle detection</p>
<h3 id="pitfall-4-no-clear-owner"><a class="header" href="#pitfall-4-no-clear-owner">Pitfall 4: No Clear Owner</a></h3>
<p><strong>Problem</strong>: Task falls through the cracks
<strong>Solution</strong>: Always assign clear responsibility</p>
<h2 id="next-steps-7"><a class="header" href="#next-steps-7">Next Steps</a></h2>
<p>You now understand multi-agent systems! In Chapter 4, weâ€™ll explore the tools and capabilities that make agents powerful, including code execution, data access, and web interaction.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="code-execution"><a class="header" href="#code-execution">Code Execution</a></h1>
<h2 id="module-4-learning-objectives"><a class="header" href="#module-4-learning-objectives">Module 4: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Execute code safely in sandboxed environments</li>
<li>âœ“ Integrate data sources (databases, APIs, file systems)</li>
<li>âœ“ Implement web scraping and browser automation</li>
<li>âœ“ Build RAG systems for knowledge retrieval</li>
<li>âœ“ Handle various data formats and protocols</li>
</ul>
<hr>
<h2 id="why-agents-need-code-execution"><a class="header" href="#why-agents-need-code-execution">Why Agents Need Code Execution</a></h2>
<p>Code execution allows agents to:</p>
<ul>
<li>Perform precise calculations</li>
<li>Process data programmatically</li>
<li>Generate and test code</li>
<li>Automate complex operations</li>
<li>Verify results deterministically</li>
</ul>
<p><strong>Without code execution</strong>: â€œThe sum of 1 to 100 is approximately 5050â€
<strong>With code execution</strong>: â€œThe sum of 1 to 100 is exactly 5050â€ (calculated)</p>
<h2 id="sandboxed-environments"><a class="header" href="#sandboxed-environments">Sandboxed Environments</a></h2>
<p>Never execute untrusted code directly. Always use sandboxing.</p>
<h3 id="why-sandboxing"><a class="header" href="#why-sandboxing">Why Sandboxing?</a></h3>
<p><strong>Risks of unsandboxed execution</strong>:</p>
<ul>
<li>File system access (delete files)</li>
<li>Network access (data exfiltration)</li>
<li>System commands (malicious operations)</li>
<li>Resource exhaustion (infinite loops)</li>
</ul>
<h3 id="docker-sandbox"><a class="header" href="#docker-sandbox">Docker Sandbox</a></h3>
<pre><code class="language-python">import docker
import tempfile

class DockerSandbox:
    """Execute code in Docker container"""
    
    def __init__(self, image="python:3.11-slim"):
        self.client = docker.from_env()
        self.image = image
    
    def execute(self, code: str, timeout: int = 30) -&gt; dict:
        """Execute Python code in container"""
        try:
            # Create temporary file with code
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(code)
                code_file = f.name
            
            # Run container
            container = self.client.containers.run(
                self.image,
                f"python {code_file}",
                detach=True,
                mem_limit="128m",
                network_disabled=True,
                remove=True
            )
            
            # Wait for completion
            result = container.wait(timeout=timeout)
            logs = container.logs().decode('utf-8')
            
            return {
                "success": result['StatusCode'] == 0,
                "output": logs,
                "exit_code": result['StatusCode']
            }
            
        except docker.errors.ContainerError as e:
            return {
                "success": False,
                "output": str(e),
                "exit_code": -1
            }
        except Exception as e:
            return {
                "success": False,
                "output": f"Error: {str(e)}",
                "exit_code": -1
            }
</code></pre>
<h3 id="restrictedpython"><a class="header" href="#restrictedpython">RestrictedPython</a></h3>
<pre><code class="language-python">from RestrictedPython import compile_restricted, safe_globals
import io
import sys

class RestrictedExecutor:
    """Execute Python with restrictions"""
    
    def __init__(self):
        self.safe_builtins = {
            'print': print,
            'range': range,
            'len': len,
            'sum': sum,
            'max': max,
            'min': min,
            'abs': abs,
            'round': round,
            'sorted': sorted,
            'list': list,
            'dict': dict,
            'set': set,
            'str': str,
            'int': int,
            'float': float,
        }
    
    def execute(self, code: str, timeout: int = 5) -&gt; dict:
        """Execute restricted Python code"""
        try:
            # Compile with restrictions
            byte_code = compile_restricted(
                code,
                filename='&lt;inline&gt;',
                mode='exec'
            )
            
            if byte_code.errors:
                return {
                    "success": False,
                    "output": "\n".join(byte_code.errors)
                }
            
            # Capture output
            output_buffer = io.StringIO()
            sys.stdout = output_buffer
            
            # Execute with safe globals
            exec(byte_code, {
                "__builtins__": self.safe_builtins,
                "_print_": print,
                "_getattr_": getattr,
            })
            
            # Restore stdout
            sys.stdout = sys.__stdout__
            
            return {
                "success": True,
                "output": output_buffer.getvalue()
            }
            
        except Exception as e:
            sys.stdout = sys.__stdout__
            return {
                "success": False,
                "output": f"Error: {str(e)}"
            }
</code></pre>
<h3 id="e2b-code-interpreter"><a class="header" href="#e2b-code-interpreter">E2B Code Interpreter</a></h3>
<pre><code class="language-python">from e2b import Sandbox

class E2BSandbox:
    """Execute code using E2B"""
    
    def __init__(self):
        self.sandbox = Sandbox()
    
    def execute_python(self, code: str) -&gt; dict:
        """Execute Python code"""
        try:
            execution = self.sandbox.run_code(code)
            
            return {
                "success": not execution.error,
                "output": execution.stdout,
                "error": execution.stderr,
                "logs": execution.logs
            }
        except Exception as e:
            return {
                "success": False,
                "output": "",
                "error": str(e)
            }
    
    def execute_bash(self, command: str) -&gt; dict:
        """Execute bash command"""
        try:
            result = self.sandbox.process.start_and_wait(command)
            
            return {
                "success": result.exit_code == 0,
                "output": result.stdout,
                "error": result.stderr
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
</code></pre>
<h2 id="code-generation-and-validation"><a class="header" href="#code-generation-and-validation">Code Generation and Validation</a></h2>
<h3 id="generate-code"><a class="header" href="#generate-code">Generate Code</a></h3>
<pre><code class="language-python">def generate_code(task: str, language: str = "python") -&gt; str:
    """Generate code for a task"""
    prompt = f"""Write {language} code to accomplish this task:

Task: {task}

Requirements:
- Include error handling
- Add comments
- Return result clearly
- Keep it simple and readable

Code:"""
    
    response = llm.generate(prompt, temperature=0.2)
    return extract_code(response)

def extract_code(response: str) -&gt; str:
    """Extract code from markdown"""
    import re
    
    # Look for code blocks
    pattern = r"```(?:python)?\n(.*?)```"
    matches = re.findall(pattern, response, re.DOTALL)
    
    if matches:
        return matches[0].strip()
    
    return response.strip()
</code></pre>
<h3 id="validate-code"><a class="header" href="#validate-code">Validate Code</a></h3>
<pre><code class="language-python">import ast

def validate_python_code(code: str) -&gt; dict:
    """Validate Python code syntax"""
    try:
        ast.parse(code)
        return {
            "valid": True,
            "errors": []
        }
    except SyntaxError as e:
        return {
            "valid": False,
            "errors": [f"Line {e.lineno}: {e.msg}"]
        }

def check_dangerous_operations(code: str) -&gt; dict:
    """Check for dangerous operations"""
    dangerous_patterns = [
        (r'import\s+os', "OS module import"),
        (r'import\s+sys', "System module import"),
        (r'import\s+subprocess', "Subprocess import"),
        (r'open\s*\(', "File operations"),
        (r'eval\s*\(', "Eval usage"),
        (r'exec\s*\(', "Exec usage"),
        (r'__import__', "Dynamic imports"),
    ]
    
    issues = []
    for pattern, description in dangerous_patterns:
        if re.search(pattern, code):
            issues.append(description)
    
    return {
        "safe": len(issues) == 0,
        "issues": issues
    }
</code></pre>
<h3 id="test-generated-code"><a class="header" href="#test-generated-code">Test Generated Code</a></h3>
<pre><code class="language-python">def test_code(code: str, test_cases: List[dict]) -&gt; dict:
    """Test code with test cases"""
    sandbox = RestrictedExecutor()
    results = []
    
    for test in test_cases:
        # Prepare test code
        test_code = f"""
{code}

# Test case
result = {test['call']}
print(result)
"""
        
        # Execute
        output = sandbox.execute(test_code)
        
        # Check result
        expected = str(test['expected'])
        actual = output['output'].strip()
        
        results.append({
            "test": test['call'],
            "expected": expected,
            "actual": actual,
            "passed": actual == expected
        })
    
    return {
        "total": len(results),
        "passed": sum(1 for r in results if r['passed']),
        "results": results
    }

# Example usage
code = """
def add(a, b):
    return a + b
"""

test_cases = [
    {"call": "add(2, 3)", "expected": 5},
    {"call": "add(-1, 1)", "expected": 0},
    {"call": "add(0, 0)", "expected": 0}
]

results = test_code(code, test_cases)
</code></pre>
<h2 id="debugging-and-error-recovery"><a class="header" href="#debugging-and-error-recovery">Debugging and Error Recovery</a></h2>
<h3 id="parse-errors"><a class="header" href="#parse-errors">Parse Errors</a></h3>
<pre><code class="language-python">def parse_error(error_message: str) -&gt; dict:
    """Parse error message for useful info"""
    import re
    
    # Extract line number
    line_match = re.search(r'line (\d+)', error_message)
    line_num = int(line_match.group(1)) if line_match else None
    
    # Extract error type
    type_match = re.search(r'(\w+Error):', error_message)
    error_type = type_match.group(1) if type_match else "Unknown"
    
    return {
        "type": error_type,
        "line": line_num,
        "message": error_message
    }
</code></pre>
<h3 id="auto-fix-errors"><a class="header" href="#auto-fix-errors">Auto-Fix Errors</a></h3>
<pre><code class="language-python">def fix_code_error(code: str, error: str) -&gt; str:
    """Attempt to fix code based on error"""
    prompt = f"""This code has an error:

Code:
```python
{code}
</code></pre>
<p>Error:
{error}</p>
<p>Provide the corrected code:â€œâ€â€œ</p>
<pre><code>response = llm.generate(prompt, temperature=0.1)
return extract_code(response)
</code></pre>
<p>def iterative_fix(code: str, max_attempts: int = 3) -&gt; dict:
â€œâ€â€œIteratively fix code until it worksâ€â€œâ€
sandbox = RestrictedExecutor()</p>
<pre><code>for attempt in range(max_attempts):
    # Try to execute
    result = sandbox.execute(code)
    
    if result['success']:
        return {
            "success": True,
            "code": code,
            "attempts": attempt + 1
        }
    
    # Try to fix
    code = fix_code_error(code, result['output'])

return {
    "success": False,
    "code": code,
    "attempts": max_attempts,
    "error": "Max attempts reached"
}
</code></pre>
<pre><code>
## Security Considerations

### Input Validation

```python
def validate_code_input(code: str) -&gt; dict:
    """Validate code before execution"""
    
    # Check length
    if len(code) &gt; 10000:
        return {
            "valid": False,
            "reason": "Code too long (max 10000 chars)"
        }
    
    # Check for null bytes
    if '\x00' in code:
        return {
            "valid": False,
            "reason": "Invalid characters in code"
        }
    
    # Check syntax
    syntax_check = validate_python_code(code)
    if not syntax_check['valid']:
        return {
            "valid": False,
            "reason": f"Syntax error: {syntax_check['errors']}"
        }
    
    # Check for dangerous operations
    safety_check = check_dangerous_operations(code)
    if not safety_check['safe']:
        return {
            "valid": False,
            "reason": f"Unsafe operations: {safety_check['issues']}"
        }
    
    return {"valid": True}
</code></pre>
<h3 id="resource-limits"><a class="header" href="#resource-limits">Resource Limits</a></h3>
<pre><code class="language-python">class ResourceLimitedExecutor:
    """Execute code with resource limits"""
    
    def __init__(self):
        self.max_execution_time = 30  # seconds
        self.max_memory = 128 * 1024 * 1024  # 128 MB
        self.max_output_size = 10000  # characters
    
    def execute(self, code: str) -&gt; dict:
        """Execute with limits"""
        import signal
        import resource
        
        def timeout_handler(signum, frame):
            raise TimeoutError("Execution timeout")
        
        # Set timeout
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(self.max_execution_time)
        
        # Set memory limit
        resource.setrlimit(
            resource.RLIMIT_AS,
            (self.max_memory, self.max_memory)
        )
        
        try:
            # Execute code
            result = self._execute_code(code)
            
            # Limit output size
            if len(result['output']) &gt; self.max_output_size:
                result['output'] = result['output'][:self.max_output_size] + "...(truncated)"
            
            return result
            
        except TimeoutError:
            return {
                "success": False,
                "output": "Execution timeout"
            }
        except MemoryError:
            return {
                "success": False,
                "output": "Memory limit exceeded"
            }
        finally:
            signal.alarm(0)  # Cancel alarm
</code></pre>
<h2 id="complete-code-execution-agent"><a class="header" href="#complete-code-execution-agent">Complete Code Execution Agent</a></h2>
<pre><code class="language-python">class CodeExecutionAgent:
    """Agent that can generate and execute code"""
    
    def __init__(self):
        self.sandbox = RestrictedExecutor()
        self.client = openai.OpenAI()
    
    def solve_with_code(self, problem: str) -&gt; str:
        """Solve problem by generating and executing code"""
        
        # Generate code
        print("ğŸ’» Generating code...")
        code = self.generate_solution(problem)
        print(f"Generated:\n{code}\n")
        
        # Validate
        validation = validate_code_input(code)
        if not validation['valid']:
            return f"Invalid code: {validation['reason']}"
        
        # Execute
        print("â–¶ï¸  Executing code...")
        result = self.sandbox.execute(code)
        
        if result['success']:
            print(f"âœ“ Output: {result['output']}\n")
            return self.format_result(problem, code, result['output'])
        else:
            # Try to fix and retry
            print("âš ï¸  Error occurred, attempting fix...")
            fixed = iterative_fix(code)
            
            if fixed['success']:
                result = self.sandbox.execute(fixed['code'])
                return self.format_result(problem, fixed['code'], result['output'])
            else:
                return f"Failed to execute: {result['output']}"
    
    def generate_solution(self, problem: str) -&gt; str:
        """Generate code to solve problem"""
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"""Write Python code to solve this problem:

{problem}

Requirements:
- Use only standard library
- Print the final result
- Handle edge cases
- Keep it simple

Provide only the code, no explanations."""
            }],
            temperature=0.2
        )
        
        return extract_code(response.choices[0].message.content)
    
    def format_result(self, problem: str, code: str, output: str) -&gt; str:
        """Format final result"""
        return f"""Problem: {problem}

Solution:
```python
{code}
</code></pre>
<p>Result: {output}â€œâ€â€œ</p>
<h1 id="usage"><a class="header" href="#usage">Usage</a></h1>
<p>agent = CodeExecutionAgent()
result = agent.solve_with_code(â€œCalculate the sum of all prime numbers less than 100â€)
print(result)</p>
<pre><code>
## Advanced Use Cases

### Data Analysis

```python
def analyze_data_with_code(data: List[dict], question: str) -&gt; str:
    """Analyze data using generated code"""
    
    # Generate analysis code
    code = f"""
import json

data = {json.dumps(data)}

# Analysis code will be generated here
"""
    
    analysis_code = generate_code(
        f"Analyze this data to answer: {question}\nData structure: {data[0] if data else {}}"
    )
    
    full_code = code + "\n" + analysis_code
    
    # Execute
    sandbox = RestrictedExecutor()
    result = sandbox.execute(full_code)
    
    return result['output']
</code></pre>
<h3 id="mathematical-computation"><a class="header" href="#mathematical-computation">Mathematical Computation</a></h3>
<pre><code class="language-python">def compute_math(expression: str) -&gt; str:
    """Safely compute mathematical expression"""
    
    code = f"""
import math

result = {expression}
print(result)
"""
    
    sandbox = RestrictedExecutor()
    result = sandbox.execute(code)
    
    if result['success']:
        return result['output'].strip()
    else:
        return f"Error: {result['output']}"
</code></pre>
<h3 id="code-transformation"><a class="header" href="#code-transformation">Code Transformation</a></h3>
<pre><code class="language-python">def transform_code(code: str, transformation: str) -&gt; str:
    """Transform code (refactor, optimize, etc.)"""
    
    prompt = f"""Transform this code:

Original:
```python
{code}
</code></pre>
<p>Transformation: {transformation}</p>
<p>Transformed code:â€œâ€â€œ</p>
<pre><code>response = llm.generate(prompt)
return extract_code(response)
</code></pre>
<h1 id="example"><a class="header" href="#example">Example</a></h1>
<p>original = â€œfor i in range(len(items)): print(items[i])â€
transformed = transform_code(original, â€œMake it more Pythonicâ€)</p>
<h1 id="result-for-item-in-items-printitem"><a class="header" href="#result-for-item-in-items-printitem">Result: â€œfor item in items: print(item)â€</a></h1>
<pre><code>
## Best Practices

1. **Always sandbox**: Never execute untrusted code directly
2. **Set timeouts**: Prevent infinite loops
3. **Limit resources**: Memory, CPU, network
4. **Validate inputs**: Check code before execution
5. **Handle errors gracefully**: Don't crash on bad code
6. **Test generated code**: Verify it works
7. **Log executions**: Track what code runs
8. **Isolate environments**: One execution shouldn't affect others
9. **Clean up**: Remove temporary files and containers
10. **Monitor usage**: Track resource consumption

## Common Pitfalls

### Pitfall 1: Trusting Generated Code
**Problem**: LLM generates code with bugs
**Solution**: Always test and validate

### Pitfall 2: No Timeout
**Problem**: Infinite loops hang the system
**Solution**: Set execution timeouts

### Pitfall 3: Unrestricted Access
**Problem**: Code can access file system
**Solution**: Use proper sandboxing

### Pitfall 4: Poor Error Messages
**Problem**: User doesn't understand what went wrong
**Solution**: Parse and explain errors clearly

## Next Steps

You now understand code execution for agents! Next, we'll explore data access and retrieval, including databases, APIs, and RAG systems.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="data-access--retrieval"><a class="header" href="#data-access--retrieval">Data Access &amp; Retrieval</a></h1>
<h2 id="rag-retrieval-augmented-generation"><a class="header" href="#rag-retrieval-augmented-generation">RAG (Retrieval Augmented Generation)</a></h2>
<p>RAG combines retrieval with generation to provide accurate, grounded responses.</p>
<h3 id="why-rag"><a class="header" href="#why-rag">Why RAG?</a></h3>
<p><strong>Without RAG</strong>:</p>
<ul>
<li>LLM relies on training data (may be outdated)</li>
<li>Can hallucinate facts</li>
<li>No access to private/recent information</li>
</ul>
<p><strong>With RAG</strong>:</p>
<ul>
<li>Retrieves relevant documents first</li>
<li>Grounds responses in actual data</li>
<li>Works with private knowledge bases</li>
<li>Always up-to-date</li>
</ul>
<h3 id="basic-rag-pipeline"><a class="header" href="#basic-rag-pipeline">Basic RAG Pipeline</a></h3>
<pre><code class="language-python">class SimpleRAG:
    """Basic RAG implementation"""
    
    def __init__(self):
        self.documents = []
        self.embeddings = []
        self.client = openai.OpenAI()
    
    def add_document(self, text: str, metadata: dict = None):
        """Add document to knowledge base"""
        # Create embedding
        embedding = self.get_embedding(text)
        
        self.documents.append({
            "text": text,
            "metadata": metadata or {},
            "id": len(self.documents)
        })
        self.embeddings.append(embedding)
    
    def get_embedding(self, text: str) -&gt; list:
        """Get embedding for text"""
        response = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    
    def retrieve(self, query: str, top_k: int = 3) -&gt; list:
        """Retrieve relevant documents"""
        # Get query embedding
        query_embedding = self.get_embedding(query)
        
        # Calculate similarities
        similarities = []
        for i, doc_embedding in enumerate(self.embeddings):
            similarity = self.cosine_similarity(query_embedding, doc_embedding)
            similarities.append((i, similarity))
        
        # Sort and get top k
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        results = []
        for i, score in similarities[:top_k]:
            doc = self.documents[i].copy()
            doc['score'] = score
            results.append(doc)
        
        return results
    
    def query(self, question: str) -&gt; str:
        """Answer question using RAG"""
        # Retrieve relevant documents
        docs = self.retrieve(question, top_k=3)
        
        # Build context
        context = "\n\n".join([
            f"Document {i+1}:\n{doc['text']}"
            for i, doc in enumerate(docs)
        ])
        
        # Generate answer
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "Answer questions based on the provided context. If the answer isn't in the context, say so."
                },
                {
                    "role": "user",
                    "content": f"Context:\n{context}\n\nQuestion: {question}"
                }
            ]
        )
        
        return response.choices[0].message.content
    
    def cosine_similarity(self, a: list, b: list) -&gt; float:
        """Calculate cosine similarity"""
        import numpy as np
        a = np.array(a)
        b = np.array(b)
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# Usage
rag = SimpleRAG()

# Add documents
rag.add_document("Python is a high-level programming language.")
rag.add_document("JavaScript is used for web development.")
rag.add_document("Python is popular for data science and AI.")

# Query
answer = rag.query("What is Python used for?")
print(answer)
</code></pre>
<h3 id="advanced-rag-with-langchain"><a class="header" href="#advanced-rag-with-langchain">Advanced RAG with LangChain</a></h3>
<pre><code class="language-python">from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

class AdvancedRAG:
    """RAG using LangChain"""
    
    def __init__(self, persist_directory="./chroma_db"):
        self.embeddings = OpenAIEmbeddings()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        self.vectorstore = None
        self.persist_directory = persist_directory
    
    def load_documents(self, documents: list):
        """Load and process documents"""
        # Split documents into chunks
        chunks = self.text_splitter.create_documents(documents)
        
        # Create vector store
        self.vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory=self.persist_directory
        )
    
    def query(self, question: str) -&gt; dict:
        """Query with source attribution"""
        if not self.vectorstore:
            return {"answer": "No documents loaded", "sources": []}
        
        # Create QA chain
        qa_chain = RetrievalQA.from_chain_type(
            llm=OpenAI(temperature=0),
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3}),
            return_source_documents=True
        )
        
        # Query
        result = qa_chain({"query": question})
        
        return {
            "answer": result["result"],
            "sources": [doc.page_content for doc in result["source_documents"]]
        }
</code></pre>
<h3 id="chunking-strategies"><a class="header" href="#chunking-strategies">Chunking Strategies</a></h3>
<pre><code class="language-python">class DocumentChunker:
    """Different chunking strategies"""
    
    def chunk_by_tokens(self, text: str, chunk_size: int = 512, overlap: int = 50) -&gt; list:
        """Chunk by token count"""
        import tiktoken
        
        encoding = tiktoken.encoding_for_model("gpt-4")
        tokens = encoding.encode(text)
        
        chunks = []
        start = 0
        
        while start &lt; len(tokens):
            end = start + chunk_size
            chunk_tokens = tokens[start:end]
            chunk_text = encoding.decode(chunk_tokens)
            chunks.append(chunk_text)
            start = end - overlap
        
        return chunks
    
    def chunk_by_sentences(self, text: str, sentences_per_chunk: int = 5) -&gt; list:
        """Chunk by sentences"""
        import re
        
        # Split into sentences
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        chunks = []
        for i in range(0, len(sentences), sentences_per_chunk):
            chunk = ". ".join(sentences[i:i+sentences_per_chunk]) + "."
            chunks.append(chunk)
        
        return chunks
    
    def chunk_by_paragraphs(self, text: str) -&gt; list:
        """Chunk by paragraphs"""
        paragraphs = text.split('\n\n')
        return [p.strip() for p in paragraphs if p.strip()]
    
    def semantic_chunking(self, text: str, similarity_threshold: float = 0.7) -&gt; list:
        """Chunk based on semantic similarity"""
        sentences = self.split_sentences(text)
        
        if not sentences:
            return []
        
        chunks = []
        current_chunk = [sentences[0]]
        
        for i in range(1, len(sentences)):
            # Check similarity with current chunk
            chunk_text = " ".join(current_chunk)
            similarity = self.calculate_similarity(chunk_text, sentences[i])
            
            if similarity &gt;= similarity_threshold:
                current_chunk.append(sentences[i])
            else:
                # Start new chunk
                chunks.append(" ".join(current_chunk))
                current_chunk = [sentences[i]]
        
        # Add last chunk
        if current_chunk:
            chunks.append(" ".join(current_chunk))
        
        return chunks
</code></pre>
<h2 id="database-queries"><a class="header" href="#database-queries">Database Queries</a></h2>
<h3 id="sql-databases"><a class="header" href="#sql-databases">SQL Databases</a></h3>
<pre><code class="language-python">import sqlite3
from typing import List, Dict

class SQLAgent:
    """Agent that can query SQL databases"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.client = openai.OpenAI()
    
    def get_schema(self) -&gt; str:
        """Get database schema"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get all tables
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = cursor.fetchall()
        
        schema = []
        for table in tables:
            table_name = table[0]
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = cursor.fetchall()
            
            schema.append(f"Table: {table_name}")
            for col in columns:
                schema.append(f"  - {col[1]} ({col[2]})")
        
        conn.close()
        return "\n".join(schema)
    
    def natural_language_query(self, question: str) -&gt; Dict:
        """Convert natural language to SQL and execute"""
        # Generate SQL
        sql = self.generate_sql(question)
        
        # Execute SQL
        results = self.execute_sql(sql)
        
        # Format response
        answer = self.format_results(question, results)
        
        return {
            "question": question,
            "sql": sql,
            "results": results,
            "answer": answer
        }
    
    def generate_sql(self, question: str) -&gt; str:
        """Generate SQL from natural language"""
        schema = self.get_schema()
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": f"""You are a SQL expert. Convert natural language questions to SQL queries.

Database schema:
{schema}

Rules:
- Return only the SQL query, no explanations
- Use proper SQL syntax
- Be careful with column names
- Use appropriate JOINs when needed"""
                },
                {
                    "role": "user",
                    "content": question
                }
            ],
            temperature=0.1
        )
        
        sql = response.choices[0].message.content.strip()
        # Remove markdown code blocks if present
        sql = sql.replace("```sql", "").replace("```", "").strip()
        
        return sql
    
    def execute_sql(self, sql: str) -&gt; List[Dict]:
        """Execute SQL query safely"""
        # Validate query (read-only)
        if not self.is_safe_query(sql):
            raise ValueError("Only SELECT queries are allowed")
        
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        try:
            cursor.execute(sql)
            rows = cursor.fetchall()
            
            # Convert to list of dicts
            results = [dict(row) for row in rows]
            
            conn.close()
            return results
            
        except Exception as e:
            conn.close()
            raise Exception(f"SQL execution error: {str(e)}")
    
    def is_safe_query(self, sql: str) -&gt; bool:
        """Check if query is safe (read-only)"""
        sql_upper = sql.upper().strip()
        
        # Only allow SELECT
        if not sql_upper.startswith("SELECT"):
            return False
        
        # Disallow dangerous keywords
        dangerous = ["DROP", "DELETE", "INSERT", "UPDATE", "ALTER", "CREATE"]
        for keyword in dangerous:
            if keyword in sql_upper:
                return False
        
        return True
    
    def format_results(self, question: str, results: List[Dict]) -&gt; str:
        """Format results as natural language"""
        if not results:
            return "No results found."
        
        # Convert results to text
        results_text = "\n".join([str(row) for row in results[:10]])
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "user",
                    "content": f"""Answer this question based on the query results:

Question: {question}

Results:
{results_text}

Provide a clear, natural language answer:"""
                }
            ]
        )
        
        return response.choices[0].message.content

# Usage
agent = SQLAgent("company.db")
result = agent.natural_language_query("How many employees are in the sales department?")
print(result['answer'])
</code></pre>
<h3 id="nosql-databases"><a class="header" href="#nosql-databases">NoSQL Databases</a></h3>
<pre><code class="language-python">from pymongo import MongoClient

class MongoDBAgent:
    """Agent for MongoDB queries"""
    
    def __init__(self, connection_string: str, database: str):
        self.client = MongoClient(connection_string)
        self.db = self.client[database]
        self.llm = openai.OpenAI()
    
    def query(self, question: str, collection: str) -&gt; dict:
        """Query MongoDB using natural language"""
        # Generate MongoDB query
        query_dict = self.generate_query(question, collection)
        
        # Execute query
        results = list(self.db[collection].find(query_dict).limit(10))
        
        # Format response
        answer = self.format_results(question, results)
        
        return {
            "question": question,
            "query": query_dict,
            "results": results,
            "answer": answer
        }
    
    def generate_query(self, question: str, collection: str) -&gt; dict:
        """Generate MongoDB query from natural language"""
        # Get sample document
        sample = self.db[collection].find_one()
        
        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": f"""Convert natural language to MongoDB query.

Collection: {collection}
Sample document: {sample}

Return only valid JSON for MongoDB find() query."""
                },
                {
                    "role": "user",
                    "content": question
                }
            ],
            temperature=0.1
        )
        
        import json
        query_str = response.choices[0].message.content.strip()
        return json.loads(query_str)
</code></pre>
<h2 id="api-integrations"><a class="header" href="#api-integrations">API Integrations</a></h2>
<h3 id="rest-api-client"><a class="header" href="#rest-api-client">REST API Client</a></h3>
<pre><code class="language-python">import requests
from typing import Optional

class APIAgent:
    """Agent that can call REST APIs"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.session = requests.Session()
    
    def call_api(self, 
                 url: str,
                 method: str = "GET",
                 headers: Optional[dict] = None,
                 params: Optional[dict] = None,
                 data: Optional[dict] = None) -&gt; dict:
        """Make API call"""
        try:
            response = self.session.request(
                method=method,
                url=url,
                headers=headers,
                params=params,
                json=data,
                timeout=30
            )
            
            response.raise_for_status()
            
            return {
                "success": True,
                "status_code": response.status_code,
                "data": response.json() if response.content else None
            }
            
        except requests.exceptions.RequestException as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def natural_language_api_call(self, request: str, api_spec: dict) -&gt; dict:
        """Convert natural language to API call"""
        # Generate API call parameters
        params = self.generate_api_params(request, api_spec)
        
        # Make API call
        result = self.call_api(**params)
        
        # Format response
        if result['success']:
            answer = self.format_api_response(request, result['data'])
            return {
                "request": request,
                "api_call": params,
                "response": result['data'],
                "answer": answer
            }
        else:
            return {
                "request": request,
                "error": result['error']
            }
    
    def generate_api_params(self, request: str, api_spec: dict) -&gt; dict:
        """Generate API parameters from natural language"""
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": f"""Convert natural language to API call parameters.

API Specification:
{json.dumps(api_spec, indent=2)}

Return JSON with: url, method, headers, params, data"""
                },
                {
                    "role": "user",
                    "content": request
                }
            ],
            temperature=0.1
        )
        
        import json
        return json.loads(response.choices[0].message.content)
</code></pre>
<h3 id="graphql-client"><a class="header" href="#graphql-client">GraphQL Client</a></h3>
<pre><code class="language-python">from gql import gql, Client
from gql.transport.requests import RequestsHTTPTransport

class GraphQLAgent:
    """Agent for GraphQL APIs"""
    
    def __init__(self, endpoint: str):
        transport = RequestsHTTPTransport(url=endpoint)
        self.client = Client(transport=transport, fetch_schema_from_transport=True)
        self.llm = openai.OpenAI()
    
    def query(self, natural_language_query: str) -&gt; dict:
        """Execute GraphQL query from natural language"""
        # Generate GraphQL query
        graphql_query = self.generate_graphql(natural_language_query)
        
        # Execute query
        query = gql(graphql_query)
        result = self.client.execute(query)
        
        # Format response
        answer = self.format_results(natural_language_query, result)
        
        return {
            "question": natural_language_query,
            "graphql": graphql_query,
            "result": result,
            "answer": answer
        }
    
    def generate_graphql(self, question: str) -&gt; str:
        """Generate GraphQL query"""
        schema = self.client.schema
        
        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": f"""Generate GraphQL query from natural language.

Schema: {schema}

Return only the GraphQL query."""
                },
                {
                    "role": "user",
                    "content": question
                }
            ]
        )
        
        return response.choices[0].message.content.strip()
</code></pre>
<h2 id="file-system-operations"><a class="header" href="#file-system-operations">File System Operations</a></h2>
<h3 id="safe-file-access"><a class="header" href="#safe-file-access">Safe File Access</a></h3>
<pre><code class="language-python">import os
from pathlib import Path

class FileSystemAgent:
    """Agent with safe file system access"""
    
    def __init__(self, allowed_directory: str):
        self.allowed_directory = Path(allowed_directory).resolve()
    
    def is_safe_path(self, path: str) -&gt; bool:
        """Check if path is within allowed directory"""
        try:
            requested_path = (self.allowed_directory / path).resolve()
            return requested_path.is_relative_to(self.allowed_directory)
        except:
            return False
    
    def read_file(self, path: str) -&gt; dict:
        """Read file safely"""
        if not self.is_safe_path(path):
            return {"success": False, "error": "Access denied"}
        
        try:
            full_path = self.allowed_directory / path
            with open(full_path, 'r') as f:
                content = f.read()
            
            return {
                "success": True,
                "content": content,
                "size": len(content)
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def list_files(self, path: str = ".") -&gt; dict:
        """List files in directory"""
        if not self.is_safe_path(path):
            return {"success": False, "error": "Access denied"}
        
        try:
            full_path = self.allowed_directory / path
            files = []
            
            for item in full_path.iterdir():
                files.append({
                    "name": item.name,
                    "type": "directory" if item.is_dir() else "file",
                    "size": item.stat().st_size if item.is_file() else None
                })
            
            return {
                "success": True,
                "files": files
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def search_files(self, pattern: str, path: str = ".") -&gt; dict:
        """Search for files matching pattern"""
        if not self.is_safe_path(path):
            return {"success": False, "error": "Access denied"}
        
        try:
            full_path = self.allowed_directory / path
            matches = list(full_path.rglob(pattern))
            
            results = [
                {
                    "path": str(m.relative_to(self.allowed_directory)),
                    "name": m.name,
                    "size": m.stat().st_size if m.is_file() else None
                }
                for m in matches
            ]
            
            return {
                "success": True,
                "matches": results
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
</code></pre>
<h2 id="complete-data-access-agent"><a class="header" href="#complete-data-access-agent">Complete Data Access Agent</a></h2>
<pre><code class="language-python">class DataAccessAgent:
    """Unified agent for data access"""
    
    def __init__(self):
        self.rag = SimpleRAG()
        self.sql_agent = None
        self.api_agent = APIAgent()
        self.fs_agent = None
        self.client = openai.OpenAI()
    
    def configure_sql(self, db_path: str):
        """Configure SQL access"""
        self.sql_agent = SQLAgent(db_path)
    
    def configure_filesystem(self, allowed_dir: str):
        """Configure file system access"""
        self.fs_agent = FileSystemAgent(allowed_dir)
    
    def query(self, question: str) -&gt; str:
        """Answer question using appropriate data source"""
        # Determine which data source to use
        source = self.determine_source(question)
        
        if source == "rag":
            return self.rag.query(question)
        elif source == "sql" and self.sql_agent:
            result = self.sql_agent.natural_language_query(question)
            return result['answer']
        elif source == "api":
            # Would need API spec
            return "API access requires configuration"
        elif source == "filesystem" and self.fs_agent:
            # Would need to determine file operation
            return "File system access requires specific operation"
        else:
            return "Unable to determine appropriate data source"
    
    def determine_source(self, question: str) -&gt; str:
        """Determine which data source to use"""
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "user",
                    "content": f"""Which data source should be used for this question?

Question: {question}

Options: rag, sql, api, filesystem

Answer with just the option:"""
                }
            ],
            temperature=0.1
        )
        
        return response.choices[0].message.content.strip().lower()
</code></pre>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<ol>
<li><strong>Validate queries</strong>: Check SQL/API calls before execution</li>
<li><strong>Limit results</strong>: Donâ€™t return huge datasets</li>
<li><strong>Cache responses</strong>: Avoid redundant queries</li>
<li><strong>Handle errors</strong>: Graceful failure handling</li>
<li><strong>Secure credentials</strong>: Never expose API keys</li>
<li><strong>Rate limiting</strong>: Respect API limits</li>
<li><strong>Chunk large documents</strong>: Better retrieval</li>
<li><strong>Use appropriate embeddings</strong>: Match your use case</li>
<li><strong>Monitor costs</strong>: Track API usage</li>
<li><strong>Test thoroughly</strong>: Verify data access works</li>
</ol>
<h2 id="next-steps-8"><a class="header" href="#next-steps-8">Next Steps</a></h2>
<p>You now understand data access and retrieval! Next, weâ€™ll explore web interaction including browser automation and scraping.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="web-interaction"><a class="header" href="#web-interaction">Web Interaction</a></h1>
<h2 id="browser-automation"><a class="header" href="#browser-automation">Browser Automation</a></h2>
<p>Agents can interact with websites like humans doâ€”clicking, typing, scrolling, and extracting information.</p>
<h3 id="why-browser-automation"><a class="header" href="#why-browser-automation">Why Browser Automation?</a></h3>
<ul>
<li>Access dynamic content (JavaScript-rendered)</li>
<li>Interact with web applications</li>
<li>Fill forms and submit data</li>
<li>Navigate multi-page workflows</li>
<li>Handle authentication</li>
</ul>
<h3 id="playwright-basics"><a class="header" href="#playwright-basics">Playwright Basics</a></h3>
<pre><code class="language-python">from playwright.sync_api import sync_playwright
from typing import Optional

class BrowserAgent:
    """Agent with browser automation capabilities"""
    
    def __init__(self, headless: bool = True):
        self.headless = headless
        self.playwright = None
        self.browser = None
        self.page = None
    
    def start(self):
        """Start browser"""
        self.playwright = sync_playwright().start()
        self.browser = self.playwright.chromium.launch(headless=self.headless)
        self.page = self.browser.new_page()
    
    def stop(self):
        """Stop browser"""
        if self.browser:
            self.browser.close()
        if self.playwright:
            self.playwright.stop()
    
    def navigate(self, url: str) -&gt; dict:
        """Navigate to URL"""
        try:
            self.page.goto(url, wait_until="networkidle")
            return {
                "success": True,
                "url": self.page.url,
                "title": self.page.title()
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def click(self, selector: str) -&gt; dict:
        """Click element"""
        try:
            self.page.click(selector)
            return {"success": True}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def type_text(self, selector: str, text: str) -&gt; dict:
        """Type text into element"""
        try:
            self.page.fill(selector, text)
            return {"success": True}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_text(self, selector: str) -&gt; Optional[str]:
        """Get text from element"""
        try:
            return self.page.text_content(selector)
        except:
            return None
    
    def screenshot(self, path: str = "screenshot.png") -&gt; dict:
        """Take screenshot"""
        try:
            self.page.screenshot(path=path)
            return {"success": True, "path": path}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_page_content(self) -&gt; str:
        """Get full page HTML"""
        return self.page.content()

# Usage
agent = BrowserAgent()
agent.start()

# Navigate
agent.navigate("https://example.com")

# Interact
agent.type_text("#search", "AI agents")
agent.click("button[type='submit']")

# Extract
results = agent.get_text(".results")

agent.stop()
</code></pre>
<h3 id="selenium-alternative"><a class="header" href="#selenium-alternative">Selenium Alternative</a></h3>
<pre><code class="language-python">from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class SeleniumAgent:
    """Browser automation with Selenium"""
    
    def __init__(self):
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        self.driver = webdriver.Chrome(options=options)
        self.wait = WebDriverWait(self.driver, 10)
    
    def navigate(self, url: str):
        """Navigate to URL"""
        self.driver.get(url)
    
    def click(self, selector: str, by: By = By.CSS_SELECTOR):
        """Click element"""
        element = self.wait.until(
            EC.element_to_be_clickable((by, selector))
        )
        element.click()
    
    def type_text(self, selector: str, text: str, by: By = By.CSS_SELECTOR):
        """Type text"""
        element = self.wait.until(
            EC.presence_of_element_located((by, selector))
        )
        element.clear()
        element.send_keys(text)
    
    def get_text(self, selector: str, by: By = By.CSS_SELECTOR) -&gt; str:
        """Get element text"""
        element = self.wait.until(
            EC.presence_of_element_located((by, selector))
        )
        return element.text
    
    def close(self):
        """Close browser"""
        self.driver.quit()
</code></pre>
<h2 id="web-scraping"><a class="header" href="#web-scraping">Web Scraping</a></h2>
<p>Extract structured data from websites.</p>
<h3 id="beautifulsoup-scraping"><a class="header" href="#beautifulsoup-scraping">BeautifulSoup Scraping</a></h3>
<pre><code class="language-python">import requests
from bs4 import BeautifulSoup
from typing import List, Dict

class WebScraper:
    """Web scraping agent"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def fetch_page(self, url: str) -&gt; Optional[BeautifulSoup]:
        """Fetch and parse page"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            return BeautifulSoup(response.content, 'html.parser')
        except Exception as e:
            print(f"Error fetching {url}: {e}")
            return None
    
    def extract_links(self, url: str) -&gt; List[str]:
        """Extract all links from page"""
        soup = self.fetch_page(url)
        if not soup:
            return []
        
        links = []
        for a in soup.find_all('a', href=True):
            href = a['href']
            # Convert relative to absolute
            if href.startswith('/'):
                from urllib.parse import urljoin
                href = urljoin(url, href)
            links.append(href)
        
        return links
    
    def extract_text(self, url: str, selector: Optional[str] = None) -&gt; str:
        """Extract text from page"""
        soup = self.fetch_page(url)
        if not soup:
            return ""
        
        if selector:
            element = soup.select_one(selector)
            return element.get_text(strip=True) if element else ""
        else:
            return soup.get_text(separator='\n', strip=True)
    
    def extract_structured_data(self, url: str, schema: dict) -&gt; List[Dict]:
        """Extract structured data based on schema"""
        soup = self.fetch_page(url)
        if not soup:
            return []
        
        results = []
        
        # Find all items matching container selector
        items = soup.select(schema['container'])
        
        for item in items:
            data = {}
            for field, selector in schema['fields'].items():
                element = item.select_one(selector)
                if element:
                    data[field] = element.get_text(strip=True)
            
            if data:
                results.append(data)
        
        return results

# Usage
scraper = WebScraper()

# Extract structured data
schema = {
    'container': '.product',
    'fields': {
        'name': '.product-name',
        'price': '.product-price',
        'rating': '.product-rating'
    }
}

products = scraper.extract_structured_data('https://example.com/products', schema)
</code></pre>
<h3 id="handling-dynamic-content"><a class="header" href="#handling-dynamic-content">Handling Dynamic Content</a></h3>
<pre><code class="language-python">class DynamicScraper:
    """Scrape JavaScript-rendered content"""
    
    def __init__(self):
        self.browser = BrowserAgent()
        self.browser.start()
    
    def scrape_dynamic(self, url: str, wait_selector: str = None) -&gt; str:
        """Scrape page with JavaScript"""
        self.browser.navigate(url)
        
        # Wait for content to load
        if wait_selector:
            self.browser.page.wait_for_selector(wait_selector)
        else:
            self.browser.page.wait_for_load_state("networkidle")
        
        # Get rendered HTML
        return self.browser.get_page_content()
    
    def scrape_infinite_scroll(self, url: str, max_scrolls: int = 10) -&gt; str:
        """Scrape infinite scroll pages"""
        self.browser.navigate(url)
        
        for _ in range(max_scrolls):
            # Scroll to bottom
            self.browser.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            
            # Wait for new content
            self.browser.page.wait_for_timeout(1000)
        
        return self.browser.get_page_content()
    
    def close(self):
        """Close browser"""
        self.browser.stop()
</code></pre>
<h2 id="form-filling-and-navigation"><a class="header" href="#form-filling-and-navigation">Form Filling and Navigation</a></h2>
<h3 id="automated-form-submission"><a class="header" href="#automated-form-submission">Automated Form Submission</a></h3>
<pre><code class="language-python">class FormAgent:
    """Agent that can fill and submit forms"""
    
    def __init__(self):
        self.browser = BrowserAgent()
        self.browser.start()
    
    def fill_form(self, url: str, form_data: dict) -&gt; dict:
        """Fill and submit form"""
        try:
            # Navigate to page
            self.browser.navigate(url)
            
            # Fill fields
            for selector, value in form_data.items():
                if isinstance(value, str):
                    self.browser.type_text(selector, value)
                elif value.get('type') == 'click':
                    self.browser.click(selector)
                elif value.get('type') == 'select':
                    self.browser.page.select_option(selector, value['value'])
            
            # Submit form
            submit_button = form_data.get('submit_button', 'button[type="submit"]')
            self.browser.click(submit_button)
            
            # Wait for response
            self.browser.page.wait_for_load_state("networkidle")
            
            return {
                "success": True,
                "url": self.browser.page.url,
                "title": self.browser.page.title()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def close(self):
        """Close browser"""
        self.browser.stop()

# Usage
agent = FormAgent()

form_data = {
    '#name': 'John Doe',
    '#email': 'john@example.com',
    '#message': 'Hello from agent!',
    'submit_button': '#submit-btn'
}

result = agent.fill_form('https://example.com/contact', form_data)
agent.close()
</code></pre>
<h3 id="multi-step-navigation"><a class="header" href="#multi-step-navigation">Multi-Step Navigation</a></h3>
<pre><code class="language-python">class NavigationAgent:
    """Agent for multi-step web workflows"""
    
    def __init__(self):
        self.browser = BrowserAgent()
        self.browser.start()
        self.history = []
    
    def execute_workflow(self, steps: List[dict]) -&gt; dict:
        """Execute multi-step workflow"""
        results = []
        
        for i, step in enumerate(steps):
            print(f"Step {i+1}: {step['action']}")
            
            try:
                if step['action'] == 'navigate':
                    result = self.browser.navigate(step['url'])
                
                elif step['action'] == 'click':
                    result = self.browser.click(step['selector'])
                
                elif step['action'] == 'type':
                    result = self.browser.type_text(step['selector'], step['text'])
                
                elif step['action'] == 'wait':
                    self.browser.page.wait_for_timeout(step['duration'])
                    result = {"success": True}
                
                elif step['action'] == 'extract':
                    text = self.browser.get_text(step['selector'])
                    result = {"success": True, "data": text}
                
                elif step['action'] == 'screenshot':
                    result = self.browser.screenshot(step.get('path', f'step_{i}.png'))
                
                else:
                    result = {"success": False, "error": "Unknown action"}
                
                results.append({
                    "step": i + 1,
                    "action": step['action'],
                    "result": result
                })
                
                self.history.append({
                    "url": self.browser.page.url,
                    "title": self.browser.page.title()
                })
                
                if not result.get('success', False):
                    break
                    
            except Exception as e:
                results.append({
                    "step": i + 1,
                    "action": step['action'],
                    "result": {"success": False, "error": str(e)}
                })
                break
        
        return {
            "completed": len(results),
            "total": len(steps),
            "results": results,
            "history": self.history
        }
    
    def close(self):
        """Close browser"""
        self.browser.stop()

# Usage
agent = NavigationAgent()

workflow = [
    {"action": "navigate", "url": "https://example.com"},
    {"action": "click", "selector": "#login-btn"},
    {"action": "type", "selector": "#username", "text": "user@example.com"},
    {"action": "type", "selector": "#password", "text": "password123"},
    {"action": "click", "selector": "#submit"},
    {"action": "wait", "duration": 2000},
    {"action": "extract", "selector": ".welcome-message"},
    {"action": "screenshot", "path": "logged-in.png"}
]

result = agent.execute_workflow(workflow)
agent.close()
</code></pre>
<h2 id="screenshot-and-visual-understanding"><a class="header" href="#screenshot-and-visual-understanding">Screenshot and Visual Understanding</a></h2>
<h3 id="taking-screenshots"><a class="header" href="#taking-screenshots">Taking Screenshots</a></h3>
<pre><code class="language-python">class ScreenshotAgent:
    """Agent for visual capture and analysis"""
    
    def __init__(self):
        self.browser = BrowserAgent()
        self.browser.start()
        self.client = openai.OpenAI()
    
    def capture_and_analyze(self, url: str, question: str) -&gt; dict:
        """Capture screenshot and analyze with vision model"""
        # Navigate and capture
        self.browser.navigate(url)
        screenshot_path = "temp_screenshot.png"
        self.browser.screenshot(screenshot_path)
        
        # Analyze with vision model
        import base64
        with open(screenshot_path, "rb") as f:
            image_data = base64.b64encode(f.read()).decode()
        
        response = self.client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": question},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )
        
        return {
            "url": url,
            "question": question,
            "analysis": response.choices[0].message.content,
            "screenshot": screenshot_path
        }
    
    def compare_pages(self, url1: str, url2: str) -&gt; dict:
        """Compare two pages visually"""
        # Capture both
        self.browser.navigate(url1)
        self.browser.screenshot("page1.png")
        
        self.browser.navigate(url2)
        self.browser.screenshot("page2.png")
        
        # Compare with vision model
        question = "What are the main differences between these two pages?"
        
        # Would need to send both images to vision model
        # Implementation depends on specific vision API
        
        return {
            "url1": url1,
            "url2": url2,
            "screenshot1": "page1.png",
            "screenshot2": "page2.png"
        }
    
    def close(self):
        """Close browser"""
        self.browser.stop()
</code></pre>
<h3 id="element-detection"><a class="header" href="#element-detection">Element Detection</a></h3>
<pre><code class="language-python">class ElementDetector:
    """Detect and locate elements on page"""
    
    def __init__(self):
        self.browser = BrowserAgent()
        self.browser.start()
    
    def find_element_by_description(self, url: str, description: str) -&gt; Optional[str]:
        """Find element selector by natural language description"""
        self.browser.navigate(url)
        
        # Get page structure
        elements = self.browser.page.evaluate("""
            () =&gt; {
                const elements = [];
                document.querySelectorAll('button, a, input, select, textarea').forEach(el =&gt; {
                    elements.push({
                        tag: el.tagName,
                        text: el.textContent.trim(),
                        id: el.id,
                        class: el.className,
                        type: el.type
                    });
                });
                return elements;
            }
        """)
        
        # Use LLM to match description to element
        prompt = f"""Find the element matching this description: {description}

Available elements:
{json.dumps(elements, indent=2)}

Return the best CSS selector to target this element:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.choices[0].message.content.strip()
    
    def close(self):
        """Close browser"""
        self.browser.stop()
</code></pre>
<h2 id="complete-web-interaction-agent"><a class="header" href="#complete-web-interaction-agent">Complete Web Interaction Agent</a></h2>
<pre><code class="language-python">class WebAgent:
    """Complete web interaction agent"""
    
    def __init__(self):
        self.browser = BrowserAgent()
        self.browser.start()
        self.scraper = WebScraper()
        self.client = openai.OpenAI()
    
    def execute_task(self, task: str, url: str) -&gt; str:
        """Execute web task from natural language"""
        # Generate action plan
        plan = self.generate_plan(task, url)
        
        # Execute plan
        results = []
        for step in plan:
            result = self.execute_step(step)
            results.append(result)
        
        # Summarize results
        return self.summarize_results(task, results)
    
    def generate_plan(self, task: str, url: str) -&gt; List[dict]:
        """Generate action plan for task"""
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": """Generate a step-by-step plan for web automation.

Available actions:
- navigate: Go to URL
- click: Click element (provide selector)
- type: Type text (provide selector and text)
- extract: Extract text (provide selector)
- wait: Wait for duration (milliseconds)
- screenshot: Take screenshot

Return JSON array of steps."""
                },
                {
                    "role": "user",
                    "content": f"Task: {task}\nStarting URL: {url}"
                }
            ],
            temperature=0.2
        )
        
        import json
        return json.loads(response.choices[0].message.content)
    
    def execute_step(self, step: dict) -&gt; dict:
        """Execute single step"""
        action = step['action']
        
        try:
            if action == 'navigate':
                return self.browser.navigate(step['url'])
            elif action == 'click':
                return self.browser.click(step['selector'])
            elif action == 'type':
                return self.browser.type_text(step['selector'], step['text'])
            elif action == 'extract':
                text = self.browser.get_text(step['selector'])
                return {"success": True, "data": text}
            elif action == 'wait':
                self.browser.page.wait_for_timeout(step['duration'])
                return {"success": True}
            elif action == 'screenshot':
                return self.browser.screenshot(step.get('path', 'screenshot.png'))
            else:
                return {"success": False, "error": f"Unknown action: {action}"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def summarize_results(self, task: str, results: List[dict]) -&gt; str:
        """Summarize execution results"""
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "user",
                    "content": f"""Summarize the results of this web automation task:

Task: {task}

Results:
{json.dumps(results, indent=2)}

Provide a clear summary of what was accomplished:"""
                }
            ]
        )
        
        return response.choices[0].message.content
    
    def close(self):
        """Close browser"""
        self.browser.stop()

# Usage
agent = WebAgent()
result = agent.execute_task(
    "Search for 'AI agents' on the website and extract the top 3 results",
    "https://example.com"
)
print(result)
agent.close()
</code></pre>
<h2 id="best-practices-5"><a class="header" href="#best-practices-5">Best Practices</a></h2>
<ol>
<li><strong>Respect robots.txt</strong>: Check if scraping is allowed</li>
<li><strong>Rate limiting</strong>: Donâ€™t overwhelm servers</li>
<li><strong>Use headless mode</strong>: Faster and less resource-intensive</li>
<li><strong>Handle timeouts</strong>: Set reasonable wait times</li>
<li><strong>Error recovery</strong>: Retry failed operations</li>
<li><strong>Clean up resources</strong>: Close browsers properly</li>
<li><strong>User agent</strong>: Identify your bot appropriately</li>
<li><strong>Cache responses</strong>: Avoid redundant requests</li>
<li><strong>Validate selectors</strong>: Check elements exist before interacting</li>
<li><strong>Monitor performance</strong>: Track execution time</li>
</ol>
<h2 id="common-pitfalls-1"><a class="header" href="#common-pitfalls-1">Common Pitfalls</a></h2>
<h3 id="pitfall-1-stale-selectors"><a class="header" href="#pitfall-1-stale-selectors">Pitfall 1: Stale Selectors</a></h3>
<p><strong>Problem</strong>: Element selectors change
<strong>Solution</strong>: Use more robust selectors (data attributes, ARIA labels)</p>
<h3 id="pitfall-2-race-conditions"><a class="header" href="#pitfall-2-race-conditions">Pitfall 2: Race Conditions</a></h3>
<p><strong>Problem</strong>: Clicking before element is ready
<strong>Solution</strong>: Use explicit waits</p>
<h3 id="pitfall-3-memory-leaks"><a class="header" href="#pitfall-3-memory-leaks">Pitfall 3: Memory Leaks</a></h3>
<p><strong>Problem</strong>: Not closing browsers
<strong>Solution</strong>: Always close in finally block or use context managers</p>
<h3 id="pitfall-4-detection"><a class="header" href="#pitfall-4-detection">Pitfall 4: Detection</a></h3>
<p><strong>Problem</strong>: Website blocks automated access
<strong>Solution</strong>: Use stealth plugins, rotate user agents, add delays</p>
<h2 id="next-steps-9"><a class="header" href="#next-steps-9">Next Steps</a></h2>
<p>Chapter 4 (Agent Tools &amp; Capabilities) is complete! You now understand code execution, data access, and web interaction. In Chapter 5, weâ€™ll explore production-ready agents including reliability, testing, and monitoring.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="reliability--safety"><a class="header" href="#reliability--safety">Reliability &amp; Safety</a></h1>
<h2 id="module-5-learning-objectives"><a class="header" href="#module-5-learning-objectives">Module 5: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Implement input validation and guardrails</li>
<li>âœ“ Design comprehensive testing strategies</li>
<li>âœ“ Set up monitoring and observability systems</li>
<li>âœ“ Handle failures gracefully with retries and fallbacks</li>
<li>âœ“ Measure and improve agent reliability</li>
</ul>
<hr>
<h2 id="input-validation-and-sanitization"><a class="header" href="#input-validation-and-sanitization">Input Validation and Sanitization</a></h2>
<p>Never trust user input. Always validate and sanitize.</p>
<h3 id="input-validation"><a class="header" href="#input-validation">Input Validation</a></h3>
<pre><code class="language-python">from typing import Optional
import re

class InputValidator:
    """Validate user inputs"""
    
    def __init__(self):
        self.max_input_length = 10000
        self.max_file_size = 10 * 1024 * 1024  # 10MB
    
    def validate_text_input(self, text: str) -&gt; dict:
        """Validate text input"""
        errors = []
        
        # Check type
        if not isinstance(text, str):
            return {"valid": False, "errors": ["Input must be string"]}
        
        # Check length
        if len(text) &gt; self.max_input_length:
            errors.append(f"Input too long (max {self.max_input_length} chars)")
        
        # Check for null bytes
        if '\x00' in text:
            errors.append("Invalid characters detected")
        
        # Check for control characters
        if any(ord(c) &lt; 32 and c not in '\n\r\t' for c in text):
            errors.append("Control characters not allowed")
        
        return {
            "valid": len(errors) == 0,
            "errors": errors
        }
    
    def validate_url(self, url: str) -&gt; dict:
        """Validate URL"""
        if not isinstance(url, str):
            return {"valid": False, "errors": ["URL must be string"]}
        
        # Basic URL pattern
        url_pattern = re.compile(
            r'^https?://'  # http:// or https://
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain
            r'localhost|'  # localhost
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # IP
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        
        if not url_pattern.match(url):
            return {"valid": False, "errors": ["Invalid URL format"]}
        
        # Check for dangerous protocols
        if url.startswith(('file://', 'javascript:', 'data:')):
            return {"valid": False, "errors": ["Unsafe URL protocol"]}
        
        return {"valid": True, "errors": []}
    
    def validate_file_path(self, path: str, allowed_extensions: list = None) -&gt; dict:
        """Validate file path"""
        errors = []
        
        # Check for path traversal
        if '..' in path or path.startswith('/'):
            errors.append("Path traversal detected")
        
        # Check extension
        if allowed_extensions:
            ext = path.split('.')[-1].lower()
            if ext not in allowed_extensions:
                errors.append(f"File type not allowed. Allowed: {allowed_extensions}")
        
        return {
            "valid": len(errors) == 0,
            "errors": errors
        }
    
    def sanitize_text(self, text: str) -&gt; str:
        """Sanitize text input"""
        # Remove null bytes
        text = text.replace('\x00', '')
        
        # Remove control characters except newlines and tabs
        text = ''.join(c for c in text if ord(c) &gt;= 32 or c in '\n\r\t')
        
        # Trim whitespace
        text = text.strip()
        
        # Limit length
        if len(text) &gt; self.max_input_length:
            text = text[:self.max_input_length]
        
        return text
</code></pre>
<h3 id="sql-injection-prevention"><a class="header" href="#sql-injection-prevention">SQL Injection Prevention</a></h3>
<pre><code class="language-python">import sqlite3

class SafeDatabase:
    """Database access with SQL injection prevention"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
    
    def query(self, sql: str, params: tuple = ()) -&gt; list:
        """Execute query with parameterized statements"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # Always use parameterized queries
            cursor.execute(sql, params)
            results = cursor.fetchall()
            conn.close()
            return results
        except Exception as e:
            conn.close()
            raise Exception(f"Query error: {str(e)}")
    
    def safe_search(self, table: str, column: str, value: str) -&gt; list:
        """Safe search with validation"""
        # Validate table and column names (whitelist)
        allowed_tables = ['users', 'products', 'orders']
        allowed_columns = ['name', 'email', 'description', 'title']
        
        if table not in allowed_tables:
            raise ValueError(f"Invalid table: {table}")
        
        if column not in allowed_columns:
            raise ValueError(f"Invalid column: {column}")
        
        # Use parameterized query
        sql = f"SELECT * FROM {table} WHERE {column} LIKE ?"
        return self.query(sql, (f"%{value}%",))
</code></pre>
<h2 id="output-guardrails"><a class="header" href="#output-guardrails">Output Guardrails</a></h2>
<p>Ensure agent outputs are safe and appropriate.</p>
<h3 id="content-filtering"><a class="header" href="#content-filtering">Content Filtering</a></h3>
<pre><code class="language-python">class OutputGuardrails:
    """Filter and validate agent outputs"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.blocked_patterns = [
            r'\b\d{3}-\d{2}-\d{4}\b',  # SSN
            r'\b\d{16}\b',  # Credit card
            r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}',  # Email (if needed)
        ]
    
    def check_output(self, text: str) -&gt; dict:
        """Check if output is safe"""
        issues = []
        
        # Check for PII
        for pattern in self.blocked_patterns:
            if re.search(pattern, text):
                issues.append(f"Potential PII detected: {pattern}")
        
        # Check for harmful content
        if self.contains_harmful_content(text):
            issues.append("Potentially harmful content detected")
        
        # Check length
        if len(text) &gt; 50000:
            issues.append("Output too long")
        
        return {
            "safe": len(issues) == 0,
            "issues": issues
        }
    
    def contains_harmful_content(self, text: str) -&gt; bool:
        """Check for harmful content using moderation API"""
        try:
            response = self.client.moderations.create(input=text)
            result = response.results[0]
            
            # Check if any category is flagged
            return any([
                result.categories.hate,
                result.categories.violence,
                result.categories.self_harm,
                result.categories.sexual,
            ])
        except:
            return False
    
    def redact_pii(self, text: str) -&gt; str:
        """Redact PII from text"""
        # Redact SSN
        text = re.sub(r'\b\d{3}-\d{2}-\d{4}\b', '[REDACTED-SSN]', text)
        
        # Redact credit cards
        text = re.sub(r'\b\d{16}\b', '[REDACTED-CC]', text)
        
        # Redact emails (if needed)
        text = re.sub(
            r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}',
            '[REDACTED-EMAIL]',
            text
        )
        
        return text
    
    def filter_output(self, text: str) -&gt; dict:
        """Filter and clean output"""
        check = self.check_output(text)
        
        if not check['safe']:
            # Redact PII
            text = self.redact_pii(text)
            
            # Re-check
            check = self.check_output(text)
        
        return {
            "text": text,
            "safe": check['safe'],
            "issues": check['issues']
        }
</code></pre>
<h3 id="response-validation"><a class="header" href="#response-validation">Response Validation</a></h3>
<pre><code class="language-python">class ResponseValidator:
    """Validate agent responses"""
    
    def validate_response(self, response: str, expected_format: str = None) -&gt; dict:
        """Validate response format and content"""
        errors = []
        
        # Check not empty
        if not response or not response.strip():
            errors.append("Empty response")
        
        # Check format if specified
        if expected_format == 'json':
            try:
                json.loads(response)
            except json.JSONDecodeError:
                errors.append("Invalid JSON format")
        
        elif expected_format == 'markdown':
            # Basic markdown validation
            if not any(marker in response for marker in ['#', '*', '-', '`']):
                errors.append("Not valid markdown")
        
        # Check for refusal patterns
        refusal_patterns = [
            "I cannot", "I'm unable to", "I can't",
            "I don't have access", "I'm not able to"
        ]
        
        if any(pattern.lower() in response.lower() for pattern in refusal_patterns):
            errors.append("Agent refused to complete task")
        
        return {
            "valid": len(errors) == 0,
            "errors": errors
        }
</code></pre>
<h2 id="rate-limiting-and-cost-control"><a class="header" href="#rate-limiting-and-cost-control">Rate Limiting and Cost Control</a></h2>
<p>Prevent runaway costs and abuse.</p>
<h3 id="rate-limiter"><a class="header" href="#rate-limiter">Rate Limiter</a></h3>
<pre><code class="language-python">import time
from collections import defaultdict
from threading import Lock

class RateLimiter:
    """Rate limit API calls"""
    
    def __init__(self):
        self.requests = defaultdict(list)
        self.lock = Lock()
    
    def check_rate_limit(self, 
                         user_id: str,
                         max_requests: int = 100,
                         window_seconds: int = 3600) -&gt; dict:
        """Check if user is within rate limit"""
        with self.lock:
            current_time = time.time()
            
            # Remove old requests outside window
            self.requests[user_id] = [
                req_time for req_time in self.requests[user_id]
                if current_time - req_time &lt; window_seconds
            ]
            
            # Check limit
            if len(self.requests[user_id]) &gt;= max_requests:
                return {
                    "allowed": False,
                    "remaining": 0,
                    "reset_in": window_seconds - (current_time - self.requests[user_id][0])
                }
            
            # Add current request
            self.requests[user_id].append(current_time)
            
            return {
                "allowed": True,
                "remaining": max_requests - len(self.requests[user_id]),
                "reset_in": window_seconds
            }
</code></pre>
<h3 id="cost-tracker"><a class="header" href="#cost-tracker">Cost Tracker</a></h3>
<pre><code class="language-python">class CostTracker:
    """Track and limit API costs"""
    
    def __init__(self, max_cost_per_user: float = 10.0):
        self.costs = defaultdict(float)
        self.max_cost_per_user = max_cost_per_user
        self.lock = Lock()
    
    def estimate_cost(self, model: str, input_tokens: int, output_tokens: int) -&gt; float:
        """Estimate cost for API call"""
        # Pricing per 1K tokens (example rates)
        pricing = {
            'gpt-4': {'input': 0.03, 'output': 0.06},
            'gpt-4-turbo': {'input': 0.01, 'output': 0.03},
            'gpt-3.5-turbo': {'input': 0.0005, 'output': 0.0015},
        }
        
        if model not in pricing:
            model = 'gpt-4'  # Default to most expensive
        
        cost = (
            (input_tokens / 1000) * pricing[model]['input'] +
            (output_tokens / 1000) * pricing[model]['output']
        )
        
        return cost
    
    def check_budget(self, user_id: str, estimated_cost: float) -&gt; dict:
        """Check if user has budget for request"""
        with self.lock:
            current_cost = self.costs[user_id]
            
            if current_cost + estimated_cost &gt; self.max_cost_per_user:
                return {
                    "allowed": False,
                    "current_cost": current_cost,
                    "max_cost": self.max_cost_per_user,
                    "remaining": self.max_cost_per_user - current_cost
                }
            
            return {
                "allowed": True,
                "current_cost": current_cost,
                "remaining": self.max_cost_per_user - current_cost - estimated_cost
            }
    
    def record_cost(self, user_id: str, cost: float):
        """Record actual cost"""
        with self.lock:
            self.costs[user_id] += cost
    
    def reset_user_cost(self, user_id: str):
        """Reset user's cost (e.g., monthly)"""
        with self.lock:
            self.costs[user_id] = 0.0
</code></pre>
<h2 id="failure-modes-and-fallbacks"><a class="header" href="#failure-modes-and-fallbacks">Failure Modes and Fallbacks</a></h2>
<p>Handle failures gracefully.</p>
<h3 id="retry-logic-1"><a class="header" href="#retry-logic-1">Retry Logic</a></h3>
<pre><code class="language-python">import time
from functools import wraps

def retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0):
    """Decorator for retry with exponential backoff"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise
                    
                    delay = base_delay * (2 ** attempt)
                    print(f"Attempt {attempt + 1} failed: {e}. Retrying in {delay}s...")
                    time.sleep(delay)
        
        return wrapper
    return decorator

# Usage
@retry_with_backoff(max_retries=3, base_delay=1.0)
def call_api(prompt: str) -&gt; str:
    """API call with retry"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content
</code></pre>
<h3 id="circuit-breaker"><a class="header" href="#circuit-breaker">Circuit Breaker</a></h3>
<pre><code class="language-python">class CircuitBreaker:
    """Circuit breaker pattern for API calls"""
    
    def __init__(self, failure_threshold: int = 5, timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failures = 0
        self.last_failure_time = None
        self.state = 'closed'  # closed, open, half-open
    
    def call(self, func, *args, **kwargs):
        """Execute function with circuit breaker"""
        if self.state == 'open':
            # Check if timeout has passed
            if time.time() - self.last_failure_time &gt; self.timeout:
                self.state = 'half-open'
            else:
                raise Exception("Circuit breaker is OPEN")
        
        try:
            result = func(*args, **kwargs)
            
            # Success - reset if in half-open
            if self.state == 'half-open':
                self.state = 'closed'
                self.failures = 0
            
            return result
            
        except Exception as e:
            self.failures += 1
            self.last_failure_time = time.time()
            
            if self.failures &gt;= self.failure_threshold:
                self.state = 'open'
            
            raise e
</code></pre>
<h3 id="fallback-strategies"><a class="header" href="#fallback-strategies">Fallback Strategies</a></h3>
<pre><code class="language-python">class FallbackAgent:
    """Agent with fallback strategies"""
    
    def __init__(self):
        self.primary_model = "gpt-4"
        self.fallback_model = "gpt-3.5-turbo"
        self.client = openai.OpenAI()
    
    def generate_with_fallback(self, prompt: str) -&gt; dict:
        """Try primary model, fallback to cheaper model if fails"""
        try:
            response = self.client.chat.completions.create(
                model=self.primary_model,
                messages=[{"role": "user", "content": prompt}],
                timeout=30
            )
            
            return {
                "success": True,
                "response": response.choices[0].message.content,
                "model": self.primary_model
            }
            
        except Exception as e:
            print(f"Primary model failed: {e}. Trying fallback...")
            
            try:
                response = self.client.chat.completions.create(
                    model=self.fallback_model,
                    messages=[{"role": "user", "content": prompt}],
                    timeout=30
                )
                
                return {
                    "success": True,
                    "response": response.choices[0].message.content,
                    "model": self.fallback_model,
                    "fallback": True
                }
                
            except Exception as e2:
                return {
                    "success": False,
                    "error": str(e2)
                }
    
    def execute_with_fallback(self, task: str, strategies: list) -&gt; dict:
        """Try multiple strategies in order"""
        for i, strategy in enumerate(strategies):
            try:
                result = strategy(task)
                return {
                    "success": True,
                    "result": result,
                    "strategy": i
                }
            except Exception as e:
                if i == len(strategies) - 1:
                    return {
                        "success": False,
                        "error": f"All strategies failed. Last error: {e}"
                    }
                continue
</code></pre>
<h2 id="complete-safe-agent"><a class="header" href="#complete-safe-agent">Complete Safe Agent</a></h2>
<pre><code class="language-python">class SafeAgent:
    """Production-ready agent with safety features"""
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.validator = InputValidator()
        self.guardrails = OutputGuardrails()
        self.rate_limiter = RateLimiter()
        self.cost_tracker = CostTracker()
        self.circuit_breaker = CircuitBreaker()
        self.client = openai.OpenAI()
    
    def process(self, user_input: str) -&gt; dict:
        """Process user input safely"""
        
        # 1. Validate input
        validation = self.validator.validate_text_input(user_input)
        if not validation['valid']:
            return {
                "success": False,
                "error": "Invalid input",
                "details": validation['errors']
            }
        
        # 2. Check rate limit
        rate_check = self.rate_limiter.check_rate_limit(self.user_id)
        if not rate_check['allowed']:
            return {
                "success": False,
                "error": "Rate limit exceeded",
                "reset_in": rate_check['reset_in']
            }
        
        # 3. Sanitize input
        clean_input = self.validator.sanitize_text(user_input)
        
        # 4. Estimate cost
        estimated_tokens = len(clean_input.split()) * 1.3  # Rough estimate
        estimated_cost = self.cost_tracker.estimate_cost(
            'gpt-4',
            int(estimated_tokens),
            500  # Estimated output
        )
        
        # 5. Check budget
        budget_check = self.cost_tracker.check_budget(self.user_id, estimated_cost)
        if not budget_check['allowed']:
            return {
                "success": False,
                "error": "Budget exceeded",
                "remaining": budget_check['remaining']
            }
        
        # 6. Generate response with circuit breaker
        try:
            response = self.circuit_breaker.call(
                self._generate_response,
                clean_input
            )
        except Exception as e:
            return {
                "success": False,
                "error": f"Generation failed: {str(e)}"
            }
        
        # 7. Validate output
        filtered = self.guardrails.filter_output(response)
        
        if not filtered['safe']:
            return {
                "success": False,
                "error": "Output failed safety check",
                "issues": filtered['issues']
            }
        
        # 8. Record actual cost
        self.cost_tracker.record_cost(self.user_id, estimated_cost)
        
        return {
            "success": True,
            "response": filtered['text'],
            "cost": estimated_cost,
            "remaining_budget": budget_check['remaining'] - estimated_cost
        }
    
    @retry_with_backoff(max_retries=3)
    def _generate_response(self, prompt: str) -&gt; str:
        """Generate response with retry"""
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful assistant. Never share personal information or harmful content."
                },
                {"role": "user", "content": prompt}
            ],
            timeout=30
        )
        
        return response.choices[0].message.content

# Usage
agent = SafeAgent(user_id="user123")
result = agent.process("What is the capital of France?")

if result['success']:
    print(result['response'])
else:
    print(f"Error: {result['error']}")
</code></pre>
<h2 id="best-practices-6"><a class="header" href="#best-practices-6">Best Practices</a></h2>
<ol>
<li><strong>Validate everything</strong>: Never trust input</li>
<li><strong>Sanitize data</strong>: Clean before processing</li>
<li><strong>Rate limit</strong>: Prevent abuse</li>
<li><strong>Track costs</strong>: Monitor spending</li>
<li><strong>Filter outputs</strong>: Check for harmful content</li>
<li><strong>Implement retries</strong>: Handle transient failures</li>
<li><strong>Use circuit breakers</strong>: Prevent cascading failures</li>
<li><strong>Have fallbacks</strong>: Multiple strategies</li>
<li><strong>Log everything</strong>: Track for debugging</li>
<li><strong>Test failure modes</strong>: Ensure graceful degradation</li>
</ol>
<h2 id="next-steps-10"><a class="header" href="#next-steps-10">Next Steps</a></h2>
<p>You now understand reliability and safety! Next, weâ€™ll explore evaluation and testing to ensure your agents work correctly.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="evaluation--testing"><a class="header" href="#evaluation--testing">Evaluation &amp; Testing</a></h1>
<h2 id="agent-benchmarks"><a class="header" href="#agent-benchmarks">Agent Benchmarks</a></h2>
<p>Measure agent performance systematically.</p>
<h3 id="creating-test-suites"><a class="header" href="#creating-test-suites">Creating Test Suites</a></h3>
<pre><code class="language-python">from dataclasses import dataclass
from typing import List, Callable
import time

@dataclass
class TestCase:
    """Single test case"""
    name: str
    input: str
    expected_output: str = None
    expected_behavior: str = None
    timeout: int = 30

@dataclass
class TestResult:
    """Test result"""
    test_name: str
    passed: bool
    actual_output: str
    expected_output: str
    execution_time: float
    error: str = None

class AgentTestSuite:
    """Test suite for agents"""
    
    def __init__(self, agent):
        self.agent = agent
        self.test_cases = []
        self.results = []
    
    def add_test(self, test_case: TestCase):
        """Add test case"""
        self.test_cases.append(test_case)
    
    def run_tests(self) -&gt; dict:
        """Run all tests"""
        self.results = []
        
        for test in self.test_cases:
            print(f"Running: {test.name}...")
            result = self.run_single_test(test)
            self.results.append(result)
        
        return self.generate_report()
    
    def run_single_test(self, test: TestCase) -&gt; TestResult:
        """Run single test"""
        start_time = time.time()
        
        try:
            # Execute agent
            actual_output = self.agent.process(test.input)
            execution_time = time.time() - start_time
            
            # Check result
            if test.expected_output:
                passed = self.check_output_match(actual_output, test.expected_output)
            elif test.expected_behavior:
                passed = self.check_behavior(actual_output, test.expected_behavior)
            else:
                passed = True  # Just check it doesn't crash
            
            return TestResult(
                test_name=test.name,
                passed=passed,
                actual_output=actual_output,
                expected_output=test.expected_output or test.expected_behavior,
                execution_time=execution_time
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            return TestResult(
                test_name=test.name,
                passed=False,
                actual_output="",
                expected_output=test.expected_output or test.expected_behavior,
                execution_time=execution_time,
                error=str(e)
            )
    
    def check_output_match(self, actual: str, expected: str) -&gt; bool:
        """Check if output matches expected"""
        # Exact match
        if actual.strip() == expected.strip():
            return True
        
        # Contains expected
        if expected.lower() in actual.lower():
            return True
        
        return False
    
    def check_behavior(self, output: str, behavior: str) -&gt; bool:
        """Check if output exhibits expected behavior"""
        # Use LLM to judge
        prompt = f"""Does this output exhibit the expected behavior?

Output: {output}

Expected behavior: {behavior}

Answer with just 'yes' or 'no':"""
        
        response = llm.generate(prompt).strip().lower()
        return response == 'yes'
    
    def generate_report(self) -&gt; dict:
        """Generate test report"""
        total = len(self.results)
        passed = sum(1 for r in self.results if r.passed)
        failed = total - passed
        
        avg_time = sum(r.execution_time for r in self.results) / total if total &gt; 0 else 0
        
        return {
            "total": total,
            "passed": passed,
            "failed": failed,
            "pass_rate": passed / total if total &gt; 0 else 0,
            "avg_execution_time": avg_time,
            "results": self.results
        }

# Usage
suite = AgentTestSuite(agent)

suite.add_test(TestCase(
    name="Basic math",
    input="What is 2 + 2?",
    expected_output="4"
))

suite.add_test(TestCase(
    name="Tool usage",
    input="Search for information about Python",
    expected_behavior="Uses search tool and provides relevant information"
))

report = suite.run_tests()
print(f"Pass rate: {report['pass_rate']:.1%}")
</code></pre>
<h3 id="standard-benchmarks"><a class="header" href="#standard-benchmarks">Standard Benchmarks</a></h3>
<pre><code class="language-python">class StandardBenchmarks:
    """Common agent benchmarks"""
    
    @staticmethod
    def get_math_benchmark() -&gt; List[TestCase]:
        """Math reasoning tests"""
        return [
            TestCase("Addition", "What is 123 + 456?", "579"),
            TestCase("Multiplication", "What is 25 * 17?", "425"),
            TestCase("Word problem", "If I have 3 apples and buy 2 more, how many do I have?", "5"),
            TestCase("Percentage", "What is 15% of 200?", "30"),
        ]
    
    @staticmethod
    def get_reasoning_benchmark() -&gt; List[TestCase]:
        """Logical reasoning tests"""
        return [
            TestCase(
                "Deduction",
                "All cats are animals. Fluffy is a cat. Is Fluffy an animal?",
                expected_behavior="Correctly deduces that Fluffy is an animal"
            ),
            TestCase(
                "Planning",
                "I need to make dinner. What steps should I take?",
                expected_behavior="Provides logical sequence of steps"
            ),
        ]
    
    @staticmethod
    def get_tool_usage_benchmark() -&gt; List[TestCase]:
        """Tool usage tests"""
        return [
            TestCase(
                "Search",
                "Find information about the Eiffel Tower",
                expected_behavior="Uses search tool and provides facts"
            ),
            TestCase(
                "Calculation",
                "Calculate the compound interest on $1000 at 5% for 3 years",
                expected_behavior="Uses calculator tool"
            ),
        ]
</code></pre>
<h2 id="success-metrics"><a class="header" href="#success-metrics">Success Metrics</a></h2>
<p>Define what success means for your agent.</p>
<h3 id="quantitative-metrics"><a class="header" href="#quantitative-metrics">Quantitative Metrics</a></h3>
<pre><code class="language-python">class AgentMetrics:
    """Track agent performance metrics"""
    
    def __init__(self):
        self.metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_execution_time": 0,
            "tool_calls": 0,
            "tokens_used": 0,
            "cost": 0.0
        }
    
    def record_request(self, 
                      success: bool,
                      execution_time: float,
                      tool_calls: int = 0,
                      tokens: int = 0,
                      cost: float = 0.0):
        """Record request metrics"""
        self.metrics["total_requests"] += 1
        
        if success:
            self.metrics["successful_requests"] += 1
        else:
            self.metrics["failed_requests"] += 1
        
        self.metrics["total_execution_time"] += execution_time
        self.metrics["tool_calls"] += tool_calls
        self.metrics["tokens_used"] += tokens
        self.metrics["cost"] += cost
    
    def get_summary(self) -&gt; dict:
        """Get metrics summary"""
        total = self.metrics["total_requests"]
        
        if total == 0:
            return self.metrics
        
        return {
            **self.metrics,
            "success_rate": self.metrics["successful_requests"] / total,
            "avg_execution_time": self.metrics["total_execution_time"] / total,
            "avg_tool_calls": self.metrics["tool_calls"] / total,
            "avg_tokens": self.metrics["tokens_used"] / total,
            "avg_cost": self.metrics["cost"] / total
        }
    
    def print_summary(self):
        """Print formatted summary"""
        summary = self.get_summary()
        
        print("Agent Performance Metrics")
        print("=" * 40)
        print(f"Total Requests: {summary['total_requests']}")
        print(f"Success Rate: {summary['success_rate']:.1%}")
        print(f"Avg Execution Time: {summary['avg_execution_time']:.2f}s")
        print(f"Avg Tool Calls: {summary['avg_tool_calls']:.1f}")
        print(f"Avg Tokens: {summary['avg_tokens']:.0f}")
        print(f"Avg Cost: ${summary['avg_cost']:.4f}")
        print(f"Total Cost: ${summary['cost']:.2f}")
</code></pre>
<h3 id="qualitative-metrics"><a class="header" href="#qualitative-metrics">Qualitative Metrics</a></h3>
<pre><code class="language-python">class QualityEvaluator:
    """Evaluate response quality"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def evaluate_response(self, 
                         question: str,
                         response: str,
                         criteria: List[str] = None) -&gt; dict:
        """Evaluate response quality"""
        
        if criteria is None:
            criteria = [
                "Accuracy: Is the information correct?",
                "Completeness: Does it fully answer the question?",
                "Clarity: Is it easy to understand?",
                "Relevance: Does it stay on topic?"
            ]
        
        scores = {}
        
        for criterion in criteria:
            score = self.score_criterion(question, response, criterion)
            criterion_name = criterion.split(':')[0]
            scores[criterion_name] = score
        
        return {
            "scores": scores,
            "average": sum(scores.values()) / len(scores),
            "passed": all(score &gt;= 3 for score in scores.values())
        }
    
    def score_criterion(self, question: str, response: str, criterion: str) -&gt; int:
        """Score response on single criterion (1-5)"""
        prompt = f"""Rate this response on the following criterion (1-5):

Question: {question}

Response: {response}

Criterion: {criterion}

Provide only a number from 1 (poor) to 5 (excellent):"""
        
        result = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        try:
            score = int(result.choices[0].message.content.strip())
            return max(1, min(5, score))  # Clamp to 1-5
        except:
            return 3  # Default to middle score
</code></pre>
<h2 id="unit-and-integration-testing"><a class="header" href="#unit-and-integration-testing">Unit and Integration Testing</a></h2>
<h3 id="unit-tests-for-components"><a class="header" href="#unit-tests-for-components">Unit Tests for Components</a></h3>
<pre><code class="language-python">import unittest

class TestAgentComponents(unittest.TestCase):
    """Unit tests for agent components"""
    
    def setUp(self):
        """Set up test fixtures"""
        self.agent = MyAgent()
    
    def test_input_validation(self):
        """Test input validation"""
        validator = InputValidator()
        
        # Valid input
        result = validator.validate_text_input("Hello world")
        self.assertTrue(result['valid'])
        
        # Invalid input (too long)
        long_text = "x" * 20000
        result = validator.validate_text_input(long_text)
        self.assertFalse(result['valid'])
    
    def test_tool_execution(self):
        """Test tool execution"""
        result = self.agent.execute_tool("calculate", {"expression": "2 + 2"})
        self.assertEqual(result, "4")
    
    def test_memory_storage(self):
        """Test memory system"""
        self.agent.memory.add("user_name", "Alice")
        retrieved = self.agent.memory.get("user_name")
        self.assertEqual(retrieved, "Alice")
    
    def test_error_handling(self):
        """Test error handling"""
        # Should not crash on invalid tool
        result = self.agent.execute_tool("nonexistent_tool", {})
        self.assertIn("error", result.lower())
    
    def tearDown(self):
        """Clean up"""
        pass

# Run tests
if __name__ == '__main__':
    unittest.main()
</code></pre>
<h3 id="integration-tests"><a class="header" href="#integration-tests">Integration Tests</a></h3>
<pre><code class="language-python">class TestAgentIntegration(unittest.TestCase):
    """Integration tests for full agent"""
    
    def test_end_to_end_query(self):
        """Test complete query flow"""
        agent = MyAgent()
        
        response = agent.process("What is 2 + 2?")
        
        self.assertIsNotNone(response)
        self.assertIn("4", response)
    
    def test_multi_step_task(self):
        """Test multi-step task execution"""
        agent = MyAgent()
        
        response = agent.process("Search for Python tutorials and summarize the top result")
        
        # Should use search tool
        self.assertTrue(agent.tool_used("search"))
        
        # Should provide summary
        self.assertGreater(len(response), 50)
    
    def test_error_recovery(self):
        """Test error recovery"""
        agent = MyAgent()
        
        # Simulate tool failure
        agent.tools["search"] = lambda x: raise_error()
        
        response = agent.process("Search for something")
        
        # Should handle gracefully
        self.assertIsNotNone(response)
        self.assertNotIn("Traceback", response)
    
    def test_rate_limiting(self):
        """Test rate limiting"""
        agent = MyAgent()
        
        # Make many requests
        for i in range(150):
            response = agent.process(f"Request {i}")
        
        # Should be rate limited
        self.assertTrue(agent.was_rate_limited())
</code></pre>
<h3 id="property-based-testing"><a class="header" href="#property-based-testing">Property-Based Testing</a></h3>
<pre><code class="language-python">from hypothesis import given, strategies as st

class TestAgentProperties(unittest.TestCase):
    """Property-based tests"""
    
    @given(st.text(min_size=1, max_size=1000))
    def test_agent_handles_any_text(self, text):
        """Agent should handle any text input without crashing"""
        agent = MyAgent()
        
        try:
            response = agent.process(text)
            # Should return something
            self.assertIsNotNone(response)
        except Exception as e:
            # Should not crash
            self.fail(f"Agent crashed on input: {text[:50]}... Error: {e}")
    
    @given(st.integers(min_value=-1000, max_value=1000))
    def test_calculator_tool(self, number):
        """Calculator should handle any integer"""
        agent = MyAgent()
        
        result = agent.execute_tool("calculate", {"expression": f"{number} + 1"})
        expected = str(number + 1)
        
        self.assertEqual(result, expected)
</code></pre>
<h2 id="human-evaluation-frameworks"><a class="header" href="#human-evaluation-frameworks">Human Evaluation Frameworks</a></h2>
<h3 id="collecting-human-feedback"><a class="header" href="#collecting-human-feedback">Collecting Human Feedback</a></h3>
<pre><code class="language-python">class HumanEvaluator:
    """Collect human evaluations"""
    
    def __init__(self):
        self.evaluations = []
    
    def request_evaluation(self, 
                          question: str,
                          response: str,
                          evaluator_id: str) -&gt; dict:
        """Request human evaluation"""
        
        print(f"\n{'='*60}")
        print(f"Question: {question}")
        print(f"\nResponse: {response}")
        print(f"\n{'='*60}")
        
        # Collect ratings
        ratings = {}
        
        criteria = [
            ("accuracy", "Is the response accurate? (1-5)"),
            ("helpfulness", "Is the response helpful? (1-5)"),
            ("clarity", "Is the response clear? (1-5)"),
        ]
        
        for key, prompt in criteria:
            while True:
                try:
                    score = int(input(f"{prompt}: "))
                    if 1 &lt;= score &lt;= 5:
                        ratings[key] = score
                        break
                except ValueError:
                    pass
        
        # Collect feedback
        feedback = input("\nAdditional feedback (optional): ")
        
        evaluation = {
            "question": question,
            "response": response,
            "evaluator_id": evaluator_id,
            "ratings": ratings,
            "feedback": feedback,
            "timestamp": time.time()
        }
        
        self.evaluations.append(evaluation)
        return evaluation
    
    def get_summary(self) -&gt; dict:
        """Get evaluation summary"""
        if not self.evaluations:
            return {}
        
        # Average ratings
        avg_ratings = {}
        for criterion in ["accuracy", "helpfulness", "clarity"]:
            scores = [e["ratings"][criterion] for e in self.evaluations]
            avg_ratings[criterion] = sum(scores) / len(scores)
        
        return {
            "total_evaluations": len(self.evaluations),
            "average_ratings": avg_ratings,
            "overall_score": sum(avg_ratings.values()) / len(avg_ratings)
        }
</code></pre>
<h3 id="ab-testing"><a class="header" href="#ab-testing">A/B Testing</a></h3>
<pre><code class="language-python">class ABTest:
    """A/B test different agent versions"""
    
    def __init__(self, agent_a, agent_b):
        self.agent_a = agent_a
        self.agent_b = agent_b
        self.results = {"a": [], "b": []}
    
    def run_test(self, test_cases: List[str], evaluator) -&gt; dict:
        """Run A/B test"""
        
        for i, test_case in enumerate(test_cases):
            # Alternate between agents
            if i % 2 == 0:
                agent = self.agent_a
                variant = "a"
            else:
                agent = self.agent_b
                variant = "b"
            
            # Get response
            response = agent.process(test_case)
            
            # Evaluate
            evaluation = evaluator.evaluate_response(test_case, response)
            
            self.results[variant].append(evaluation)
        
        return self.compare_results()
    
    def compare_results(self) -&gt; dict:
        """Compare A vs B"""
        avg_a = sum(r["average"] for r in self.results["a"]) / len(self.results["a"])
        avg_b = sum(r["average"] for r in self.results["b"]) / len(self.results["b"])
        
        return {
            "agent_a_score": avg_a,
            "agent_b_score": avg_b,
            "winner": "a" if avg_a &gt; avg_b else "b",
            "difference": abs(avg_a - avg_b)
        }
</code></pre>
<h2 id="automated-testing-pipeline"><a class="header" href="#automated-testing-pipeline">Automated Testing Pipeline</a></h2>
<pre><code class="language-python">class TestPipeline:
    """Automated testing pipeline"""
    
    def __init__(self, agent):
        self.agent = agent
        self.test_suite = AgentTestSuite(agent)
        self.metrics = AgentMetrics()
        self.evaluator = QualityEvaluator()
    
    def run_full_pipeline(self) -&gt; dict:
        """Run complete test pipeline"""
        results = {}
        
        # 1. Unit tests
        print("Running unit tests...")
        results["unit_tests"] = self.run_unit_tests()
        
        # 2. Integration tests
        print("Running integration tests...")
        results["integration_tests"] = self.run_integration_tests()
        
        # 3. Benchmark tests
        print("Running benchmarks...")
        results["benchmarks"] = self.run_benchmarks()
        
        # 4. Quality evaluation
        print("Running quality evaluation...")
        results["quality"] = self.run_quality_evaluation()
        
        # 5. Performance metrics
        print("Collecting performance metrics...")
        results["performance"] = self.metrics.get_summary()
        
        # 6. Generate report
        report = self.generate_report(results)
        
        return report
    
    def run_unit_tests(self) -&gt; dict:
        """Run unit tests"""
        loader = unittest.TestLoader()
        suite = loader.loadTestsFromTestCase(TestAgentComponents)
        runner = unittest.TextTestRunner(verbosity=0)
        result = runner.run(suite)
        
        return {
            "total": result.testsRun,
            "passed": result.testsRun - len(result.failures) - len(result.errors),
            "failed": len(result.failures) + len(result.errors)
        }
    
    def run_integration_tests(self) -&gt; dict:
        """Run integration tests"""
        loader = unittest.TestLoader()
        suite = loader.loadTestsFromTestCase(TestAgentIntegration)
        runner = unittest.TextTestRunner(verbosity=0)
        result = runner.run(suite)
        
        return {
            "total": result.testsRun,
            "passed": result.testsRun - len(result.failures) - len(result.errors),
            "failed": len(result.failures) + len(result.errors)
        }
    
    def run_benchmarks(self) -&gt; dict:
        """Run benchmark tests"""
        # Add standard benchmarks
        for test in StandardBenchmarks.get_math_benchmark():
            self.test_suite.add_test(test)
        
        for test in StandardBenchmarks.get_reasoning_benchmark():
            self.test_suite.add_test(test)
        
        return self.test_suite.run_tests()
    
    def run_quality_evaluation(self) -&gt; dict:
        """Run quality evaluation"""
        test_cases = [
            ("What is Python?", "Python is a high-level programming language..."),
            ("How do I sort a list?", "You can use the sorted() function..."),
        ]
        
        evaluations = []
        for question, response in test_cases:
            eval_result = self.evaluator.evaluate_response(question, response)
            evaluations.append(eval_result)
        
        avg_score = sum(e["average"] for e in evaluations) / len(evaluations)
        
        return {
            "evaluations": evaluations,
            "average_score": avg_score
        }
    
    def generate_report(self, results: dict) -&gt; dict:
        """Generate comprehensive report"""
        return {
            "timestamp": time.time(),
            "summary": {
                "unit_tests_passed": results["unit_tests"]["passed"],
                "integration_tests_passed": results["integration_tests"]["passed"],
                "benchmark_pass_rate": results["benchmarks"]["pass_rate"],
                "quality_score": results["quality"]["average_score"],
                "success_rate": results["performance"]["success_rate"]
            },
            "details": results
        }

# Usage
pipeline = TestPipeline(agent)
report = pipeline.run_full_pipeline()

print("\nTest Report Summary")
print("=" * 40)
for key, value in report["summary"].items():
    print(f"{key}: {value}")
</code></pre>
<h2 id="best-practices-7"><a class="header" href="#best-practices-7">Best Practices</a></h2>
<ol>
<li><strong>Test early and often</strong>: Continuous testing during development</li>
<li><strong>Automate testing</strong>: Run tests automatically on changes</li>
<li><strong>Use multiple metrics</strong>: Quantitative and qualitative</li>
<li><strong>Test edge cases</strong>: Unusual inputs, errors, limits</li>
<li><strong>Benchmark regularly</strong>: Track performance over time</li>
<li><strong>Get human feedback</strong>: Automated tests arenâ€™t enough</li>
<li><strong>Test in production</strong>: Monitor real usage</li>
<li><strong>Version your tests</strong>: Track test changes</li>
<li><strong>Document failures</strong>: Learn from what breaks</li>
<li><strong>Iterate based on results</strong>: Use tests to improve</li>
</ol>
<h2 id="next-steps-11"><a class="header" href="#next-steps-11">Next Steps</a></h2>
<p>You now understand evaluation and testing! Next, weâ€™ll explore monitoring and observability for production agents.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="monitoring--observability"><a class="header" href="#monitoring--observability">Monitoring &amp; Observability</a></h1>
<h2 id="logging-and-tracing"><a class="header" href="#logging-and-tracing">Logging and Tracing</a></h2>
<p>Track what your agent is doing at every step.</p>
<h3 id="structured-logging"><a class="header" href="#structured-logging">Structured Logging</a></h3>
<pre><code class="language-python">import logging
import json
from datetime import datetime
from typing import Any, Dict

class AgentLogger:
    """Structured logging for agents"""
    
    def __init__(self, agent_id: str, log_file: str = "agent.log"):
        self.agent_id = agent_id
        self.logger = logging.getLogger(agent_id)
        self.logger.setLevel(logging.INFO)
        
        # File handler
        handler = logging.FileHandler(log_file)
        handler.setFormatter(logging.Formatter('%(message)s'))
        self.logger.addHandler(handler)
        
        # Console handler
        console = logging.StreamHandler()
        console.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
        self.logger.addHandler(console)
    
    def log_event(self, 
                  event_type: str,
                  data: Dict[str, Any],
                  level: str = "info"):
        """Log structured event"""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "agent_id": self.agent_id,
            "event_type": event_type,
            "data": data
        }
        
        log_message = json.dumps(log_entry)
        
        if level == "info":
            self.logger.info(log_message)
        elif level == "warning":
            self.logger.warning(log_message)
        elif level == "error":
            self.logger.error(log_message)
        elif level == "debug":
            self.logger.debug(log_message)
    
    def log_request(self, user_id: str, input_text: str):
        """Log incoming request"""
        self.log_event("request", {
            "user_id": user_id,
            "input": input_text[:200],  # Truncate long inputs
            "input_length": len(input_text)
        })
    
    def log_response(self, user_id: str, output_text: str, execution_time: float):
        """Log response"""
        self.log_event("response", {
            "user_id": user_id,
            "output": output_text[:200],
            "output_length": len(output_text),
            "execution_time": execution_time
        })
    
    def log_tool_call(self, tool_name: str, parameters: dict, result: Any):
        """Log tool execution"""
        self.log_event("tool_call", {
            "tool": tool_name,
            "parameters": parameters,
            "result": str(result)[:200],
            "success": result is not None
        })
    
    def log_error(self, error_type: str, error_message: str, context: dict = None):
        """Log error"""
        self.log_event("error", {
            "error_type": error_type,
            "message": error_message,
            "context": context or {}
        }, level="error")

# Usage
logger = AgentLogger("agent-001")
logger.log_request("user123", "What is the weather?")
logger.log_tool_call("weather_api", {"location": "NYC"}, {"temp": 72})
logger.log_response("user123", "It's 72Â°F in NYC", 1.5)
</code></pre>
<h3 id="distributed-tracing"><a class="header" href="#distributed-tracing">Distributed Tracing</a></h3>
<pre><code class="language-python">import uuid
from contextlib import contextmanager
from typing import Optional

class Tracer:
    """Distributed tracing for agent operations"""
    
    def __init__(self):
        self.traces = {}
        self.current_trace = None
    
    @contextmanager
    def trace(self, operation_name: str, parent_id: Optional[str] = None):
        """Create trace span"""
        span_id = str(uuid.uuid4())
        trace_id = parent_id or str(uuid.uuid4())
        
        span = {
            "span_id": span_id,
            "trace_id": trace_id,
            "operation": operation_name,
            "start_time": time.time(),
            "parent_id": parent_id,
            "children": [],
            "metadata": {}
        }
        
        # Store current trace
        previous_trace = self.current_trace
        self.current_trace = span_id
        self.traces[span_id] = span
        
        try:
            yield span
        finally:
            # End span
            span["end_time"] = time.time()
            span["duration"] = span["end_time"] - span["start_time"]
            
            # Restore previous trace
            self.current_trace = previous_trace
    
    def add_metadata(self, key: str, value: Any):
        """Add metadata to current span"""
        if self.current_trace:
            self.traces[self.current_trace]["metadata"][key] = value
    
    def get_trace(self, trace_id: str) -&gt; dict:
        """Get full trace"""
        spans = [s for s in self.traces.values() if s["trace_id"] == trace_id]
        
        # Build tree
        root = [s for s in spans if s["parent_id"] is None][0]
        self._build_tree(root, spans)
        
        return root
    
    def _build_tree(self, node: dict, all_spans: list):
        """Build trace tree"""
        children = [s for s in all_spans if s["parent_id"] == node["span_id"]]
        node["children"] = children
        
        for child in children:
            self._build_tree(child, all_spans)

# Usage
tracer = Tracer()

with tracer.trace("agent_request") as trace:
    tracer.add_metadata("user_id", "user123")
    
    with tracer.trace("tool_call", parent_id=trace["span_id"]):
        tracer.add_metadata("tool", "search")
        # Execute tool
        pass
    
    with tracer.trace("generate_response", parent_id=trace["span_id"]):
        # Generate response
        pass

# View trace
full_trace = tracer.get_trace(trace["trace_id"])
</code></pre>
<h2 id="performance-metrics"><a class="header" href="#performance-metrics">Performance Metrics</a></h2>
<p>Track agent performance in real-time.</p>
<h3 id="metrics-collector"><a class="header" href="#metrics-collector">Metrics Collector</a></h3>
<pre><code class="language-python">from collections import defaultdict
from threading import Lock
import time

class MetricsCollector:
    """Collect and aggregate metrics"""
    
    def __init__(self):
        self.metrics = defaultdict(list)
        self.counters = defaultdict(int)
        self.lock = Lock()
    
    def record_metric(self, name: str, value: float, tags: dict = None):
        """Record a metric value"""
        with self.lock:
            self.metrics[name].append({
                "value": value,
                "timestamp": time.time(),
                "tags": tags or {}
            })
    
    def increment_counter(self, name: str, amount: int = 1):
        """Increment counter"""
        with self.lock:
            self.counters[name] += amount
    
    def get_stats(self, name: str, window_seconds: int = 3600) -&gt; dict:
        """Get statistics for metric"""
        with self.lock:
            current_time = time.time()
            
            # Filter to time window
            values = [
                m["value"] for m in self.metrics[name]
                if current_time - m["timestamp"] &lt; window_seconds
            ]
            
            if not values:
                return {}
            
            return {
                "count": len(values),
                "min": min(values),
                "max": max(values),
                "avg": sum(values) / len(values),
                "p50": self._percentile(values, 50),
                "p95": self._percentile(values, 95),
                "p99": self._percentile(values, 99)
            }
    
    def _percentile(self, values: list, percentile: int) -&gt; float:
        """Calculate percentile"""
        sorted_values = sorted(values)
        index = int(len(sorted_values) * percentile / 100)
        return sorted_values[min(index, len(sorted_values) - 1)]
    
    def get_counter(self, name: str) -&gt; int:
        """Get counter value"""
        with self.lock:
            return self.counters[name]
    
    def reset(self):
        """Reset all metrics"""
        with self.lock:
            self.metrics.clear()
            self.counters.clear()

# Usage
metrics = MetricsCollector()

# Record metrics
metrics.record_metric("response_time", 1.5, {"user": "user123"})
metrics.record_metric("response_time", 2.1, {"user": "user456"})
metrics.increment_counter("total_requests")
metrics.increment_counter("successful_requests")

# Get stats
stats = metrics.get_stats("response_time")
print(f"Avg response time: {stats['avg']:.2f}s")
print(f"P95 response time: {stats['p95']:.2f}s")
</code></pre>
<h3 id="real-time-dashboard"><a class="header" href="#real-time-dashboard">Real-Time Dashboard</a></h3>
<pre><code class="language-python">class MetricsDashboard:
    """Real-time metrics dashboard"""
    
    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics = metrics_collector
    
    def display(self):
        """Display current metrics"""
        print("\n" + "="*60)
        print("AGENT METRICS DASHBOARD")
        print("="*60)
        
        # Request metrics
        total = self.metrics.get_counter("total_requests")
        successful = self.metrics.get_counter("successful_requests")
        failed = self.metrics.get_counter("failed_requests")
        
        print(f"\nRequests:")
        print(f"  Total: {total}")
        print(f"  Successful: {successful}")
        print(f"  Failed: {failed}")
        if total &gt; 0:
            print(f"  Success Rate: {successful/total:.1%}")
        
        # Response time
        response_stats = self.metrics.get_stats("response_time")
        if response_stats:
            print(f"\nResponse Time:")
            print(f"  Average: {response_stats['avg']:.2f}s")
            print(f"  P50: {response_stats['p50']:.2f}s")
            print(f"  P95: {response_stats['p95']:.2f}s")
            print(f"  P99: {response_stats['p99']:.2f}s")
        
        # Tool usage
        tool_calls = self.metrics.get_counter("tool_calls")
        print(f"\nTool Calls: {tool_calls}")
        
        # Cost
        total_cost = self.metrics.get_counter("total_cost_cents") / 100
        print(f"\nTotal Cost: ${total_cost:.2f}")
        
        print("="*60 + "\n")
</code></pre>
<h2 id="cost-tracking"><a class="header" href="#cost-tracking">Cost Tracking</a></h2>
<p>Monitor spending in real-time.</p>
<h3 id="cost-monitor"><a class="header" href="#cost-monitor">Cost Monitor</a></h3>
<pre><code class="language-python">class CostMonitor:
    """Monitor and alert on costs"""
    
    def __init__(self, budget_limit: float = 100.0):
        self.budget_limit = budget_limit
        self.costs = defaultdict(float)
        self.lock = Lock()
        self.alerts = []
    
    def record_cost(self, 
                   user_id: str,
                   cost: float,
                   model: str,
                   tokens: int):
        """Record cost"""
        with self.lock:
            self.costs[user_id] += cost
            
            # Check for alerts
            if self.costs[user_id] &gt; self.budget_limit * 0.8:
                self.add_alert(
                    "warning",
                    f"User {user_id} at 80% of budget: ${self.costs[user_id]:.2f}"
                )
            
            if self.costs[user_id] &gt; self.budget_limit:
                self.add_alert(
                    "critical",
                    f"User {user_id} exceeded budget: ${self.costs[user_id]:.2f}"
                )
    
    def add_alert(self, level: str, message: str):
        """Add alert"""
        alert = {
            "level": level,
            "message": message,
            "timestamp": time.time()
        }
        self.alerts.append(alert)
        
        # Log alert
        if level == "critical":
            logger.log_event("cost_alert", alert, level="error")
        else:
            logger.log_event("cost_alert", alert, level="warning")
    
    def get_user_cost(self, user_id: str) -&gt; dict:
        """Get user's cost"""
        with self.lock:
            cost = self.costs[user_id]
            return {
                "cost": cost,
                "budget": self.budget_limit,
                "remaining": self.budget_limit - cost,
                "percentage": (cost / self.budget_limit) * 100
            }
    
    def get_total_cost(self) -&gt; float:
        """Get total cost across all users"""
        with self.lock:
            return sum(self.costs.values())
    
    def get_alerts(self, level: str = None) -&gt; list:
        """Get alerts"""
        if level:
            return [a for a in self.alerts if a["level"] == level]
        return self.alerts
</code></pre>
<h2 id="user-feedback-loops"><a class="header" href="#user-feedback-loops">User Feedback Loops</a></h2>
<p>Collect and act on user feedback.</p>
<h3 id="feedback-collector"><a class="header" href="#feedback-collector">Feedback Collector</a></h3>
<pre><code class="language-python">class FeedbackCollector:
    """Collect user feedback"""
    
    def __init__(self):
        self.feedback = []
        self.ratings = defaultdict(list)
    
    def collect_rating(self, 
                      user_id: str,
                      interaction_id: str,
                      rating: int,
                      comment: str = ""):
        """Collect user rating (1-5)"""
        feedback = {
            "user_id": user_id,
            "interaction_id": interaction_id,
            "rating": rating,
            "comment": comment,
            "timestamp": time.time()
        }
        
        self.feedback.append(feedback)
        self.ratings[user_id].append(rating)
        
        # Log feedback
        logger.log_event("user_feedback", feedback)
        
        # Alert on low ratings
        if rating &lt;= 2:
            logger.log_event("low_rating", feedback, level="warning")
    
    def get_average_rating(self, user_id: str = None) -&gt; float:
        """Get average rating"""
        if user_id:
            ratings = self.ratings[user_id]
        else:
            ratings = [f["rating"] for f in self.feedback]
        
        if not ratings:
            return 0.0
        
        return sum(ratings) / len(ratings)
    
    def get_recent_feedback(self, limit: int = 10) -&gt; list:
        """Get recent feedback"""
        return sorted(
            self.feedback,
            key=lambda x: x["timestamp"],
            reverse=True
        )[:limit]
    
    def get_low_ratings(self, threshold: int = 2) -&gt; list:
        """Get low-rated interactions"""
        return [
            f for f in self.feedback
            if f["rating"] &lt;= threshold
        ]
</code></pre>
<h3 id="feedback-analysis"><a class="header" href="#feedback-analysis">Feedback Analysis</a></h3>
<pre><code class="language-python">class FeedbackAnalyzer:
    """Analyze feedback patterns"""
    
    def __init__(self, feedback_collector: FeedbackCollector):
        self.collector = feedback_collector
        self.client = openai.OpenAI()
    
    def analyze_trends(self) -&gt; dict:
        """Analyze feedback trends"""
        recent = self.collector.get_recent_feedback(limit=100)
        
        if not recent:
            return {}
        
        # Calculate trends
        ratings = [f["rating"] for f in recent]
        
        return {
            "average_rating": sum(ratings) / len(ratings),
            "total_feedback": len(recent),
            "rating_distribution": {
                "5_star": sum(1 for r in ratings if r == 5),
                "4_star": sum(1 for r in ratings if r == 4),
                "3_star": sum(1 for r in ratings if r == 3),
                "2_star": sum(1 for r in ratings if r == 2),
                "1_star": sum(1 for r in ratings if r == 1),
            }
        }
    
    def identify_issues(self) -&gt; list:
        """Identify common issues from feedback"""
        low_ratings = self.collector.get_low_ratings()
        
        if not low_ratings:
            return []
        
        # Extract comments
        comments = [f["comment"] for f in low_ratings if f["comment"]]
        
        if not comments:
            return []
        
        # Use LLM to identify themes
        prompt = f"""Analyze these negative feedback comments and identify common themes:

{chr(10).join(comments[:20])}

List the top 3 issues:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.choices[0].message.content.split('\n')
</code></pre>
<h2 id="complete-monitoring-system"><a class="header" href="#complete-monitoring-system">Complete Monitoring System</a></h2>
<pre><code class="language-python">class AgentMonitor:
    """Complete monitoring system"""
    
    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.logger = AgentLogger(agent_id)
        self.tracer = Tracer()
        self.metrics = MetricsCollector()
        self.cost_monitor = CostMonitor()
        self.feedback = FeedbackCollector()
    
    def monitor_request(self, user_id: str, input_text: str):
        """Monitor incoming request"""
        self.logger.log_request(user_id, input_text)
        self.metrics.increment_counter("total_requests")
        
        return {
            "trace_id": str(uuid.uuid4()),
            "start_time": time.time()
        }
    
    def monitor_response(self, 
                        user_id: str,
                        output_text: str,
                        context: dict):
        """Monitor response"""
        execution_time = time.time() - context["start_time"]
        
        self.logger.log_response(user_id, output_text, execution_time)
        self.metrics.record_metric("response_time", execution_time)
        self.metrics.increment_counter("successful_requests")
    
    def monitor_tool_call(self, tool_name: str, parameters: dict, result: Any):
        """Monitor tool execution"""
        self.logger.log_tool_call(tool_name, parameters, result)
        self.metrics.increment_counter("tool_calls")
        self.metrics.increment_counter(f"tool_calls_{tool_name}")
    
    def monitor_cost(self, 
                    user_id: str,
                    model: str,
                    tokens: int,
                    cost: float):
        """Monitor cost"""
        self.cost_monitor.record_cost(user_id, cost, model, tokens)
        self.metrics.increment_counter("total_cost_cents", int(cost * 100))
    
    def monitor_error(self, error_type: str, error_message: str, context: dict):
        """Monitor error"""
        self.logger.log_error(error_type, error_message, context)
        self.metrics.increment_counter("failed_requests")
        self.metrics.increment_counter(f"error_{error_type}")
    
    def get_health_status(self) -&gt; dict:
        """Get system health status"""
        total = self.metrics.get_counter("total_requests")
        successful = self.metrics.get_counter("successful_requests")
        failed = self.metrics.get_counter("failed_requests")
        
        success_rate = successful / total if total &gt; 0 else 0
        
        response_stats = self.metrics.get_stats("response_time")
        avg_response_time = response_stats.get("avg", 0) if response_stats else 0
        
        # Determine health
        if success_rate &lt; 0.9 or avg_response_time &gt; 10:
            health = "unhealthy"
        elif success_rate &lt; 0.95 or avg_response_time &gt; 5:
            health = "degraded"
        else:
            health = "healthy"
        
        return {
            "status": health,
            "success_rate": success_rate,
            "avg_response_time": avg_response_time,
            "total_requests": total,
            "failed_requests": failed,
            "total_cost": self.cost_monitor.get_total_cost()
        }
    
    def generate_report(self) -&gt; dict:
        """Generate monitoring report"""
        return {
            "agent_id": self.agent_id,
            "timestamp": time.time(),
            "health": self.get_health_status(),
            "metrics": {
                "response_time": self.metrics.get_stats("response_time"),
                "requests": {
                    "total": self.metrics.get_counter("total_requests"),
                    "successful": self.metrics.get_counter("successful_requests"),
                    "failed": self.metrics.get_counter("failed_requests")
                },
                "tool_calls": self.metrics.get_counter("tool_calls")
            },
            "cost": {
                "total": self.cost_monitor.get_total_cost(),
                "alerts": self.cost_monitor.get_alerts()
            },
            "feedback": {
                "average_rating": self.feedback.get_average_rating(),
                "recent": self.feedback.get_recent_feedback(limit=5)
            }
        }

# Usage
monitor = AgentMonitor("agent-001")

# Monitor request
context = monitor.monitor_request("user123", "What is Python?")

# Monitor tool call
monitor.monitor_tool_call("search", {"query": "Python"}, "Results...")

# Monitor cost
monitor.monitor_cost("user123", "gpt-4", 500, 0.015)

# Monitor response
monitor.monitor_response("user123", "Python is...", context)

# Get health status
health = monitor.get_health_status()
print(f"System health: {health['status']}")

# Generate report
report = monitor.generate_report()
</code></pre>
<h2 id="alerting"><a class="header" href="#alerting">Alerting</a></h2>
<p>Set up alerts for critical issues.</p>
<h3 id="alert-manager"><a class="header" href="#alert-manager">Alert Manager</a></h3>
<pre><code class="language-python">class AlertManager:
    """Manage alerts and notifications"""
    
    def __init__(self):
        self.alert_rules = []
        self.active_alerts = []
    
    def add_rule(self, 
                 name: str,
                 condition: Callable,
                 severity: str,
                 message: str):
        """Add alert rule"""
        self.alert_rules.append({
            "name": name,
            "condition": condition,
            "severity": severity,
            "message": message
        })
    
    def check_alerts(self, metrics: dict):
        """Check all alert rules"""
        new_alerts = []
        
        for rule in self.alert_rules:
            if rule["condition"](metrics):
                alert = {
                    "name": rule["name"],
                    "severity": rule["severity"],
                    "message": rule["message"],
                    "timestamp": time.time(),
                    "metrics": metrics
                }
                new_alerts.append(alert)
                self.trigger_alert(alert)
        
        self.active_alerts.extend(new_alerts)
        return new_alerts
    
    def trigger_alert(self, alert: dict):
        """Trigger alert notification"""
        print(f"\nğŸš¨ ALERT [{alert['severity']}]: {alert['name']}")
        print(f"   {alert['message']}")
        
        # In production, send to:
        # - Email
        # - Slack
        # - PagerDuty
        # - etc.
    
    def get_active_alerts(self, severity: str = None) -&gt; list:
        """Get active alerts"""
        if severity:
            return [a for a in self.active_alerts if a["severity"] == severity]
        return self.active_alerts

# Setup alerts
alerts = AlertManager()

# High error rate
alerts.add_rule(
    name="High Error Rate",
    condition=lambda m: m.get("success_rate", 1) &lt; 0.9,
    severity="critical",
    message="Success rate below 90%"
)

# Slow response time
alerts.add_rule(
    name="Slow Response Time",
    condition=lambda m: m.get("avg_response_time", 0) &gt; 5,
    severity="warning",
    message="Average response time above 5 seconds"
)

# High cost
alerts.add_rule(
    name="High Cost",
    condition=lambda m: m.get("total_cost", 0) &gt; 50,
    severity="warning",
    message="Total cost exceeded $50"
)
</code></pre>
<h2 id="best-practices-8"><a class="header" href="#best-practices-8">Best Practices</a></h2>
<ol>
<li><strong>Log everything</strong>: Requests, responses, errors, tool calls</li>
<li><strong>Use structured logging</strong>: JSON format for easy parsing</li>
<li><strong>Track key metrics</strong>: Response time, success rate, cost</li>
<li><strong>Set up alerts</strong>: Be notified of issues immediately</li>
<li><strong>Monitor costs</strong>: Track spending in real-time</li>
<li><strong>Collect feedback</strong>: Learn from users</li>
<li><strong>Create dashboards</strong>: Visualize metrics</li>
<li><strong>Trace requests</strong>: Follow execution flow</li>
<li><strong>Analyze trends</strong>: Look for patterns over time</li>
<li><strong>Act on insights</strong>: Use data to improve</li>
</ol>
<h2 id="next-steps-12"><a class="header" href="#next-steps-12">Next Steps</a></h2>
<p>Chapter 5 (Production-Ready Agents) is complete! You now understand reliability, testing, and monitoring. Youâ€™re ready to build production-grade agents that are safe, tested, and observable.</p>
<p>Would you like to continue with Chapter 6 (Specialized Agent Types)?</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="coding-agents"><a class="header" href="#coding-agents">Coding Agents</a></h1>
<h2 id="module-6-learning-objectives"><a class="header" href="#module-6-learning-objectives">Module 6: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Build coding agents that analyze and generate code</li>
<li>âœ“ Create research agents with multi-source verification</li>
<li>âœ“ Implement task automation with workflow orchestration</li>
<li>âœ“ Design specialized agents for specific domains</li>
<li>âœ“ Integrate advanced capabilities into focused agents</li>
</ul>
<hr>
<h2 id="introduction-to-coding-agents"><a class="header" href="#introduction-to-coding-agents">Introduction to Coding Agents</a></h2>
<p>Coding agents are specialized AI systems that understand, generate, modify, and debug code. Theyâ€™re among the most powerful and practical agent applications.</p>
<h3 id="what-makes-coding-agents-special"><a class="header" href="#what-makes-coding-agents-special">What Makes Coding Agents Special?</a></h3>
<p><strong>Unique Capabilities</strong>:</p>
<ul>
<li>Understand code semantics and structure</li>
<li>Generate syntactically correct code</li>
<li>Refactor and optimize existing code</li>
<li>Debug and fix errors</li>
<li>Write tests and documentation</li>
<li>Work across multiple programming languages</li>
</ul>
<p><strong>Key Challenges</strong>:</p>
<ul>
<li>Code must be syntactically correct</li>
<li>Logic must be sound</li>
<li>Must handle edge cases</li>
<li>Need to understand context and dependencies</li>
<li>Security vulnerabilities must be avoided</li>
</ul>
<h3 id="types-of-coding-agents"><a class="header" href="#types-of-coding-agents">Types of Coding Agents</a></h3>
<ol>
<li><strong>Code Generation Agents</strong>: Write new code from specifications</li>
<li><strong>Code Review Agents</strong>: Analyze and suggest improvements</li>
<li><strong>Debugging Agents</strong>: Find and fix bugs</li>
<li><strong>Refactoring Agents</strong>: Improve code structure</li>
<li><strong>Testing Agents</strong>: Generate and run tests</li>
<li><strong>Documentation Agents</strong>: Write comments and docs</li>
</ol>
<h2 id="code-understanding-and-generation"><a class="header" href="#code-understanding-and-generation">Code Understanding and Generation</a></h2>
<h3 id="understanding-code-structure"><a class="header" href="#understanding-code-structure">Understanding Code Structure</a></h3>
<pre><code class="language-python">import ast
from typing import Dict, List, Any

class CodeAnalyzer:
    """Analyze code structure and semantics"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def parse_python_code(self, code: str) -&gt; Dict[str, Any]:
        """Parse Python code into AST"""
        try:
            tree = ast.parse(code)
            
            analysis = {
                "functions": [],
                "classes": [],
                "imports": [],
                "variables": [],
                "complexity": 0
            }
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    analysis["functions"].append({
                        "name": node.name,
                        "args": [arg.arg for arg in node.args.args],
                        "line": node.lineno,
                        "docstring": ast.get_docstring(node)
                    })
                
                elif isinstance(node, ast.ClassDef):
                    methods = [
                        n.name for n in node.body 
                        if isinstance(n, ast.FunctionDef)
                    ]
                    analysis["classes"].append({
                        "name": node.name,
                        "methods": methods,
                        "line": node.lineno,
                        "docstring": ast.get_docstring(node)
                    })
                
                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        analysis["imports"].append(alias.name)
                
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ""
                    for alias in node.names:
                        analysis["imports"].append(f"{module}.{alias.name}")
            
            return analysis
            
        except SyntaxError as e:
            return {
                "error": "Syntax error",
                "message": str(e),
                "line": e.lineno
            }
    
    def analyze_complexity(self, code: str) -&gt; Dict[str, Any]:
        """Analyze code complexity"""
        try:
            tree = ast.parse(code)
            
            complexity = {
                "cyclomatic": 1,  # Base complexity
                "lines_of_code": len(code.split('\n')),
                "num_functions": 0,
                "num_classes": 0,
                "max_nesting": 0
            }
            
            for node in ast.walk(tree):
                # Count decision points for cyclomatic complexity
                if isinstance(node, (ast.If, ast.While, ast.For, ast.ExceptHandler)):
                    complexity["cyclomatic"] += 1
                
                elif isinstance(node, ast.FunctionDef):
                    complexity["num_functions"] += 1
                
                elif isinstance(node, ast.ClassDef):
                    complexity["num_classes"] += 1
            
            return complexity
            
        except Exception as e:
            return {"error": str(e)}
    
    def extract_dependencies(self, code: str) -&gt; List[str]:
        """Extract external dependencies"""
        try:
            tree = ast.parse(code)
            dependencies = set()
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        # Get top-level package
                        pkg = alias.name.split('.')[0]
                        dependencies.add(pkg)
                
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        pkg = node.module.split('.')[0]
                        dependencies.add(pkg)
            
            # Filter out standard library
            stdlib = {'os', 'sys', 'json', 're', 'time', 'datetime', 'math'}
            external = dependencies - stdlib
            
            return sorted(external)
            
        except Exception as e:
            return []
    
    def understand_code_intent(self, code: str) -&gt; str:
        """Use LLM to understand what code does"""
        prompt = f"""Analyze this code and explain what it does:

```python
{code}
</code></pre>
<p>Provide:</p>
<ol>
<li>High-level purpose</li>
<li>Key functionality</li>
<li>Input/output</li>
<li>Any notable patterns or techniques</li>
</ol>
<p>Explanation:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    return response.choices[0].message.content
</code></pre>
<h1 id="usage-1"><a class="header" href="#usage-1">Usage</a></h1>
<p>analyzer = CodeAnalyzer()</p>
<p>code = â€œâ€â€œ
def fibonacci(n):
if n &lt;= 1:
return n
return fibonacci(n-1) + fibonacci(n-2)</p>
<p>class Calculator:
def add(self, a, b):
return a + b
â€œâ€â€œ</p>
<p>analysis = analyzer.parse_python_code(code)
print(fâ€œFunctions: {[f[â€˜nameâ€™] for f in analysis[â€˜functionsâ€™]]}â€œ)
print(fâ€œClasses: {[c[â€˜nameâ€™] for c in analysis[â€˜classesâ€™]]}â€)</p>
<p>complexity = analyzer.analyze_complexity(code)
print(fâ€œCyclomatic complexity: {complexity[â€˜cyclomaticâ€™]}â€œ)</p>
<p>intent = analyzer.understand_code_intent(code)
print(fâ€œIntent: {intent}â€œ)</p>
<pre><code>
### Generating Code from Specifications

```python
class CodeGenerator:
    """Generate code from natural language specifications"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def generate_function(self, 
                         description: str,
                         language: str = "python",
                         include_tests: bool = False) -&gt; Dict[str, str]:
        """Generate function from description"""
        
        prompt = f"""Generate a {language} function based on this description:

{description}

Requirements:
- Include type hints (if applicable)
- Add docstring with description, parameters, and return value
- Handle edge cases
- Include error handling
- Follow best practices
- Keep it simple and readable

{"Also generate unit tests for this function." if include_tests else ""}

Provide the code:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        
        code = response.choices[0].message.content
        
        # Extract code and tests
        parts = self.extract_code_blocks(code)
        
        return {
            "code": parts.get("main", code),
            "tests": parts.get("tests", "") if include_tests else None
        }
    
    def generate_class(self,
                      description: str,
                      methods: List[str] = None) -&gt; str:
        """Generate class from description"""
        
        methods_str = ""
        if methods:
            methods_str = f"\nMethods to implement:\n" + "\n".join(f"- {m}" for m in methods)
        
        prompt = f"""Generate a Python class based on this description:

{description}{methods_str}

Requirements:
- Include __init__ method
- Add docstrings for class and methods
- Use type hints
- Follow PEP 8 style guide
- Include example usage in docstring

Provide the code:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        
        return self.extract_code_blocks(response.choices[0].message.content)["main"]
    
    def generate_from_signature(self, signature: str) -&gt; str:
        """Generate function implementation from signature"""
        
        prompt = f"""Implement this function:

```python
{signature}
    pass
</code></pre>
<p>Provide a complete, working implementation with:</p>
<ul>
<li>Proper logic</li>
<li>Error handling</li>
<li>Edge case handling</li>
<li>Comments for complex parts</li>
</ul>
<p>Implementation:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    
    return self.extract_code_blocks(response.choices[0].message.content)["main"]

def extract_code_blocks(self, text: str) -&gt; Dict[str, str]:
    """Extract code blocks from markdown"""
    import re
    
    # Find all code blocks
    pattern = r'```(?:python)?\n(.*?)```'
    blocks = re.findall(pattern, text, re.DOTALL)
    
    if not blocks:
        return {"main": text}
    
    result = {"main": blocks[0]}
    
    if len(blocks) &gt; 1:
        result["tests"] = blocks[1]
    
    return result
</code></pre>
<h1 id="usage-1-1"><a class="header" href="#usage-1-1">Usage</a></h1>
<p>generator = CodeGenerator()</p>
<h1 id="generate-function"><a class="header" href="#generate-function">Generate function</a></h1>
<p>result = generator.generate_function(
â€œCreate a function that calculates the factorial of a numberâ€,
include_tests=True
)</p>
<p>print(â€œGenerated code:â€)
print(result[â€œcodeâ€])</p>
<p>if result[â€œtestsâ€]:
print(â€œ\nGenerated tests:â€)
print(result[â€œtestsâ€])</p>
<h1 id="generate-class"><a class="header" href="#generate-class">Generate class</a></h1>
<p>class_code = generator.generate_class(
â€œA simple cache that stores key-value pairs with expirationâ€,
methods=[â€œsetâ€, â€œgetâ€, â€œdeleteâ€, â€œclearâ€]
)</p>
<p>print(â€œ\nGenerated class:â€)
print(class_code)</p>
<pre><code>

## Refactoring and Optimization

### Automated Refactoring

```python
class RefactoringAgent:
    """Refactor and improve code quality"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def refactor_for_readability(self, code: str) -&gt; Dict[str, str]:
        """Improve code readability"""
        prompt = f"""Refactor this code for better readability:

```python
{code}
</code></pre>
<p>Apply these improvements:</p>
<ul>
<li>Better variable names</li>
<li>Extract complex expressions</li>
<li>Add comments</li>
<li>Simplify logic</li>
<li>Follow PEP 8</li>
</ul>
<p>Provide:</p>
<ol>
<li>Refactored code</li>
<li>List of changes made</li>
</ol>
<p>Response:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    return self.parse_response(response.choices[0].message.content)

def optimize_performance(self, code: str) -&gt; Dict[str, str]:
    """Optimize code for performance"""
    prompt = f"""Optimize this code for better performance:
</code></pre>
<pre><code class="language-python">{code}
</code></pre>
<p>Consider:</p>
<ul>
<li>Algorithm complexity</li>
<li>Data structure choices</li>
<li>Unnecessary operations</li>
<li>Caching opportunities</li>
<li>Memory usage</li>
</ul>
<p>Provide optimized code with explanation:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    return self.parse_response(response.choices[0].message.content)

def apply_design_pattern(self, code: str, pattern: str) -&gt; Dict[str, str]:
    """Apply design pattern to code"""
    prompt = f"""Refactor this code to use the {pattern} design pattern:
</code></pre>
<pre><code class="language-python">{code}
</code></pre>
<p>Explain:</p>
<ul>
<li>Why this pattern is appropriate</li>
<li>How it improves the code</li>
<li>What changed</li>
</ul>
<p>Refactored code:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    return self.parse_response(response.choices[0].message.content)

def extract_method(self, code: str, lines: tuple) -&gt; Dict[str, str]:
    """Extract method refactoring"""
    prompt = f"""Extract lines {lines[0]}-{lines[1]} into a separate method:
</code></pre>
<pre><code class="language-python">{code}
</code></pre>
<p>Provide:</p>
<ul>
<li>New method with good name</li>
<li>Updated original code</li>
<li>Method signature</li>
</ul>
<p>Result:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    
    return self.parse_response(response.choices[0].message.content)
</code></pre>
<h1 id="usage-2"><a class="header" href="#usage-2">Usage</a></h1>
<p>refactorer = RefactoringAgent()</p>
<h1 id="improve-readability"><a class="header" href="#improve-readability">Improve readability</a></h1>
<p>messy_code = â€œâ€â€œ
def f(x,y,z):
if x&gt;0:
if y&gt;0:
if z&gt;0:
return x+y+z
return 0
â€œâ€â€œ</p>
<p>result = refactorer.refactor_for_readability(messy_code)
print(â€œRefactored:â€, result[â€œcodeâ€])</p>
<h1 id="optimize-performance"><a class="header" href="#optimize-performance">Optimize performance</a></h1>
<p>slow_code = â€œâ€â€œ
def find_duplicates(items):
duplicates = []
for i in range(len(items)):
for j in range(i+1, len(items)):
if items[i] == items[j] and items[i] not in duplicates:
duplicates.append(items[i])
return duplicates
â€œâ€â€œ</p>
<p>result = refactorer.optimize_performance(slow_code)
print(â€œOptimized:â€, result[â€œcodeâ€])</p>
<pre><code>
## Test Generation

### Comprehensive Test Generation

```python
class TestGenerator:
    """Generate comprehensive unit tests"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def generate_unit_tests(self, code: str, framework: str = "pytest") -&gt; str:
        """Generate unit tests with full coverage"""
        prompt = f"""Generate comprehensive {framework} tests for this code:

```python
{code}
</code></pre>
<p>Include tests for:</p>
<ol>
<li>Normal/happy path cases</li>
<li>Edge cases (empty, None, boundaries)</li>
<li>Error cases (invalid input, exceptions)</li>
<li>Integration scenarios</li>
<li>Fixtures and setup if needed</li>
</ol>
<p>Use descriptive test names and add comments.</p>
<p>Tests:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    
    return self.extract_code(response.choices[0].message.content)

def generate_property_tests(self, code: str) -&gt; str:
    """Generate property-based tests using Hypothesis"""
    prompt = f"""Generate property-based tests using Hypothesis for:
</code></pre>
<pre><code class="language-python">{code}
</code></pre>
<p>Create tests that verify properties like:</p>
<ul>
<li>Invariants</li>
<li>Idempotence</li>
<li>Commutativity</li>
<li>Round-trip properties</li>
</ul>
<p>Tests:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    
    return self.extract_code(response.choices[0].message.content)

def generate_integration_tests(self, code: str, dependencies: List[str]) -&gt; str:
    """Generate integration tests"""
    deps_str = ", ".join(dependencies)
    
    prompt = f"""Generate integration tests for this code that interacts with: {deps_str}
</code></pre>
<pre><code class="language-python">{code}
</code></pre>
<p>Include:</p>
<ul>
<li>Mocking external dependencies</li>
<li>Testing interactions</li>
<li>Setup and teardown</li>
<li>Error scenarios</li>
</ul>
<p>Tests:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    
    return self.extract_code(response.choices[0].message.content)

def extract_code(self, text: str) -&gt; str:
    """Extract code from markdown"""
    import re
    pattern = r'```(?:python)?\n(.*?)```'
    matches = re.findall(pattern, text, re.DOTALL)
    return matches[0] if matches else text
</code></pre>
<h1 id="usage-3"><a class="header" href="#usage-3">Usage</a></h1>
<p>test_gen = TestGenerator()</p>
<p>code_to_test = â€œâ€â€œ
def divide(a: float, b: float) -&gt; float:
if b == 0:
raise ValueError(â€œCannot divide by zeroâ€)
return a / b
â€œâ€â€œ</p>
<p>tests = test_gen.generate_unit_tests(code_to_test)
print(â€œGenerated tests:â€)
print(tests)</p>
<pre><code>
## Debugging and Error Fixing

### Automated Debugging Agent

```python
class DebuggingAgent:
    """Find and fix bugs in code"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.sandbox = CodeExecutor()  # From previous chapters
    
    def debug_code(self, code: str, error_message: str = None) -&gt; Dict:
        """Debug code and suggest fixes"""
        
        # Try to execute and capture error if not provided
        if not error_message:
            result = self.sandbox.execute(code)
            if not result["success"]:
                error_message = result["output"]
        
        prompt = f"""Debug this code:

```python
{code}
</code></pre>
<p>Error: {error_message}</p>
<p>Provide:</p>
<ol>
<li>Root cause analysis</li>
<li>Fixed code</li>
<li>Explanation of the fix</li>
<li>How to prevent similar bugs</li>
</ol>
<p>Response:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    
    return self.parse_debug_response(response.choices[0].message.content)

def find_logical_errors(self, code: str, expected_behavior: str) -&gt; Dict:
    """Find logical errors (code runs but wrong output)"""
    prompt = f"""This code runs without errors but produces wrong results:
</code></pre>
<pre><code class="language-python">{code}
</code></pre>
<p>Expected behavior: {expected_behavior}</p>
<p>Analyze:</p>
<ol>
<li>Whatâ€™s the logical error?</li>
<li>Why does it produce wrong results?</li>
<li>How to fix it?</li>
<li>Test cases to verify the fix</li>
</ol>
<p>Analysis:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    return self.parse_debug_response(response.choices[0].message.content)

def suggest_improvements(self, code: str, issue: str) -&gt; List[str]:
    """Suggest multiple ways to fix an issue"""
    prompt = f"""Suggest 3 different ways to fix this issue:
</code></pre>
<p>Code:</p>
<pre><code class="language-python">{code}
</code></pre>
<p>Issue: {issue}</p>
<p>For each solution, provide:</p>
<ul>
<li>The fix</li>
<li>Pros and cons</li>
<li>When to use it</li>
</ul>
<p>Solutions:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5
    )
    
    return self.parse_solutions(response.choices[0].message.content)

def iterative_fix(self, code: str, max_attempts: int = 3) -&gt; Dict:
    """Iteratively fix code until it works"""
    for attempt in range(max_attempts):
        # Try to execute
        result = self.sandbox.execute(code)
        
        if result["success"]:
            return {
                "success": True,
                "code": code,
                "attempts": attempt + 1
            }
        
        # Try to fix
        fix_result = self.debug_code(code, result["output"])
        code = fix_result["fixed_code"]
    
    return {
        "success": False,
        "code": code,
        "attempts": max_attempts,
        "last_error": result["output"]
    }
</code></pre>
<h1 id="usage-4"><a class="header" href="#usage-4">Usage</a></h1>
<p>debugger = DebuggingAgent()</p>
<p>buggy_code = â€œâ€â€œ
def calculate_average(numbers):
total = 0
for num in numbers:
total += num
return total / len(numbers)</p>
<h1 id="this-will-crash-on-empty-list"><a class="header" href="#this-will-crash-on-empty-list">This will crash on empty list</a></h1>
<p>result = calculate_average([])
â€œâ€â€œ</p>
<p>fix = debugger.debug_code(buggy_code)
print(â€œRoot cause:â€, fix[â€œroot_causeâ€])
print(â€œFixed code:â€, fix[â€œfixed_codeâ€])</p>
<pre><code>
## Repository-Level Operations

### Codebase Understanding

```python
from pathlib import Path
import json

class CodebaseAgent:
    """Understand and navigate entire codebases"""
    
    def __init__(self, root_path: str):
        self.root_path = Path(root_path)
        self.index = {}
        self.dependency_graph = {}
        self.client = openai.OpenAI()
    
    def index_codebase(self):
        """Index all Python files in codebase"""
        print("Indexing codebase...")
        
        for py_file in self.root_path.rglob("*.py"):
            if "venv" in str(py_file) or ".git" in str(py_file):
                continue
            
            try:
                with open(py_file) as f:
                    code = f.read()
                
                analyzer = CodeAnalyzer()
                analysis = analyzer.parse_python_code(code)
                
                self.index[str(py_file.relative_to(self.root_path))] = {
                    "analysis": analysis,
                    "size": len(code),
                    "lines": len(code.split('\n'))
                }
            except Exception as e:
                print(f"Error indexing {py_file}: {e}")
        
        print(f"Indexed {len(self.index)} files")
    
    def find_function_definition(self, function_name: str) -&gt; List[Dict]:
        """Find where a function is defined"""
        results = []
        
        for file_path, data in self.index.items():
            for func in data["analysis"].get("functions", []):
                if func["name"] == function_name:
                    results.append({
                        "file": file_path,
                        "line": func["line"],
                        "signature": f"{func['name']}({', '.join(func['args'])})"
                    })
        
        return results
    
    def find_class_definition(self, class_name: str) -&gt; List[Dict]:
        """Find where a class is defined"""
        results = []
        
        for file_path, data in self.index.items():
            for cls in data["analysis"].get("classes", []):
                if cls["name"] == class_name:
                    results.append({
                        "file": file_path,
                        "line": cls["line"],
                        "methods": cls["methods"]
                    })
        
        return results
    
    def find_usages(self, symbol: str) -&gt; List[Dict]:
        """Find where a symbol is used"""
        usages = []
        
        for py_file in self.root_path.rglob("*.py"):
            if "venv" in str(py_file):
                continue
            
            try:
                with open(py_file) as f:
                    for i, line in enumerate(f, 1):
                        if symbol in line:
                            usages.append({
                                "file": str(py_file.relative_to(self.root_path)),
                                "line": i,
                                "content": line.strip()
                            })
            except:
                pass
        
        return usages
    
    def analyze_dependencies(self):
        """Build dependency graph"""
        for file_path, data in self.index.items():
            imports = data["analysis"].get("imports", [])
            self.dependency_graph[file_path] = imports
    
    def get_codebase_summary(self) -&gt; Dict:
        """Get high-level codebase summary"""
        total_files = len(self.index)
        total_functions = sum(
            len(data["analysis"].get("functions", []))
            for data in self.index.values()
        )
        total_classes = sum(
            len(data["analysis"].get("classes", []))
            for data in self.index.values()
        )
        total_lines = sum(
            data["lines"]
            for data in self.index.values()
        )
        
        return {
            "total_files": total_files,
            "total_functions": total_functions,
            "total_classes": total_classes,
            "total_lines": total_lines,
            "avg_lines_per_file": total_lines / total_files if total_files &gt; 0 else 0
        }
    
    def explain_codebase(self) -&gt; str:
        """Generate high-level explanation of codebase"""
        summary = self.get_codebase_summary()
        
        # Get file structure
        files = list(self.index.keys())
        
        prompt = f"""Explain this codebase structure:

Files: {len(files)}
Functions: {summary['total_functions']}
Classes: {summary['total_classes']}
Lines of code: {summary['total_lines']}

File structure:
{chr(10).join(files[:20])}

Provide:
1. What this codebase likely does
2. Main components/modules
3. Architecture pattern
4. Key areas of functionality

Explanation:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return response.choices[0].message.content

# Usage
codebase = CodebaseAgent("./my_project")
codebase.index_codebase()

# Find function
results = codebase.find_function_definition("process_data")
print(f"Found in: {results}")

# Get summary
summary = codebase.get_codebase_summary()
print(f"Codebase: {summary['total_files']} files, {summary['total_lines']} lines")

# Explain codebase
explanation = codebase.explain_codebase()
print(explanation)
</code></pre>
<h2 id="complete-coding-agent-system"><a class="header" href="#complete-coding-agent-system">Complete Coding Agent System</a></h2>
<pre><code class="language-python">class CompleteCodingAgent:
    """Full-featured coding agent"""
    
    def __init__(self):
        self.analyzer = CodeAnalyzer()
        self.generator = CodeGenerator()
        self.refactorer = RefactoringAgent()
        self.test_gen = TestGenerator()
        self.debugger = DebuggingAgent()
        self.client = openai.OpenAI()
    
    def process_request(self, request: str, code: str = None, context: Dict = None) -&gt; Dict:
        """Process any coding request"""
        
        # Classify intent
        intent = self.classify_intent(request)
        
        if intent == "generate":
            return self.handle_generation(request)
        
        elif intent == "analyze":
            return self.handle_analysis(code)
        
        elif intent == "refactor":
            return self.handle_refactoring(code, request)
        
        elif intent == "test":
            return self.handle_test_generation(code)
        
        elif intent == "debug":
            return self.handle_debugging(code, context)
        
        elif intent == "explain":
            return self.handle_explanation(code)
        
        else:
            return {"error": "Could not understand request"}
    
    def handle_generation(self, request: str) -&gt; Dict:
        """Handle code generation requests"""
        code = self.generator.generate_function(request)
        
        # Validate generated code
        validation = self.analyzer.parse_python_code(code)
        
        if "error" in validation:
            # Try to fix
            fixed = self.debugger.debug_code(code, validation["error"])
            code = fixed["fixed_code"]
        
        # Generate tests
        tests = self.test_gen.generate_unit_tests(code)
        
        return {
            "type": "generation",
            "code": code,
            "tests": tests,
            "validated": True
        }
    
    def handle_analysis(self, code: str) -&gt; Dict:
        """Handle code analysis requests"""
        # Parse structure
        structure = self.analyzer.parse_python_code(code)
        
        # Analyze complexity
        complexity = self.analyzer.analyze_complexity(code)
        
        # Get explanation
        explanation = self.analyzer.understand_code_intent(code)
        
        return {
            "type": "analysis",
            "structure": structure,
            "complexity": complexity,
            "explanation": explanation
        }
    
    def handle_refactoring(self, code: str, request: str) -&gt; Dict:
        """Handle refactoring requests"""
        if "performance" in request.lower():
            result = self.refactorer.optimize_performance(code)
        elif "readable" in request.lower():
            result = self.refactorer.refactor_for_readability(code)
        else:
            result = self.refactorer.refactor_code(code)
        
        return {
            "type": "refactoring",
            "original": code,
            "refactored": result["code"],
            "changes": result.get("changes", [])
        }
    
    def handle_test_generation(self, code: str) -&gt; Dict:
        """Handle test generation requests"""
        unit_tests = self.test_gen.generate_unit_tests(code)
        
        return {
            "type": "tests",
            "code": code,
            "tests": unit_tests
        }
    
    def handle_debugging(self, code: str, context: Dict) -&gt; Dict:
        """Handle debugging requests"""
        error_msg = context.get("error") if context else None
        
        result = self.debugger.debug_code(code, error_msg)
        
        return {
            "type": "debugging",
            "original": code,
            "fixed": result["fixed_code"],
            "explanation": result.get("explanation", "")
        }
    
    def handle_explanation(self, code: str) -&gt; Dict:
        """Handle code explanation requests"""
        explanation = self.analyzer.understand_code_intent(code)
        structure = self.analyzer.parse_python_code(code)
        
        return {
            "type": "explanation",
            "explanation": explanation,
            "structure": structure
        }
    
    def classify_intent(self, request: str) -&gt; str:
        """Classify user intent"""
        request_lower = request.lower()
        
        keywords = {
            "generate": ["generate", "create", "write", "implement"],
            "analyze": ["analyze", "understand", "explain what"],
            "refactor": ["refactor", "improve", "optimize", "clean"],
            "test": ["test", "unittest", "pytest"],
            "debug": ["debug", "fix", "error", "bug"],
            "explain": ["explain", "what does", "how does"]
        }
        
        for intent, words in keywords.items():
            if any(word in request_lower for word in words):
                return intent
        
        return "unknown"

# Usage
agent = CompleteCodingAgent()

# Generate code
result = agent.process_request("Create a function to validate email addresses")
print("Generated code:")
print(result["code"])
print("\nTests:")
print(result["tests"])

# Analyze code
code = """
def fibonacci(n):
    if n &lt;= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)
"""

result = agent.process_request("Analyze this code", code=code)
print("\nComplexity:", result["complexity"])
print("Explanation:", result["explanation"])

# Refactor code
result = agent.process_request("Optimize this code for performance", code=code)
print("\nRefactored:")
print(result["refactored"])
</code></pre>
<h2 id="best-practices-for-coding-agents"><a class="header" href="#best-practices-for-coding-agents">Best Practices for Coding Agents</a></h2>
<h3 id="1-code-quality-checks"><a class="header" href="#1-code-quality-checks">1. Code Quality Checks</a></h3>
<p>Always validate generated code:</p>
<ul>
<li>Syntax checking (AST parsing)</li>
<li>Style checking (PEP 8, linting)</li>
<li>Security scanning (bandit, safety)</li>
<li>Type checking (mypy)</li>
</ul>
<h3 id="2-testing-strategy"><a class="header" href="#2-testing-strategy">2. Testing Strategy</a></h3>
<ul>
<li>Generate tests alongside code</li>
<li>Run tests automatically</li>
<li>Achieve high coverage</li>
<li>Include edge cases</li>
</ul>
<h3 id="3-context-awareness"><a class="header" href="#3-context-awareness">3. Context Awareness</a></h3>
<ul>
<li>Understand existing codebase</li>
<li>Match coding style</li>
<li>Respect conventions</li>
<li>Consider dependencies</li>
</ul>
<h3 id="4-iterative-improvement"><a class="header" href="#4-iterative-improvement">4. Iterative Improvement</a></h3>
<ul>
<li>Start with simple solution</li>
<li>Refine based on feedback</li>
<li>Test incrementally</li>
<li>Document changes</li>
</ul>
<h3 id="5-security-considerations"><a class="header" href="#5-security-considerations">5. Security Considerations</a></h3>
<ul>
<li>Validate all inputs</li>
<li>Avoid SQL injection</li>
<li>Check for XSS vulnerabilities</li>
<li>Use secure libraries</li>
<li>Never expose secrets</li>
</ul>
<h3 id="6-performance-optimization"><a class="header" href="#6-performance-optimization">6. Performance Optimization</a></h3>
<ul>
<li>Profile before optimizing</li>
<li>Choose right algorithms</li>
<li>Consider memory usage</li>
<li>Cache when appropriate</li>
<li>Benchmark improvements</li>
</ul>
<h3 id="7-documentation"><a class="header" href="#7-documentation">7. Documentation</a></h3>
<ul>
<li>Generate docstrings</li>
<li>Add inline comments</li>
<li>Create README files</li>
<li>Document APIs</li>
<li>Explain complex logic</li>
</ul>
<h3 id="8-version-control"><a class="header" href="#8-version-control">8. Version Control</a></h3>
<ul>
<li>Commit frequently</li>
<li>Write clear messages</li>
<li>Use branches</li>
<li>Review changes</li>
<li>Tag releases</li>
</ul>
<h3 id="9-collaboration"><a class="header" href="#9-collaboration">9. Collaboration</a></h3>
<ul>
<li>Follow team standards</li>
<li>Request code reviews</li>
<li>Share knowledge</li>
<li>Document decisions</li>
<li>Communicate changes</li>
</ul>
<h3 id="10-continuous-learning"><a class="header" href="#10-continuous-learning">10. Continuous Learning</a></h3>
<ul>
<li>Learn from mistakes</li>
<li>Study good code</li>
<li>Stay updated</li>
<li>Experiment safely</li>
<li>Share learnings</li>
</ul>
<h2 id="advanced-topics"><a class="header" href="#advanced-topics">Advanced Topics</a></h2>
<h3 id="multi-language-support"><a class="header" href="#multi-language-support">Multi-Language Support</a></h3>
<pre><code class="language-python">class MultiLanguageAgent:
    """Support multiple programming languages"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.supported_languages = ["python", "javascript", "java", "go", "rust"]
    
    def generate_code(self, description: str, language: str) -&gt; str:
        """Generate code in specified language"""
        if language not in self.supported_languages:
            raise ValueError(f"Unsupported language: {language}")
        
        prompt = f"""Generate {language} code for:

{description}

Follow {language} best practices and conventions.

Code:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        
        return response.choices[0].message.content
    
    def translate_code(self, code: str, from_lang: str, to_lang: str) -&gt; str:
        """Translate code between languages"""
        prompt = f"""Translate this {from_lang} code to {to_lang}:

```{from_lang}
{code}
</code></pre>
<p>Maintain:</p>
<ul>
<li>Same functionality</li>
<li>Idiomatic {to_lang} style</li>
<li>Best practices</li>
</ul>
<p>{to_lang} code:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    
    return response.choices[0].message.content
</code></pre>
<pre><code>
### Code Review Agent

```python
class CodeReviewAgent:
    """Automated code review"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def review_code(self, code: str) -&gt; Dict:
        """Comprehensive code review"""
        prompt = f"""Review this code:

```python
{code}
</code></pre>
<p>Provide feedback on:</p>
<ol>
<li>Code quality (readability, maintainability)</li>
<li>Potential bugs or issues</li>
<li>Performance concerns</li>
<li>Security vulnerabilities</li>
<li>Best practice violations</li>
<li>Suggestions for improvement</li>
</ol>
<p>Rate each category 1-5 and provide specific feedback.</p>
<p>Review:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    return self.parse_review(response.choices[0].message.content)

def suggest_improvements(self, code: str) -&gt; List[Dict]:
    """Suggest specific improvements"""
    review = self.review_code(code)
    
    improvements = []
    for issue in review.get("issues", []):
        improvements.append({
            "issue": issue,
            "suggestion": self.generate_fix(code, issue),
            "priority": self.assess_priority(issue)
        })
    
    return improvements
</code></pre>
<pre><code>
## Next Steps

You now have comprehensive knowledge of coding agents! Next, we'll explore research agents that gather and synthesize information from multiple sources.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="research-agents"><a class="header" href="#research-agents">Research Agents</a></h1>
<h2 id="introduction-to-research-agents"><a class="header" href="#introduction-to-research-agents">Introduction to Research Agents</a></h2>
<p>Research agents are specialized AI systems that gather, analyze, and synthesize information from multiple sources to answer complex questions or investigate topics in depth.</p>
<h3 id="what-makes-research-agents-unique"><a class="header" href="#what-makes-research-agents-unique">What Makes Research Agents Unique?</a></h3>
<p><strong>Core Capabilities</strong>:</p>
<ul>
<li>Multi-source information gathering</li>
<li>Source credibility assessment</li>
<li>Information synthesis and summarization</li>
<li>Citation management</li>
<li>Fact verification</li>
<li>Deep topic exploration</li>
</ul>
<p><strong>Key Challenges</strong>:</p>
<ul>
<li>Information overload</li>
<li>Source reliability</li>
<li>Conflicting information</li>
<li>Bias detection</li>
<li>Citation accuracy</li>
<li>Staying current</li>
</ul>
<h3 id="types-of-research-agents"><a class="header" href="#types-of-research-agents">Types of Research Agents</a></h3>
<ol>
<li><strong>Academic Research Agents</strong>: Literature reviews, paper analysis</li>
<li><strong>Market Research Agents</strong>: Competitive analysis, trends</li>
<li><strong>Investigative Agents</strong>: Deep dives, fact-checking</li>
<li><strong>News Aggregation Agents</strong>: Current events, monitoring</li>
<li><strong>Technical Research Agents</strong>: Documentation, specifications</li>
</ol>
<h2 id="information-gathering-strategies"><a class="header" href="#information-gathering-strategies">Information Gathering Strategies</a></h2>
<h3 id="multi-source-search"><a class="header" href="#multi-source-search">Multi-Source Search</a></h3>
<pre><code class="language-python">from typing import List, Dict
import requests
from bs4 import BeautifulSoup

class MultiSourceSearcher:
    """Search across multiple sources"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.sources = {
            "web": self.search_web,
            "academic": self.search_academic,
            "news": self.search_news,
            "social": self.search_social
        }
    
    def search_all_sources(self, query: str, sources: List[str] = None) -&gt; Dict:
        """Search across all specified sources"""
        if sources is None:
            sources = list(self.sources.keys())
        
        results = {}
        
        for source in sources:
            if source in self.sources:
                print(f"Searching {source}...")
                results[source] = self.sources[source](query)
        
        return results
    
    def search_web(self, query: str) -&gt; List[Dict]:
        """Search general web"""
        # Using a search API (example with Google Custom Search)
        api_key = os.getenv("GOOGLE_API_KEY")
        search_engine_id = os.getenv("GOOGLE_SEARCH_ENGINE_ID")
        
        url = "https://www.googleapis.com/customsearch/v1"
        params = {
            "key": api_key,
            "cx": search_engine_id,
            "q": query,
            "num": 10
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            results = []
            for item in data.get("items", []):
                results.append({
                    "title": item["title"],
                    "url": item["link"],
                    "snippet": item["snippet"],
                    "source": "web"
                })
            
            return results
        except Exception as e:
            print(f"Web search error: {e}")
            return []
    
    def search_academic(self, query: str) -&gt; List[Dict]:
        """Search academic sources (arXiv, PubMed, etc.)"""
        # Example with arXiv API
        url = "http://export.arxiv.org/api/query"
        params = {
            "search_query": f"all:{query}",
            "start": 0,
            "max_results": 10
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            # Parse XML response
            from xml.etree import ElementTree as ET
            root = ET.fromstring(response.content)
            
            results = []
            for entry in root.findall("{http://www.w3.org/2005/Atom}entry"):
                title = entry.find("{http://www.w3.org/2005/Atom}title").text
                summary = entry.find("{http://www.w3.org/2005/Atom}summary").text
                link = entry.find("{http://www.w3.org/2005/Atom}id").text
                
                results.append({
                    "title": title.strip(),
                    "url": link,
                    "snippet": summary.strip()[:200],
                    "source": "academic"
                })
            
            return results
        except Exception as e:
            print(f"Academic search error: {e}")
            return []
    
    def search_news(self, query: str) -&gt; List[Dict]:
        """Search news sources"""
        # Example with News API
        api_key = os.getenv("NEWS_API_KEY")
        url = "https://newsapi.org/v2/everything"
        params = {
            "q": query,
            "apiKey": api_key,
            "pageSize": 10,
            "sortBy": "relevancy"
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            results = []
            for article in data.get("articles", []):
                results.append({
                    "title": article["title"],
                    "url": article["url"],
                    "snippet": article["description"],
                    "source": "news",
                    "published": article.get("publishedAt")
                })
            
            return results
        except Exception as e:
            print(f"News search error: {e}")
            return []
    
    def search_social(self, query: str) -&gt; List[Dict]:
        """Search social media (Twitter, Reddit, etc.)"""
        # Example implementation for Reddit
        url = f"https://www.reddit.com/search.json"
        params = {
            "q": query,
            "limit": 10,
            "sort": "relevance"
        }
        headers = {"User-Agent": "ResearchAgent/1.0"}
        
        try:
            response = requests.get(url, params=params, headers=headers, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            results = []
            for post in data["data"]["children"]:
                post_data = post["data"]
                results.append({
                    "title": post_data["title"],
                    "url": f"https://reddit.com{post_data['permalink']}",
                    "snippet": post_data.get("selftext", "")[:200],
                    "source": "social",
                    "score": post_data.get("score", 0)
                })
            
            return results
        except Exception as e:
            print(f"Social search error: {e}")
            return []

# Usage
searcher = MultiSourceSearcher()
results = searcher.search_all_sources("artificial intelligence agents")

for source, items in results.items():
    print(f"\n{source.upper()} Results: {len(items)}")
    for item in items[:3]:
        print(f"  - {item['title']}")
</code></pre>
<h3 id="deep-content-extraction"><a class="header" href="#deep-content-extraction">Deep Content Extraction</a></h3>
<pre><code class="language-python">class ContentExtractor:
    """Extract and process content from sources"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def extract_from_url(self, url: str) -&gt; Dict:
        """Extract main content from URL"""
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Remove script and style elements
            for script in soup(["script", "style"]):
                script.decompose()
            
            # Get text
            text = soup.get_text(separator='\n', strip=True)
            
            # Extract metadata
            title = soup.find('title')
            title_text = title.string if title else ""
            
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            description = meta_desc['content'] if meta_desc else ""
            
            return {
                "url": url,
                "title": title_text,
                "description": description,
                "content": text[:10000],  # Limit content
                "word_count": len(text.split())
            }
            
        except Exception as e:
            return {
                "url": url,
                "error": str(e)
            }
    
    def extract_key_points(self, content: str) -&gt; List[str]:
        """Extract key points from content"""
        prompt = f"""Extract the key points from this content:

{content[:4000]}

Provide 5-7 bullet points of the most important information:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        points = response.choices[0].message.content.strip().split('\n')
        return [p.strip('- ').strip() for p in points if p.strip()]
    
    def extract_quotes(self, content: str, topic: str) -&gt; List[Dict]:
        """Extract relevant quotes"""
        prompt = f"""Find relevant quotes about "{topic}" from this content:

{content[:4000]}

Provide 3-5 direct quotes with context:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        # Parse quotes
        quotes_text = response.choices[0].message.content
        # Simple parsing - in production, use more robust method
        quotes = []
        for line in quotes_text.split('\n'):
            if line.strip().startswith('"'):
                quotes.append({"quote": line.strip(), "context": ""})
        
        return quotes

# Usage
extractor = ContentExtractor()

# Extract content
content = extractor.extract_from_url("https://example.com/article")
print(f"Title: {content['title']}")
print(f"Words: {content['word_count']}")

# Extract key points
key_points = extractor.extract_key_points(content['content'])
for point in key_points:
    print(f"  â€¢ {point}")
</code></pre>
<h2 id="source-verification"><a class="header" href="#source-verification">Source Verification</a></h2>
<h3 id="credibility-assessment"><a class="header" href="#credibility-assessment">Credibility Assessment</a></h3>
<pre><code class="language-python">class SourceVerifier:
    """Verify source credibility and reliability"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.trusted_domains = {
            "academic": [".edu", ".gov", "arxiv.org", "pubmed.gov"],
            "news": ["reuters.com", "apnews.com", "bbc.com"],
            "tech": ["github.com", "stackoverflow.com"]
        }
    
    def assess_credibility(self, url: str, content: str = None) -&gt; Dict:
        """Assess source credibility"""
        from urllib.parse import urlparse
        
        domain = urlparse(url).netloc
        
        # Check against trusted domains
        trust_level = "unknown"
        for category, domains in self.trusted_domains.items():
            if any(trusted in domain for trusted in domains):
                trust_level = "high"
                break
        
        # Analyze content if provided
        content_score = None
        if content:
            content_score = self.analyze_content_quality(content)
        
        return {
            "url": url,
            "domain": domain,
            "trust_level": trust_level,
            "content_quality": content_score,
            "is_trusted": trust_level == "high"
        }
    
    def analyze_content_quality(self, content: str) -&gt; Dict:
        """Analyze content quality indicators"""
        prompt = f"""Analyze the quality and credibility of this content:

{content[:2000]}

Rate (1-5) on:
1. Factual accuracy (based on claims made)
2. Objectivity (bias level)
3. Citation quality (references provided)
4. Writing quality (clarity, professionalism)
5. Depth of analysis

Provide scores and brief explanation:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return self.parse_quality_scores(response.choices[0].message.content)
    
    def cross_reference(self, claim: str, sources: List[Dict]) -&gt; Dict:
        """Cross-reference a claim across sources"""
        confirmations = 0
        contradictions = 0
        
        for source in sources:
            result = self.check_claim_in_source(claim, source.get("content", ""))
            
            if result == "confirms":
                confirmations += 1
            elif result == "contradicts":
                contradictions += 1
        
        return {
            "claim": claim,
            "confirmations": confirmations,
            "contradictions": contradictions,
            "confidence": confirmations / len(sources) if sources else 0
        }
    
    def check_claim_in_source(self, claim: str, content: str) -&gt; str:
        """Check if source confirms, contradicts, or is neutral on claim"""
        prompt = f"""Does this content confirm, contradict, or neither regarding this claim?

Claim: {claim}

Content: {content[:1000]}

Answer with just: confirms, contradicts, or neutral"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        return response.choices[0].message.content.strip().lower()

# Usage
verifier = SourceVerifier()

# Assess credibility
credibility = verifier.assess_credibility(
    "https://arxiv.org/abs/2023.12345",
    "This paper presents..."
)
print(f"Trust level: {credibility['trust_level']}")

# Cross-reference claim
claim = "AI agents can autonomously complete complex tasks"
sources = [
    {"content": "Research shows AI agents are capable of..."},
    {"content": "Studies indicate autonomous agents can..."}
]
verification = verifier.cross_reference(claim, sources)
print(f"Confidence: {verification['confidence']:.0%}")
</code></pre>
<h2 id="synthesis-and-summarization"><a class="header" href="#synthesis-and-summarization">Synthesis and Summarization</a></h2>
<h3 id="information-synthesis"><a class="header" href="#information-synthesis">Information Synthesis</a></h3>
<pre><code class="language-python">class InformationSynthesizer:
    """Synthesize information from multiple sources"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def synthesize_sources(self, 
                          query: str,
                          sources: List[Dict],
                          style: str = "comprehensive") -&gt; str:
        """Synthesize information from multiple sources"""
        
        # Prepare source summaries
        source_texts = []
        for i, source in enumerate(sources[:10], 1):  # Limit to 10 sources
            source_texts.append(f"""
Source {i}: {source.get('title', 'Unknown')}
URL: {source.get('url', 'N/A')}
Content: {source.get('snippet', source.get('content', ''))[:500]}
""")
        
        sources_combined = "\n---\n".join(source_texts)
        
        style_instructions = {
            "comprehensive": "Provide a detailed, thorough analysis",
            "concise": "Provide a brief, focused summary",
            "academic": "Use formal, academic tone with citations",
            "casual": "Use conversational, accessible language"
        }
        
        prompt = f"""Synthesize information about: {query}

Sources:
{sources_combined}

{style_instructions.get(style, style_instructions['comprehensive'])}.

Requirements:
- Integrate information from multiple sources
- Identify common themes and patterns
- Note any contradictions
- Cite sources [1], [2], etc.
- Provide balanced perspective

Synthesis:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=2000
        )
        
        synthesis = response.choices[0].message.content
        
        # Add source list
        source_list = "\n\nSources:\n"
        for i, source in enumerate(sources[:10], 1):
            source_list += f"[{i}] {source.get('title', 'Unknown')} - {source.get('url', 'N/A')}\n"
        
        return synthesis + source_list
    
    def identify_themes(self, sources: List[Dict]) -&gt; List[Dict]:
        """Identify common themes across sources"""
        # Combine content
        combined_content = "\n\n".join([
            s.get('snippet', s.get('content', ''))[:500]
            for s in sources[:20]
        ])
        
        prompt = f"""Identify the main themes in these sources:

{combined_content}

List 5-7 key themes with:
- Theme name
- Brief description
- How many sources mention it

Themes:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return self.parse_themes(response.choices[0].message.content)
    
    def find_contradictions(self, sources: List[Dict]) -&gt; List[Dict]:
        """Find contradictions between sources"""
        contradictions = []
        
        # Compare sources pairwise (simplified)
        for i in range(min(5, len(sources))):
            for j in range(i+1, min(5, len(sources))):
                source_a = sources[i]
                source_b = sources[j]
                
                prompt = f"""Do these sources contradict each other?

Source A: {source_a.get('snippet', '')[:300]}

Source B: {source_b.get('snippet', '')[:300]}

If yes, explain the contradiction. If no, say "no contradiction".

Analysis:"""
                
                response = self.client.chat.completions.create(
                    model="gpt-4",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.2
                )
                
                result = response.choices[0].message.content
                
                if "no contradiction" not in result.lower():
                    contradictions.append({
                        "source_a": source_a.get('title'),
                        "source_b": source_b.get('title'),
                        "contradiction": result
                    })
        
        return contradictions

# Usage
synthesizer = InformationSynthesizer()

sources = [
    {"title": "AI Agents Overview", "url": "...", "snippet": "AI agents are..."},
    {"title": "Agent Architectures", "url": "...", "snippet": "Modern agents use..."},
    # ... more sources
]

# Synthesize
synthesis = synthesizer.synthesize_sources(
    "What are AI agents?",
    sources,
    style="comprehensive"
)
print(synthesis)

# Identify themes
themes = synthesizer.identify_themes(sources)
for theme in themes:
    print(f"Theme: {theme}")
</code></pre>
<h2 id="citation-management"><a class="header" href="#citation-management">Citation Management</a></h2>
<h3 id="automatic-citation-generation"><a class="header" href="#automatic-citation-generation">Automatic Citation Generation</a></h3>
<pre><code class="language-python">class CitationManager:
    """Manage citations and references"""
    
    def __init__(self):
        self.citations = []
        self.citation_style = "APA"  # APA, MLA, Chicago
    
    def add_citation(self, source: Dict) -&gt; int:
        """Add source and return citation number"""
        self.citations.append(source)
        return len(self.citations)
    
    def format_citation(self, source: Dict, style: str = None) -&gt; str:
        """Format citation in specified style"""
        style = style or self.citation_style
        
        if style == "APA":
            return self.format_apa(source)
        elif style == "MLA":
            return self.format_mla(source)
        elif style == "Chicago":
            return self.format_chicago(source)
        else:
            return self.format_simple(source)
    
    def format_apa(self, source: Dict) -&gt; str:
        """Format in APA style"""
        author = source.get('author', 'Unknown')
        year = source.get('year', 'n.d.')
        title = source.get('title', 'Untitled')
        url = source.get('url', '')
        
        return f"{author}. ({year}). {title}. Retrieved from {url}"
    
    def format_mla(self, source: Dict) -&gt; str:
        """Format in MLA style"""
        author = source.get('author', 'Unknown')
        title = source.get('title', 'Untitled')
        website = source.get('website', 'Web')
        url = source.get('url', '')
        
        return f'{author}. "{title}." {website}. {url}.'
    
    def format_simple(self, source: Dict) -&gt; str:
        """Simple format"""
        title = source.get('title', 'Untitled')
        url = source.get('url', '')
        return f"{title} - {url}"
    
    def generate_bibliography(self) -&gt; str:
        """Generate full bibliography"""
        bibliography = "References:\n\n"
        
        for i, source in enumerate(self.citations, 1):
            citation = self.format_citation(source)
            bibliography += f"{i}. {citation}\n"
        
        return bibliography
    
    def inline_cite(self, text: str, citation_num: int) -&gt; str:
        """Add inline citation to text"""
        return f"{text} [{citation_num}]"

# Usage
citations = CitationManager()

# Add sources
source1 = {
    "author": "Smith, J.",
    "year": "2023",
    "title": "Understanding AI Agents",
    "url": "https://example.com/article"
}

cite_num = citations.add_citation(source1)

# Use in text
text = citations.inline_cite("AI agents are autonomous systems", cite_num)
print(text)  # "AI agents are autonomous systems [1]"

# Generate bibliography
print(citations.generate_bibliography())
</code></pre>
<h2 id="complete-research-agent"><a class="header" href="#complete-research-agent">Complete Research Agent</a></h2>
<pre><code class="language-python">class ResearchAgent:
    """Complete research agent system"""
    
    def __init__(self):
        self.searcher = MultiSourceSearcher()
        self.extractor = ContentExtractor()
        self.verifier = SourceVerifier()
        self.synthesizer = InformationSynthesizer()
        self.citations = CitationManager()
        self.client = openai.OpenAI()
    
    def research(self, 
                query: str,
                depth: str = "medium",
                sources: List[str] = None) -&gt; Dict:
        """Conduct comprehensive research"""
        
        print(f"ğŸ” Researching: {query}\n")
        
        # 1. Search multiple sources
        print("ğŸ“š Gathering sources...")
        search_results = self.searcher.search_all_sources(query, sources)
        
        all_sources = []
        for source_type, results in search_results.items():
            all_sources.extend(results)
        
        print(f"Found {len(all_sources)} sources\n")
        
        # 2. Extract and verify content
        print("ğŸ“– Extracting content...")
        verified_sources = []
        
        for source in all_sources[:20]:  # Limit processing
            # Extract content
            if 'content' not in source:
                content_data = self.extractor.extract_from_url(source['url'])
                source['content'] = content_data.get('content', source.get('snippet', ''))
            
            # Verify credibility
            credibility = self.verifier.assess_credibility(
                source['url'],
                source.get('content', '')
            )
            
            if credibility['is_trusted'] or credibility['trust_level'] != 'low':
                source['credibility'] = credibility
                verified_sources.append(source)
                
                # Add citation
                cite_num = self.citations.add_citation(source)
                source['citation_num'] = cite_num
        
        print(f"Verified {len(verified_sources)} sources\n")
        
        # 3. Synthesize information
        print("âœï¸  Synthesizing findings...")
        synthesis = self.synthesizer.synthesize_sources(
            query,
            verified_sources,
            style="comprehensive" if depth == "deep" else "concise"
        )
        
        # 4. Identify themes
        themes = self.synthesizer.identify_themes(verified_sources)
        
        # 5. Find contradictions
        contradictions = self.synthesizer.find_contradictions(verified_sources)
        
        # 6. Generate bibliography
        bibliography = self.citations.generate_bibliography()
        
        return {
            "query": query,
            "synthesis": synthesis,
            "themes": themes,
            "contradictions": contradictions,
            "sources": verified_sources,
            "bibliography": bibliography,
            "source_count": len(verified_sources)
        }
    
    def deep_dive(self, topic: str, subtopics: List[str] = None) -&gt; Dict:
        """Deep research on topic with subtopics"""
        
        if not subtopics:
            # Generate subtopics
            subtopics = self.generate_subtopics(topic)
        
        results = {
            "topic": topic,
            "subtopics": {}
        }
        
        for subtopic in subtopics:
            print(f"\nğŸ“Œ Researching subtopic: {subtopic}")
            result = self.research(f"{topic}: {subtopic}", depth="medium")
            results["subtopics"][subtopic] = result
        
        # Create overall synthesis
        print("\nğŸ”— Creating overall synthesis...")
        overall = self.synthesize_deep_dive(topic, results["subtopics"])
        results["overall_synthesis"] = overall
        
        return results
    
    def generate_subtopics(self, topic: str) -&gt; List[str]:
        """Generate relevant subtopics"""
        prompt = f"""Generate 5 key subtopics for researching: {topic}

Subtopics should:
- Cover different aspects
- Be specific and focused
- Be researchable

List:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        subtopics = response.choices[0].message.content.strip().split('\n')
        return [s.strip('- 0123456789.').strip() for s in subtopics if s.strip()]
    
    def synthesize_deep_dive(self, topic: str, subtopic_results: Dict) -&gt; str:
        """Synthesize results from deep dive"""
        # Combine all syntheses
        combined = f"# Comprehensive Research: {topic}\n\n"
        
        for subtopic, result in subtopic_results.items():
            combined += f"## {subtopic}\n\n"
            combined += result['synthesis'] + "\n\n"
        
        return combined
    
    def fact_check(self, claim: str) -&gt; Dict:
        """Fact-check a specific claim"""
        print(f"ğŸ” Fact-checking: {claim}\n")
        
        # Search for information about the claim
        results = self.research(claim, depth="medium")
        
        # Cross-reference
        verification = self.verifier.cross_reference(
            claim,
            results['sources']
        )
        
        # Determine verdict
        if verification['confidence'] &gt; 0.7:
            verdict = "Likely True"
        elif verification['confidence'] &lt; 0.3:
            verdict = "Likely False"
        else:
            verdict = "Unclear/Mixed Evidence"
        
        return {
            "claim": claim,
            "verdict": verdict,
            "confidence": verification['confidence'],
            "confirmations": verification['confirmations'],
            "contradictions": verification['contradictions'],
            "sources": results['sources'][:5],
            "explanation": results['synthesis']
        }

# Usage
agent = ResearchAgent()

# Basic research
result = agent.research("What are the latest developments in AI agents?")
print(result['synthesis'])
print(f"\nSources: {result['source_count']}")

# Deep dive
deep_result = agent.deep_dive(
    "AI Agent Architectures",
    subtopics=["ReAct Pattern", "Memory Systems", "Tool Use"]
)

# Fact check
fact_result = agent.fact_check("AI agents can autonomously write production code")
print(f"Verdict: {fact_result['verdict']}")
print(f"Confidence: {fact_result['confidence']:.0%}")
</code></pre>
<h2 id="best-practices-9"><a class="header" href="#best-practices-9">Best Practices</a></h2>
<ol>
<li><strong>Multi-source verification</strong>: Never rely on single source</li>
<li><strong>Assess credibility</strong>: Check source reliability</li>
<li><strong>Cite properly</strong>: Always attribute information</li>
<li><strong>Check recency</strong>: Ensure information is current</li>
<li><strong>Cross-reference</strong>: Verify claims across sources</li>
<li><strong>Note contradictions</strong>: Highlight conflicting information</li>
<li><strong>Maintain objectivity</strong>: Present balanced view</li>
<li><strong>Track sources</strong>: Keep detailed records</li>
<li><strong>Update regularly</strong>: Refresh research periodically</li>
<li><strong>Human review</strong>: Critical research needs expert review</li>
</ol>
<h2 id="next-steps-13"><a class="header" href="#next-steps-13">Next Steps</a></h2>
<p>You now have comprehensive knowledge of research agents! Next, weâ€™ll explore task automation agents that handle repetitive workflows.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="task-automation-agents"><a class="header" href="#task-automation-agents">Task Automation Agents</a></h1>
<h2 id="introduction-to-task-automation"><a class="header" href="#introduction-to-task-automation">Introduction to Task Automation</a></h2>
<p>Task automation agents handle repetitive workflows, orchestrate complex processes, and integrate with existing tools to save time and reduce errors.</p>
<h3 id="what-makes-automation-agents-special"><a class="header" href="#what-makes-automation-agents-special">What Makes Automation Agents Special?</a></h3>
<p><strong>Core Capabilities</strong>:</p>
<ul>
<li>Workflow orchestration</li>
<li>Event-driven triggers</li>
<li>Integration with multiple tools</li>
<li>Scheduled operations</li>
<li>Error handling and recovery</li>
<li>State management across tasks</li>
</ul>
<p><strong>Key Benefits</strong>:</p>
<ul>
<li>Eliminate repetitive work</li>
<li>Reduce human error</li>
<li>24/7 operation</li>
<li>Consistent execution</li>
<li>Scalable processing</li>
<li>Audit trails</li>
</ul>
<h3 id="types-of-automation-agents"><a class="header" href="#types-of-automation-agents">Types of Automation Agents</a></h3>
<ol>
<li><strong>Workflow Agents</strong>: Multi-step process automation</li>
<li><strong>Scheduling Agents</strong>: Time-based task execution</li>
<li><strong>Integration Agents</strong>: Connect different systems</li>
<li><strong>Monitoring Agents</strong>: Watch and respond to events</li>
<li><strong>Data Processing Agents</strong>: ETL and transformation</li>
</ol>
<h2 id="workflow-orchestration"><a class="header" href="#workflow-orchestration">Workflow Orchestration</a></h2>
<h3 id="building-workflow-engine"><a class="header" href="#building-workflow-engine">Building Workflow Engine</a></h3>
<pre><code class="language-python">from dataclasses import dataclass
from typing import List, Dict, Callable, Any
from enum import Enum
import time

class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

@dataclass
class Task:
    """Single task in workflow"""
    id: str
    name: str
    action: Callable
    params: Dict[str, Any]
    dependencies: List[str] = None
    retry_count: int = 3
    timeout: int = 300
    status: TaskStatus = TaskStatus.PENDING
    result: Any = None
    error: str = None

class WorkflowEngine:
    """Orchestrate complex workflows"""
    
    def __init__(self):
        self.tasks = {}
        self.execution_log = []
    
    def add_task(self, task: Task):
        """Add task to workflow"""
        self.tasks[task.id] = task
    
    def execute_workflow(self) -&gt; Dict:
        """Execute all tasks respecting dependencies"""
        print("ğŸš€ Starting workflow execution\n")
        
        completed = set()
        failed = set()
        
        while len(completed) + len(failed) &lt; len(self.tasks):
            # Find tasks ready to execute
            ready_tasks = self.get_ready_tasks(completed, failed)
            
            if not ready_tasks:
                # Check if we're stuck
                pending = [t for t in self.tasks.values() if t.status == TaskStatus.PENDING]
                if pending:
                    print("âš ï¸  Workflow stuck - circular dependencies or all tasks failed")
                    break
                else:
                    break
            
            # Execute ready tasks
            for task in ready_tasks:
                result = self.execute_task(task)
                
                if result['success']:
                    completed.add(task.id)
                else:
                    failed.add(task.id)
        
        return self.generate_report(completed, failed)
    
    def get_ready_tasks(self, completed: set, failed: set) -&gt; List[Task]:
        """Get tasks ready to execute"""
        ready = []
        
        for task in self.tasks.values():
            if task.status != TaskStatus.PENDING:
                continue
            
            # Check dependencies
            if task.dependencies:
                deps_met = all(dep in completed for dep in task.dependencies)
                deps_failed = any(dep in failed for dep in task.dependencies)
                
                if deps_failed:
                    task.status = TaskStatus.SKIPPED
                    task.error = "Dependency failed"
                    continue
                
                if not deps_met:
                    continue
            
            ready.append(task)
        
        return ready
    
    def execute_task(self, task: Task) -&gt; Dict:
        """Execute single task with retry logic"""
        print(f"â–¶ï¸  Executing: {task.name}")
        task.status = TaskStatus.RUNNING
        
        for attempt in range(task.retry_count):
            try:
                # Execute task action
                start_time = time.time()
                result = task.action(**task.params)
                execution_time = time.time() - start_time
                
                # Success
                task.status = TaskStatus.COMPLETED
                task.result = result
                
                log_entry = {
                    "task_id": task.id,
                    "task_name": task.name,
                    "status": "success",
                    "execution_time": execution_time,
                    "attempt": attempt + 1
                }
                self.execution_log.append(log_entry)
                
                print(f"âœ… Completed: {task.name} ({execution_time:.2f}s)\n")
                
                return {"success": True, "result": result}
                
            except Exception as e:
                error_msg = str(e)
                print(f"âŒ Attempt {attempt + 1} failed: {error_msg}")
                
                if attempt &lt; task.retry_count - 1:
                    wait_time = 2 ** attempt  # Exponential backoff
                    print(f"â³ Retrying in {wait_time}s...")
                    time.sleep(wait_time)
                else:
                    # Final failure
                    task.status = TaskStatus.FAILED
                    task.error = error_msg
                    
                    log_entry = {
                        "task_id": task.id,
                        "task_name": task.name,
                        "status": "failed",
                        "error": error_msg,
                        "attempts": task.retry_count
                    }
                    self.execution_log.append(log_entry)
                    
                    print(f"ğŸ’¥ Failed: {task.name}\n")
                    
                    return {"success": False, "error": error_msg}
    
    def generate_report(self, completed: set, failed: set) -&gt; Dict:
        """Generate execution report"""
        total = len(self.tasks)
        skipped = sum(1 for t in self.tasks.values() if t.status == TaskStatus.SKIPPED)
        
        report = {
            "total_tasks": total,
            "completed": len(completed),
            "failed": len(failed),
            "skipped": skipped,
            "success_rate": len(completed) / total if total &gt; 0 else 0,
            "execution_log": self.execution_log
        }
        
        print("=" * 50)
        print("WORKFLOW EXECUTION REPORT")
        print("=" * 50)
        print(f"Total Tasks: {total}")
        print(f"Completed: {len(completed)}")
        print(f"Failed: {len(failed)}")
        print(f"Skipped: {skipped}")
        print(f"Success Rate: {report['success_rate']:.1%}")
        print("=" * 50)
        
        return report

# Usage
workflow = WorkflowEngine()

# Define tasks
def fetch_data(source):
    print(f"  Fetching from {source}...")
    time.sleep(1)
    return {"data": f"Data from {source}"}

def process_data(data):
    print(f"  Processing data...")
    time.sleep(1)
    return {"processed": True}

def save_results(data):
    print(f"  Saving results...")
    time.sleep(1)
    return {"saved": True}

# Add tasks
workflow.add_task(Task(
    id="fetch",
    name="Fetch Data",
    action=fetch_data,
    params={"source": "API"}
))

workflow.add_task(Task(
    id="process",
    name="Process Data",
    action=process_data,
    params={"data": {}},
    dependencies=["fetch"]
))

workflow.add_task(Task(
    id="save",
    name="Save Results",
    action=save_results,
    params={"data": {}},
    dependencies=["process"]
))

# Execute
report = workflow.execute_workflow()
</code></pre>
<h3 id="parallel-workflow-execution"><a class="header" href="#parallel-workflow-execution">Parallel Workflow Execution</a></h3>
<pre><code class="language-python">import asyncio
from concurrent.futures import ThreadPoolExecutor

class ParallelWorkflowEngine(WorkflowEngine):
    """Execute independent tasks in parallel"""
    
    def __init__(self, max_workers: int = 4):
        super().__init__()
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    
    async def execute_workflow_async(self) -&gt; Dict:
        """Execute workflow with parallel execution"""
        print("ğŸš€ Starting parallel workflow execution\n")
        
        completed = set()
        failed = set()
        
        while len(completed) + len(failed) &lt; len(self.tasks):
            # Get ready tasks
            ready_tasks = self.get_ready_tasks(completed, failed)
            
            if not ready_tasks:
                break
            
            # Execute tasks in parallel
            tasks_futures = [
                self.execute_task_async(task)
                for task in ready_tasks
            ]
            
            results = await asyncio.gather(*tasks_futures)
            
            # Update completed/failed
            for task, result in zip(ready_tasks, results):
                if result['success']:
                    completed.add(task.id)
                else:
                    failed.add(task.id)
        
        return self.generate_report(completed, failed)
    
    async def execute_task_async(self, task: Task) -&gt; Dict:
        """Execute task asynchronously"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor,
            self.execute_task,
            task
        )

# Usage
async def main():
    workflow = ParallelWorkflowEngine(max_workers=3)
    
    # Add independent tasks that can run in parallel
    for i in range(5):
        workflow.add_task(Task(
            id=f"task_{i}",
            name=f"Task {i}",
            action=lambda x: time.sleep(1) or f"Result {x}",
            params={"x": i}
        ))
    
    report = await workflow.execute_workflow_async()

# Run
# asyncio.run(main())
</code></pre>
<h2 id="scheduled-operations"><a class="header" href="#scheduled-operations">Scheduled Operations</a></h2>
<h3 id="task-scheduler"><a class="header" href="#task-scheduler">Task Scheduler</a></h3>
<pre><code class="language-python">from datetime import datetime, timedelta
import schedule
import threading

class TaskScheduler:
    """Schedule tasks to run at specific times"""
    
    def __init__(self):
        self.scheduled_tasks = []
        self.running = False
        self.thread = None
    
    def schedule_task(self, 
                     task: Callable,
                     schedule_type: str,
                     time_spec: str = None,
                     **kwargs):
        """Schedule a task"""
        
        if schedule_type == "daily":
            job = schedule.every().day.at(time_spec).do(task, **kwargs)
        
        elif schedule_type == "hourly":
            job = schedule.every().hour.do(task, **kwargs)
        
        elif schedule_type == "interval":
            minutes = int(time_spec)
            job = schedule.every(minutes).minutes.do(task, **kwargs)
        
        elif schedule_type == "weekly":
            day, time = time_spec.split()
            job = getattr(schedule.every(), day.lower()).at(time).do(task, **kwargs)
        
        else:
            raise ValueError(f"Unknown schedule type: {schedule_type}")
        
        self.scheduled_tasks.append({
            "job": job,
            "task": task.__name__,
            "schedule": schedule_type,
            "time_spec": time_spec
        })
        
        print(f"ğŸ“… Scheduled: {task.__name__} - {schedule_type} {time_spec or ''}")
    
    def start(self):
        """Start scheduler"""
        self.running = True
        self.thread = threading.Thread(target=self._run_scheduler)
        self.thread.daemon = True
        self.thread.start()
        print("ğŸ• Scheduler started")
    
    def stop(self):
        """Stop scheduler"""
        self.running = False
        if self.thread:
            self.thread.join()
        print("ğŸ›‘ Scheduler stopped")
    
    def _run_scheduler(self):
        """Run scheduler loop"""
        while self.running:
            schedule.run_pending()
            time.sleep(1)
    
    def list_scheduled_tasks(self) -&gt; List[Dict]:
        """List all scheduled tasks"""
        return self.scheduled_tasks

# Usage
scheduler = TaskScheduler()

def backup_database():
    print(f"ğŸ’¾ Running database backup at {datetime.now()}")
    # Backup logic here

def send_report():
    print(f"ğŸ“Š Sending daily report at {datetime.now()}")
    # Report logic here

def cleanup_temp_files():
    print(f"ğŸ§¹ Cleaning temp files at {datetime.now()}")
    # Cleanup logic here

# Schedule tasks
scheduler.schedule_task(backup_database, "daily", "02:00")
scheduler.schedule_task(send_report, "daily", "09:00")
scheduler.schedule_task(cleanup_temp_files, "interval", "60")  # Every hour

# Start scheduler
scheduler.start()

# Keep running
# try:
#     while True:
#         time.sleep(1)
# except KeyboardInterrupt:
#     scheduler.stop()
</code></pre>
<h3 id="cron-style-scheduling"><a class="header" href="#cron-style-scheduling">Cron-Style Scheduling</a></h3>
<pre><code class="language-python">from crontab import CronTab

class CronScheduler:
    """Cron-style task scheduling"""
    
    def __init__(self):
        self.cron = CronTab(user=True)
    
    def add_cron_job(self, 
                     command: str,
                     schedule: str,
                     comment: str = None):
        """Add cron job
        
        Schedule format: "minute hour day month weekday"
        Examples:
        - "0 2 * * *" - Daily at 2 AM
        - "*/15 * * * *" - Every 15 minutes
        - "0 9 * * 1-5" - Weekdays at 9 AM
        """
        job = self.cron.new(command=command, comment=comment)
        job.setall(schedule)
        self.cron.write()
        
        print(f"âœ… Added cron job: {comment or command}")
        print(f"   Schedule: {schedule}")
    
    def list_jobs(self) -&gt; List[Dict]:
        """List all cron jobs"""
        jobs = []
        for job in self.cron:
            jobs.append({
                "command": job.command,
                "schedule": str(job.slices),
                "comment": job.comment,
                "enabled": job.is_enabled()
            })
        return jobs
    
    def remove_job(self, comment: str):
        """Remove job by comment"""
        self.cron.remove_all(comment=comment)
        self.cron.write()
        print(f"ğŸ—‘ï¸  Removed job: {comment}")

# Usage
# cron = CronScheduler()
# cron.add_cron_job(
#     "python /path/to/backup.py",
#     "0 2 * * *",
#     "Daily backup"
# )
</code></pre>
<h2 id="event-driven-triggers"><a class="header" href="#event-driven-triggers">Event-Driven Triggers</a></h2>
<h3 id="event-listener-system"><a class="header" href="#event-listener-system">Event Listener System</a></h3>
<pre><code class="language-python">from typing import Callable, Dict, List
from queue import Queue
import threading

class EventType(Enum):
    FILE_CREATED = "file_created"
    FILE_MODIFIED = "file_modified"
    FILE_DELETED = "file_deleted"
    API_CALL = "api_call"
    THRESHOLD_EXCEEDED = "threshold_exceeded"
    ERROR_OCCURRED = "error_occurred"

@dataclass
class Event:
    """Event data"""
    type: EventType
    data: Dict[str, Any]
    timestamp: float = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()

class EventDrivenAgent:
    """Agent that responds to events"""
    
    def __init__(self):
        self.handlers = {}
        self.event_queue = Queue()
        self.running = False
        self.thread = None
    
    def register_handler(self, event_type: EventType, handler: Callable):
        """Register event handler"""
        if event_type not in self.handlers:
            self.handlers[event_type] = []
        
        self.handlers[event_type].append(handler)
        print(f"ğŸ“ Registered handler for {event_type.value}")
    
    def emit_event(self, event: Event):
        """Emit an event"""
        self.event_queue.put(event)
    
    def start(self):
        """Start event processing"""
        self.running = True
        self.thread = threading.Thread(target=self._process_events)
        self.thread.daemon = True
        self.thread.start()
        print("ğŸ¯ Event processor started")
    
    def stop(self):
        """Stop event processing"""
        self.running = False
        if self.thread:
            self.thread.join()
        print("ğŸ›‘ Event processor stopped")
    
    def _process_events(self):
        """Process events from queue"""
        while self.running:
            try:
                event = self.event_queue.get(timeout=1)
                self._handle_event(event)
            except:
                continue
    
    def _handle_event(self, event: Event):
        """Handle single event"""
        print(f"âš¡ Event: {event.type.value}")
        
        handlers = self.handlers.get(event.type, [])
        
        for handler in handlers:
            try:
                handler(event)
            except Exception as e:
                print(f"âŒ Handler error: {e}")

# Usage
agent = EventDrivenAgent()

# Register handlers
def on_file_created(event: Event):
    print(f"  ğŸ“„ File created: {event.data['filename']}")
    # Process new file

def on_threshold_exceeded(event: Event):
    print(f"  âš ï¸  Threshold exceeded: {event.data['metric']} = {event.data['value']}")
    # Send alert

def on_error(event: Event):
    print(f"  ğŸ’¥ Error occurred: {event.data['error']}")
    # Log and notify

agent.register_handler(EventType.FILE_CREATED, on_file_created)
agent.register_handler(EventType.THRESHOLD_EXCEEDED, on_threshold_exceeded)
agent.register_handler(EventType.ERROR_OCCURRED, on_error)

# Start processing
agent.start()

# Emit events
agent.emit_event(Event(
    type=EventType.FILE_CREATED,
    data={"filename": "data.csv"}
))

agent.emit_event(Event(
    type=EventType.THRESHOLD_EXCEEDED,
    data={"metric": "cpu_usage", "value": 95}
))
</code></pre>
<h3 id="file-system-watcher"><a class="header" href="#file-system-watcher">File System Watcher</a></h3>
<pre><code class="language-python">from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class FileWatcher(FileSystemEventHandler):
    """Watch file system for changes"""
    
    def __init__(self, agent: EventDrivenAgent):
        self.agent = agent
    
    def on_created(self, event):
        """File created"""
        if not event.is_directory:
            self.agent.emit_event(Event(
                type=EventType.FILE_CREATED,
                data={"path": event.src_path}
            ))
    
    def on_modified(self, event):
        """File modified"""
        if not event.is_directory:
            self.agent.emit_event(Event(
                type=EventType.FILE_MODIFIED,
                data={"path": event.src_path}
            ))
    
    def on_deleted(self, event):
        """File deleted"""
        if not event.is_directory:
            self.agent.emit_event(Event(
                type=EventType.FILE_DELETED,
                data={"path": event.src_path}
            ))

def start_file_watcher(path: str, agent: EventDrivenAgent):
    """Start watching directory"""
    event_handler = FileWatcher(agent)
    observer = Observer()
    observer.schedule(event_handler, path, recursive=True)
    observer.start()
    print(f"ğŸ‘ï¸  Watching: {path}")
    return observer

# Usage
# observer = start_file_watcher("/path/to/watch", agent)
</code></pre>
<h2 id="integration-with-existing-tools"><a class="header" href="#integration-with-existing-tools">Integration with Existing Tools</a></h2>
<h3 id="tool-integration-framework"><a class="header" href="#tool-integration-framework">Tool Integration Framework</a></h3>
<pre><code class="language-python">class ToolIntegration:
    """Integrate with external tools"""
    
    def __init__(self):
        self.tools = {}
    
    def register_tool(self, name: str, connector: Callable):
        """Register tool connector"""
        self.tools[name] = connector
        print(f"ğŸ”Œ Registered tool: {name}")
    
    def execute_tool(self, name: str, action: str, **params) -&gt; Dict:
        """Execute tool action"""
        if name not in self.tools:
            return {"success": False, "error": f"Tool not found: {name}"}
        
        try:
            result = self.tools[name](action, **params)
            return {"success": True, "result": result}
        except Exception as e:
            return {"success": False, "error": str(e)}

# Example integrations

def slack_connector(action: str, **params):
    """Slack integration"""
    if action == "send_message":
        channel = params.get("channel")
        message = params.get("message")
        # Send to Slack API
        print(f"ğŸ“± Slack: Sending to {channel}: {message}")
        return {"sent": True}
    
    elif action == "get_messages":
        channel = params.get("channel")
        # Get from Slack API
        return {"messages": []}

def email_connector(action: str, **params):
    """Email integration"""
    if action == "send":
        to = params.get("to")
        subject = params.get("subject")
        body = params.get("body")
        # Send email
        print(f"ğŸ“§ Email: Sending to {to}")
        return {"sent": True}

def database_connector(action: str, **params):
    """Database integration"""
    if action == "query":
        sql = params.get("sql")
        # Execute query
        print(f"ğŸ—„ï¸  Database: Executing query")
        return {"rows": []}
    
    elif action == "insert":
        table = params.get("table")
        data = params.get("data")
        # Insert data
        return {"inserted": True}

# Setup
integrations = ToolIntegration()
integrations.register_tool("slack", slack_connector)
integrations.register_tool("email", email_connector)
integrations.register_tool("database", database_connector)

# Use
integrations.execute_tool(
    "slack",
    "send_message",
    channel="#general",
    message="Task completed!"
)
</code></pre>
<h2 id="complete-automation-agent"><a class="header" href="#complete-automation-agent">Complete Automation Agent</a></h2>
<pre><code class="language-python">class AutomationAgent:
    """Complete task automation agent"""
    
    def __init__(self):
        self.workflow_engine = WorkflowEngine()
        self.scheduler = TaskScheduler()
        self.event_agent = EventDrivenAgent()
        self.integrations = ToolIntegration()
        self.client = openai.OpenAI()
    
    def create_automation(self, description: str) -&gt; Dict:
        """Create automation from natural language"""
        
        # Parse description to understand automation
        automation_spec = self.parse_automation_description(description)
        
        # Create workflow
        workflow_id = self.create_workflow(automation_spec)
        
        # Setup triggers
        if automation_spec.get("trigger_type") == "schedule":
            self.setup_scheduled_trigger(workflow_id, automation_spec)
        elif automation_spec.get("trigger_type") == "event":
            self.setup_event_trigger(workflow_id, automation_spec)
        
        return {
            "workflow_id": workflow_id,
            "automation_spec": automation_spec,
            "status": "active"
        }
    
    def parse_automation_description(self, description: str) -&gt; Dict:
        """Parse natural language automation description"""
        prompt = f"""Parse this automation request into a structured specification:

"{description}"

Provide JSON with:
- trigger_type: "schedule" or "event"
- trigger_spec: schedule time or event type
- steps: list of actions to perform
- integrations: tools needed

Specification:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        
        import json
        return json.loads(response.choices[0].message.content)
    
    def create_workflow(self, spec: Dict) -&gt; str:
        """Create workflow from specification"""
        workflow_id = f"workflow_{int(time.time())}"
        
        for i, step in enumerate(spec.get("steps", [])):
            task = Task(
                id=f"{workflow_id}_step_{i}",
                name=step.get("name"),
                action=self.create_action_from_spec(step),
                params=step.get("params", {}),
                dependencies=step.get("dependencies", [])
            )
            self.workflow_engine.add_task(task)
        
        return workflow_id
    
    def create_action_from_spec(self, step_spec: Dict) -&gt; Callable:
        """Create executable action from step specification"""
        action_type = step_spec.get("action_type")
        
        if action_type == "api_call":
            def action(**params):
                return self.integrations.execute_tool(
                    step_spec["tool"],
                    step_spec["action"],
                    **params
                )
            return action
        
        elif action_type == "data_processing":
            def action(**params):
                # Process data
                return {"processed": True}
            return action
        
        else:
            def action(**params):
                print(f"Executing: {step_spec.get('name')}")
                return {"done": True}
            return action
    
    def setup_scheduled_trigger(self, workflow_id: str, spec: Dict):
        """Setup scheduled trigger for workflow"""
        def run_workflow():
            print(f"ğŸ”„ Running scheduled workflow: {workflow_id}")
            self.workflow_engine.execute_workflow()
        
        self.scheduler.schedule_task(
            run_workflow,
            spec["trigger_spec"]["type"],
            spec["trigger_spec"]["time"]
        )
    
    def setup_event_trigger(self, workflow_id: str, spec: Dict):
        """Setup event trigger for workflow"""
        event_type = EventType[spec["trigger_spec"]["event"]]
        
        def on_event(event: Event):
            print(f"ğŸ¯ Event triggered workflow: {workflow_id}")
            self.workflow_engine.execute_workflow()
        
        self.event_agent.register_handler(event_type, on_event)

# Usage
agent = AutomationAgent()

# Create automation from description
automation = agent.create_automation("""
Every day at 9 AM:
1. Fetch data from the API
2. Process and analyze the data
3. Generate a report
4. Send the report via email to team@company.com
""")

print(f"Created automation: {automation['workflow_id']}")
</code></pre>
<h2 id="best-practices-10"><a class="header" href="#best-practices-10">Best Practices</a></h2>
<ol>
<li><strong>Idempotency</strong>: Tasks should be safely re-runnable</li>
<li><strong>Error handling</strong>: Always handle failures gracefully</li>
<li><strong>Logging</strong>: Track all automation executions</li>
<li><strong>Monitoring</strong>: Alert on failures</li>
<li><strong>Testing</strong>: Test workflows before production</li>
<li><strong>Documentation</strong>: Document automation logic</li>
<li><strong>Versioning</strong>: Track automation changes</li>
<li><strong>Rollback</strong>: Ability to revert changes</li>
<li><strong>Rate limiting</strong>: Donâ€™t overwhelm systems</li>
<li><strong>Security</strong>: Secure credentials and access</li>
</ol>
<h2 id="next-steps-14"><a class="header" href="#next-steps-14">Next Steps</a></h2>
<p>Chapter 6 (Specialized Agent Types) is complete! You now have deep knowledge of coding agents, research agents, and task automation agents. These specialized agents form the foundation for building powerful, domain-specific AI systems.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="agent-learning--adaptation"><a class="header" href="#agent-learning--adaptation">Agent Learning &amp; Adaptation</a></h1>
<h2 id="module-7-learning-objectives"><a class="header" href="#module-7-learning-objectives">Module 7: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Implement few-shot and RLHF learning strategies</li>
<li>âœ“ Build multimodal agents processing vision and audio</li>
<li>âœ“ Master LangChain, LangGraph, and other frameworks</li>
<li>âœ“ Design custom agentic frameworks</li>
<li>âœ“ Enable continuous learning and adaptation</li>
</ul>
<hr>
<h2 id="introduction-to-agent-learning"><a class="header" href="#introduction-to-agent-learning">Introduction to Agent Learning</a></h2>
<p>Learning and adaptation enable agents to improve over time, personalize to users, and handle new situations without explicit reprogramming.</p>
<h3 id="why-learning-matters"><a class="header" href="#why-learning-matters">Why Learning Matters</a></h3>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Improved performance over time</li>
<li>Personalization to individual users</li>
<li>Adaptation to changing environments</li>
<li>Reduced need for manual updates</li>
<li>Discovery of better strategies</li>
</ul>
<p><strong>Challenges</strong>:</p>
<ul>
<li>Avoiding catastrophic forgetting</li>
<li>Balancing exploration vs exploitation</li>
<li>Ensuring safe learning</li>
<li>Managing computational costs</li>
<li>Maintaining consistency</li>
</ul>
<h3 id="types-of-learning"><a class="header" href="#types-of-learning">Types of Learning</a></h3>
<ol>
<li><strong>Few-Shot Learning</strong>: Learn from minimal examples</li>
<li><strong>Reinforcement Learning</strong>: Learn from feedback</li>
<li><strong>Continuous Learning</strong>: Ongoing improvement</li>
<li><strong>Transfer Learning</strong>: Apply knowledge to new domains</li>
<li><strong>Meta-Learning</strong>: Learn how to learn</li>
</ol>
<h2 id="few-shot-learning"><a class="header" href="#few-shot-learning">Few-Shot Learning</a></h2>
<h3 id="in-context-learning"><a class="header" href="#in-context-learning">In-Context Learning</a></h3>
<pre><code class="language-python">from typing import List, Dict
import openai

class FewShotLearner:
    """Learn from few examples in context"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.examples = []
    
    def add_example(self, input_text: str, output_text: str, explanation: str = None):
        """Add training example"""
        example = {
            "input": input_text,
            "output": output_text,
            "explanation": explanation
        }
        self.examples.append(example)
        print(f"âœ… Added example: {input_text[:50]}...")
    
    def learn_from_examples(self, examples: List[Dict]):
        """Batch add examples"""
        for ex in examples:
            self.add_example(ex["input"], ex["output"], ex.get("explanation"))
    
    def predict(self, input_text: str, temperature: float = 0.3) -&gt; str:
        """Make prediction using learned examples"""
        
        # Build prompt with examples
        prompt = self.build_few_shot_prompt(input_text)
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature
        )
        
        return response.choices[0].message.content
    
    def build_few_shot_prompt(self, input_text: str) -&gt; str:
        """Build prompt with examples"""
        prompt = "Learn from these examples:\n\n"
        
        for i, example in enumerate(self.examples, 1):
            prompt += f"Example {i}:\n"
            prompt += f"Input: {example['input']}\n"
            prompt += f"Output: {example['output']}\n"
            if example.get('explanation'):
                prompt += f"Why: {example['explanation']}\n"
            prompt += "\n"
        
        prompt += f"Now apply what you learned:\n"
        prompt += f"Input: {input_text}\n"
        prompt += f"Output:"
        
        return prompt
    
    def evaluate(self, test_cases: List[Dict]) -&gt; Dict:
        """Evaluate performance on test cases"""
        correct = 0
        total = len(test_cases)
        
        for test in test_cases:
            prediction = self.predict(test["input"])
            expected = test["output"]
            
            # Simple exact match (can be more sophisticated)
            if prediction.strip().lower() == expected.strip().lower():
                correct += 1
        
        accuracy = correct / total if total &gt; 0 else 0
        
        return {
            "accuracy": accuracy,
            "correct": correct,
            "total": total
        }

# Usage
learner = FewShotLearner()

# Teach sentiment analysis
learner.add_example(
    "This product is amazing!",
    "positive",
    "Enthusiastic language indicates positive sentiment"
)
learner.add_example(
    "Terrible experience, very disappointed",
    "negative",
    "Words like 'terrible' and 'disappointed' indicate negative sentiment"
)
learner.add_example(
    "It's okay, nothing special",
    "neutral",
    "Lukewarm language indicates neutral sentiment"
)

# Test
result = learner.predict("I love this so much!")
print(f"Prediction: {result}")

# Evaluate
test_cases = [
    {"input": "Best purchase ever!", "output": "positive"},
    {"input": "Waste of money", "output": "negative"},
    {"input": "It works fine", "output": "neutral"}
]
evaluation = learner.evaluate(test_cases)
print(f"Accuracy: {evaluation['accuracy']:.1%}")
</code></pre>
<h3 id="dynamic-example-selection"><a class="header" href="#dynamic-example-selection">Dynamic Example Selection</a></h3>
<pre><code class="language-python">import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class AdaptiveFewShotLearner(FewShotLearner):
    """Select most relevant examples dynamically"""
    
    def __init__(self, max_examples: int = 5):
        super().__init__()
        self.max_examples = max_examples
        self.example_embeddings = []
    
    def add_example(self, input_text: str, output_text: str, explanation: str = None):
        """Add example with embedding"""
        super().add_example(input_text, output_text, explanation)
        
        # Get embedding
        embedding = self.get_embedding(input_text)
        self.example_embeddings.append(embedding)
    
    def get_embedding(self, text: str) -&gt; np.ndarray:
        """Get text embedding"""
        response = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return np.array(response.data[0].embedding)
    
    def select_relevant_examples(self, input_text: str) -&gt; List[Dict]:
        """Select most relevant examples for input"""
        if not self.examples:
            return []
        
        # Get input embedding
        input_embedding = self.get_embedding(input_text)
        
        # Calculate similarities
        similarities = []
        for i, example_embedding in enumerate(self.example_embeddings):
            similarity = cosine_similarity(
                input_embedding.reshape(1, -1),
                example_embedding.reshape(1, -1)
            )[0][0]
            similarities.append((i, similarity))
        
        # Sort by similarity
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # Select top examples
        selected_indices = [idx for idx, _ in similarities[:self.max_examples]]
        selected_examples = [self.examples[i] for i in selected_indices]
        
        return selected_examples
    
    def predict(self, input_text: str, temperature: float = 0.3) -&gt; str:
        """Predict using most relevant examples"""
        # Select relevant examples
        relevant_examples = self.select_relevant_examples(input_text)
        
        # Temporarily use only relevant examples
        original_examples = self.examples
        self.examples = relevant_examples
        
        # Make prediction
        result = super().predict(input_text, temperature)
        
        # Restore all examples
        self.examples = original_examples
        
        return result

# Usage
adaptive_learner = AdaptiveFewShotLearner(max_examples=3)

# Add many examples
examples = [
    ("Great product!", "positive"),
    ("Horrible quality", "negative"),
    ("Works as expected", "neutral"),
    ("Absolutely love it!", "positive"),
    ("Complete waste", "negative"),
    ("It's fine", "neutral"),
]

for inp, out in examples:
    adaptive_learner.add_example(inp, out)

# Predict - will use most relevant examples
result = adaptive_learner.predict("This is fantastic!")
print(f"Prediction: {result}")
</code></pre>
<h2 id="reinforcement-learning-from-feedback"><a class="header" href="#reinforcement-learning-from-feedback">Reinforcement Learning from Feedback</a></h2>
<h3 id="human-feedback-collection"><a class="header" href="#human-feedback-collection">Human Feedback Collection</a></h3>
<pre><code class="language-python">from dataclasses import dataclass
from typing import Optional
import time

@dataclass
class Feedback:
    """User feedback on agent response"""
    response_id: str
    rating: int  # 1-5
    comment: Optional[str] = None
    timestamp: float = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()

class FeedbackCollector:
    """Collect and manage user feedback"""
    
    def __init__(self):
        self.feedback_history = []
        self.response_cache = {}
    
    def record_response(self, response_id: str, prompt: str, response: str):
        """Record agent response"""
        self.response_cache[response_id] = {
            "prompt": prompt,
            "response": response,
            "timestamp": time.time()
        }
    
    def collect_feedback(self, response_id: str, rating: int, comment: str = None) -&gt; Feedback:
        """Collect feedback on response"""
        feedback = Feedback(
            response_id=response_id,
            rating=rating,
            comment=comment
        )
        
        self.feedback_history.append(feedback)
        print(f"ğŸ“ Feedback recorded: {rating}/5")
        
        return feedback
    
    def get_average_rating(self) -&gt; float:
        """Get average rating"""
        if not self.feedback_history:
            return 0.0
        
        total = sum(f.rating for f in self.feedback_history)
        return total / len(self.feedback_history)
    
    def get_positive_examples(self, threshold: int = 4) -&gt; List[Dict]:
        """Get highly-rated examples"""
        positive = []
        
        for feedback in self.feedback_history:
            if feedback.rating &gt;= threshold:
                response_data = self.response_cache.get(feedback.response_id)
                if response_data:
                    positive.append({
                        "prompt": response_data["prompt"],
                        "response": response_data["response"],
                        "rating": feedback.rating
                    })
        
        return positive
    
    def get_negative_examples(self, threshold: int = 2) -&gt; List[Dict]:
        """Get poorly-rated examples"""
        negative = []
        
        for feedback in self.feedback_history:
            if feedback.rating &lt;= threshold:
                response_data = self.response_cache.get(feedback.response_id)
                if response_data:
                    negative.append({
                        "prompt": response_data["prompt"],
                        "response": response_data["response"],
                        "rating": feedback.rating,
                        "comment": feedback.comment
                    })
        
        return negative

# Usage
collector = FeedbackCollector()

# Record response
response_id = "resp_001"
collector.record_response(
    response_id,
    "What is Python?",
    "Python is a programming language..."
)

# Collect feedback
collector.collect_feedback(response_id, 5, "Very helpful!")

# Get positive examples for learning
positive_examples = collector.get_positive_examples()
print(f"Positive examples: {len(positive_examples)}")
</code></pre>
<h3 id="learning-from-feedback"><a class="header" href="#learning-from-feedback">Learning from Feedback</a></h3>
<pre><code class="language-python">class RLFHAgent:
    """Agent that learns from human feedback"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.feedback_collector = FeedbackCollector()
        self.learner = AdaptiveFewShotLearner()
    
    def respond(self, prompt: str, response_id: str = None) -&gt; str:
        """Generate response"""
        if response_id is None:
            response_id = f"resp_{int(time.time())}"
        
        # Use learned examples
        positive_examples = self.feedback_collector.get_positive_examples()
        
        # Build prompt with positive examples
        enhanced_prompt = self.build_prompt_with_examples(prompt, positive_examples)
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": enhanced_prompt}],
            temperature=0.7
        )
        
        response_text = response.choices[0].message.content
        
        # Record for feedback
        self.feedback_collector.record_response(response_id, prompt, response_text)
        
        return response_text
    
    def build_prompt_with_examples(self, prompt: str, examples: List[Dict]) -&gt; str:
        """Build prompt incorporating learned examples"""
        if not examples:
            return prompt
        
        enhanced = "Here are examples of good responses:\n\n"
        
        for ex in examples[:5]:  # Use top 5
            enhanced += f"Q: {ex['prompt']}\n"
            enhanced += f"A: {ex['response']}\n\n"
        
        enhanced += f"Now respond to:\nQ: {prompt}\nA:"
        
        return enhanced
    
    def learn_from_feedback(self, response_id: str, rating: int, comment: str = None):
        """Learn from user feedback"""
        feedback = self.feedback_collector.collect_feedback(response_id, rating, comment)
        
        # If positive, add to examples
        if rating &gt;= 4:
            response_data = self.feedback_collector.response_cache.get(response_id)
            if response_data:
                self.learner.add_example(
                    response_data["prompt"],
                    response_data["response"],
                    f"User rated {rating}/5"
                )
                print("âœ… Learned from positive feedback")
        
        # If negative, analyze and improve
        elif rating &lt;= 2:
            self.analyze_negative_feedback(response_id, comment)
    
    def analyze_negative_feedback(self, response_id: str, comment: str):
        """Analyze negative feedback to improve"""
        response_data = self.feedback_collector.response_cache.get(response_id)
        if not response_data:
            return
        
        prompt = f"""Analyze this negative feedback:

Original prompt: {response_data['prompt']}
Response: {response_data['response']}
User feedback: {comment}

What went wrong and how to improve?"""
        
        analysis = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        print(f"ğŸ“Š Analysis: {analysis.choices[0].message.content[:200]}...")
    
    def get_performance_metrics(self) -&gt; Dict:
        """Get learning performance metrics"""
        avg_rating = self.feedback_collector.get_average_rating()
        total_feedback = len(self.feedback_collector.feedback_history)
        positive_count = len(self.feedback_collector.get_positive_examples())
        
        return {
            "average_rating": avg_rating,
            "total_feedback": total_feedback,
            "positive_examples": positive_count,
            "learned_examples": len(self.learner.examples)
        }

# Usage
agent = RLFHAgent()

# Interact and learn
response_id = "resp_001"
response = agent.respond("Explain machine learning", response_id)
print(f"Response: {response}")

# User provides feedback
agent.learn_from_feedback(response_id, 5, "Clear and concise!")

# Check improvement
metrics = agent.get_performance_metrics()
print(f"Metrics: {metrics}")
</code></pre>
<h2 id="continuous-learning"><a class="header" href="#continuous-learning">Continuous Learning</a></h2>
<h3 id="online-learning-system"><a class="header" href="#online-learning-system">Online Learning System</a></h3>
<pre><code class="language-python">class ContinuousLearner:
    """Agent that continuously learns from interactions"""
    
    def __init__(self, memory_size: int = 1000):
        self.client = openai.OpenAI()
        self.memory_size = memory_size
        self.interaction_history = []
        self.performance_history = []
    
    def interact(self, prompt: str) -&gt; Dict:
        """Interact and learn"""
        # Generate response
        response = self.generate_response(prompt)
        
        # Record interaction
        interaction = {
            "prompt": prompt,
            "response": response,
            "timestamp": time.time()
        }
        self.interaction_history.append(interaction)
        
        # Trim history if too large
        if len(self.interaction_history) &gt; self.memory_size:
            self.interaction_history = self.interaction_history[-self.memory_size:]
        
        return {
            "response": response,
            "interaction_id": len(self.interaction_history) - 1
        }
    
    def generate_response(self, prompt: str) -&gt; str:
        """Generate response using learned knowledge"""
        # Get relevant past interactions
        relevant = self.get_relevant_interactions(prompt)
        
        # Build context
        context = self.build_context(relevant)
        
        # Generate
        messages = [
            {"role": "system", "content": context},
            {"role": "user", "content": prompt}
        ]
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7
        )
        
        return response.choices[0].message.content
    
    def get_relevant_interactions(self, prompt: str, top_k: int = 5) -&gt; List[Dict]:
        """Get relevant past interactions"""
        if not self.interaction_history:
            return []
        
        # Simple keyword matching (can use embeddings for better results)
        prompt_words = set(prompt.lower().split())
        
        scored = []
        for interaction in self.interaction_history:
            interaction_words = set(interaction["prompt"].lower().split())
            overlap = len(prompt_words &amp; interaction_words)
            scored.append((interaction, overlap))
        
        scored.sort(key=lambda x: x[1], reverse=True)
        return [interaction for interaction, _ in scored[:top_k]]
    
    def build_context(self, relevant_interactions: List[Dict]) -&gt; str:
        """Build context from relevant interactions"""
        if not relevant_interactions:
            return "You are a helpful assistant."
        
        context = "You are a helpful assistant. Here are relevant past interactions:\n\n"
        
        for interaction in relevant_interactions:
            context += f"Q: {interaction['prompt']}\n"
            context += f"A: {interaction['response']}\n\n"
        
        context += "Use this knowledge to inform your response."
        
        return context
    
    def update_from_feedback(self, interaction_id: int, feedback: Dict):
        """Update based on feedback"""
        if interaction_id &gt;= len(self.interaction_history):
            return
        
        interaction = self.interaction_history[interaction_id]
        interaction["feedback"] = feedback
        
        # Track performance
        self.performance_history.append({
            "timestamp": time.time(),
            "rating": feedback.get("rating", 0)
        })
    
    def get_learning_curve(self) -&gt; List[float]:
        """Get performance over time"""
        if not self.performance_history:
            return []
        
        # Calculate moving average
        window = 10
        curve = []
        
        for i in range(len(self.performance_history)):
            start = max(0, i - window + 1)
            window_ratings = [
                p["rating"] for p in self.performance_history[start:i+1]
            ]
            avg = sum(window_ratings) / len(window_ratings)
            curve.append(avg)
        
        return curve

# Usage
learner = ContinuousLearner()

# Continuous interaction
for i in range(10):
    result = learner.interact(f"Question {i}: What is AI?")
    print(f"Response {i}: {result['response'][:50]}...")
    
    # Simulate feedback
    learner.update_from_feedback(result["interaction_id"], {"rating": 4})

# Check learning curve
curve = learner.get_learning_curve()
print(f"Learning curve: {curve}")
</code></pre>
<h2 id="fine-tuning-for-specific-tasks"><a class="header" href="#fine-tuning-for-specific-tasks">Fine-Tuning for Specific Tasks</a></h2>
<h3 id="preparing-training-data"><a class="header" href="#preparing-training-data">Preparing Training Data</a></h3>
<pre><code class="language-python">class FineTuningDataPrep:
    """Prepare data for fine-tuning"""
    
    def __init__(self):
        self.training_data = []
    
    def add_training_example(self, 
                            system_message: str,
                            user_message: str,
                            assistant_message: str):
        """Add training example"""
        example = {
            "messages": [
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message},
                {"role": "assistant", "content": assistant_message}
            ]
        }
        self.training_data.append(example)
    
    def load_from_feedback(self, feedback_collector: FeedbackCollector, min_rating: int = 4):
        """Load training data from positive feedback"""
        positive_examples = feedback_collector.get_positive_examples(threshold=min_rating)
        
        for example in positive_examples:
            self.add_training_example(
                "You are a helpful assistant.",
                example["prompt"],
                example["response"]
            )
        
        print(f"Loaded {len(positive_examples)} training examples")
    
    def export_jsonl(self, filename: str):
        """Export to JSONL format for fine-tuning"""
        import json
        
        with open(filename, 'w') as f:
            for example in self.training_data:
                f.write(json.dumps(example) + '\n')
        
        print(f"Exported {len(self.training_data)} examples to {filename}")
    
    def validate_data(self) -&gt; Dict:
        """Validate training data quality"""
        if not self.training_data:
            return {"valid": False, "error": "No training data"}
        
        issues = []
        
        for i, example in enumerate(self.training_data):
            # Check structure
            if "messages" not in example:
                issues.append(f"Example {i}: Missing 'messages' field")
                continue
            
            messages = example["messages"]
            
            # Check message count
            if len(messages) &lt; 2:
                issues.append(f"Example {i}: Too few messages")
            
            # Check roles
            roles = [m["role"] for m in messages]
            if "user" not in roles or "assistant" not in roles:
                issues.append(f"Example {i}: Missing required roles")
        
        return {
            "valid": len(issues) == 0,
            "total_examples": len(self.training_data),
            "issues": issues
        }

# Usage
prep = FineTuningDataPrep()

# Add examples
prep.add_training_example(
    "You are a Python expert.",
    "How do I sort a list?",
    "Use the sorted() function or list.sort() method..."
)

# Validate
validation = prep.validate_data()
print(f"Valid: {validation['valid']}")

# Export
prep.export_jsonl("training_data.jsonl")
</code></pre>
<h2 id="transfer-learning"><a class="header" href="#transfer-learning">Transfer Learning</a></h2>
<h3 id="domain-adaptation"><a class="header" href="#domain-adaptation">Domain Adaptation</a></h3>
<pre><code class="language-python">class DomainAdapter:
    """Adapt agent to new domain"""
    
    def __init__(self, base_agent):
        self.base_agent = base_agent
        self.domain_examples = []
        self.client = openai.OpenAI()
    
    def add_domain_knowledge(self, domain: str, examples: List[Dict]):
        """Add domain-specific examples"""
        self.domain_examples.extend(examples)
        print(f"Added {len(examples)} examples for domain: {domain}")
    
    def adapt_response(self, prompt: str, domain: str) -&gt; str:
        """Generate domain-adapted response"""
        # Get domain examples
        domain_context = self.build_domain_context(domain)
        
        # Generate with domain context
        messages = [
            {"role": "system", "content": domain_context},
            {"role": "user", "content": prompt}
        ]
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.5
        )
        
        return response.choices[0].message.content
    
    def build_domain_context(self, domain: str) -&gt; str:
        """Build context for specific domain"""
        context = f"You are an expert in {domain}.\n\n"
        context += "Domain-specific examples:\n\n"
        
        # Filter examples for this domain
        relevant = [ex for ex in self.domain_examples if ex.get("domain") == domain]
        
        for ex in relevant[:5]:
            context += f"Q: {ex['input']}\n"
            context += f"A: {ex['output']}\n\n"
        
        return context

# Usage
adapter = DomainAdapter(base_agent=None)

# Add medical domain knowledge
medical_examples = [
    {
        "domain": "medical",
        "input": "What is hypertension?",
        "output": "Hypertension is high blood pressure..."
    }
]

adapter.add_domain_knowledge("medical", medical_examples)

# Adapt to medical domain
response = adapter.adapt_response(
    "Explain diabetes",
    domain="medical"
)
print(response)
</code></pre>
<h2 id="meta-learning"><a class="header" href="#meta-learning">Meta-Learning</a></h2>
<h3 id="learning-to-learn"><a class="header" href="#learning-to-learn">Learning to Learn</a></h3>
<pre><code class="language-python">class MetaLearner:
    """Learn how to learn new tasks quickly"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.task_history = []
        self.learning_strategies = []
    
    def learn_new_task(self, task_description: str, examples: List[Dict]) -&gt; Dict:
        """Learn a new task"""
        print(f"ğŸ“š Learning new task: {task_description}")
        
        # Analyze task
        task_analysis = self.analyze_task(task_description, examples)
        
        # Select learning strategy
        strategy = self.select_strategy(task_analysis)
        
        # Apply strategy
        learned_model = self.apply_strategy(strategy, examples)
        
        # Record
        self.task_history.append({
            "description": task_description,
            "analysis": task_analysis,
            "strategy": strategy,
            "examples_count": len(examples)
        })
        
        return {
            "task": task_description,
            "strategy": strategy,
            "model": learned_model
        }
    
    def analyze_task(self, description: str, examples: List[Dict]) -&gt; Dict:
        """Analyze task characteristics"""
        prompt = f"""Analyze this learning task:

Task: {description}

Examples: {len(examples)}
Sample: {examples[0] if examples else 'None'}

Determine:
1. Task type (classification, generation, etc.)
2. Complexity (simple, medium, complex)
3. Required examples (few, many)
4. Best learning approach

Analysis:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        # Parse analysis (simplified)
        return {
            "type": "classification",
            "complexity": "medium",
            "analysis": response.choices[0].message.content
        }
    
    def select_strategy(self, task_analysis: Dict) -&gt; str:
        """Select learning strategy based on task"""
        complexity = task_analysis.get("complexity", "medium")
        
        if complexity == "simple":
            return "few-shot"
        elif complexity == "medium":
            return "adaptive-few-shot"
        else:
            return "fine-tuning"
    
    def apply_strategy(self, strategy: str, examples: List[Dict]) -&gt; Any:
        """Apply selected learning strategy"""
        if strategy == "few-shot":
            learner = FewShotLearner()
            for ex in examples:
                learner.add_example(ex["input"], ex["output"])
            return learner
        
        elif strategy == "adaptive-few-shot":
            learner = AdaptiveFewShotLearner()
            for ex in examples:
                learner.add_example(ex["input"], ex["output"])
            return learner
        
        else:
            # Would implement fine-tuning
            return None
    
    def get_learning_insights(self) -&gt; Dict:
        """Get insights from learning history"""
        if not self.task_history:
            return {}
        
        strategies_used = {}
        for task in self.task_history:
            strategy = task["strategy"]
            strategies_used[strategy] = strategies_used.get(strategy, 0) + 1
        
        return {
            "total_tasks_learned": len(self.task_history),
            "strategies_used": strategies_used,
            "avg_examples_per_task": sum(t["examples_count"] for t in self.task_history) / len(self.task_history)
        }

# Usage
meta_learner = MetaLearner()

# Learn multiple tasks
tasks = [
    {
        "description": "Sentiment analysis",
        "examples": [
            {"input": "Great!", "output": "positive"},
            {"input": "Terrible", "output": "negative"}
        ]
    },
    {
        "description": "Language detection",
        "examples": [
            {"input": "Hello", "output": "English"},
            {"input": "Bonjour", "output": "French"}
        ]
    }
]

for task in tasks:
    result = meta_learner.learn_new_task(task["description"], task["examples"])
    print(f"Learned using: {result['strategy']}")

# Get insights
insights = meta_learner.get_learning_insights()
print(f"Insights: {insights}")
</code></pre>
<h2 id="best-practices-11"><a class="header" href="#best-practices-11">Best Practices</a></h2>
<ol>
<li><strong>Start simple</strong>: Begin with few-shot learning</li>
<li><strong>Collect feedback</strong>: Continuously gather user input</li>
<li><strong>Monitor performance</strong>: Track learning metrics</li>
<li><strong>Avoid overfitting</strong>: Donâ€™t memorize, generalize</li>
<li><strong>Safe learning</strong>: Validate before deploying</li>
<li><strong>Incremental updates</strong>: Small, frequent improvements</li>
<li><strong>A/B testing</strong>: Compare learned vs baseline</li>
<li><strong>Human oversight</strong>: Review learned behaviors</li>
<li><strong>Version control</strong>: Track model versions</li>
<li><strong>Rollback capability</strong>: Revert if performance degrades</li>
</ol>
<h2 id="next-steps-15"><a class="header" href="#next-steps-15">Next Steps</a></h2>
<p>You now understand agent learning and adaptation in depth! Next, weâ€™ll explore multimodal agents that work with images, audio, and other modalities.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="multimodal-agents"><a class="header" href="#multimodal-agents">Multimodal Agents</a></h1>
<h2 id="introduction-to-multimodal-ai"><a class="header" href="#introduction-to-multimodal-ai">Introduction to Multimodal AI</a></h2>
<p>Multimodal agents can process and generate multiple types of data: text, images, audio, video, and more. This enables richer interactions and broader capabilities.</p>
<h3 id="why-multimodal-matters"><a class="header" href="#why-multimodal-matters">Why Multimodal Matters</a></h3>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Richer understanding of context</li>
<li>More natural interactions</li>
<li>Broader range of tasks</li>
<li>Better accessibility</li>
<li>Cross-modal reasoning</li>
</ul>
<p><strong>Challenges</strong>:</p>
<ul>
<li>Increased complexity</li>
<li>Higher computational costs</li>
<li>Data alignment across modalities</li>
<li>Quality control</li>
<li>Privacy concerns</li>
</ul>
<h3 id="modalities"><a class="header" href="#modalities">Modalities</a></h3>
<ol>
<li><strong>Vision</strong>: Images, videos, screenshots</li>
<li><strong>Audio</strong>: Speech, music, sounds</li>
<li><strong>Text</strong>: Natural language</li>
<li><strong>Documents</strong>: PDFs, spreadsheets</li>
<li><strong>Structured Data</strong>: Tables, graphs</li>
</ol>
<h2 id="vision-and-image-understanding"><a class="header" href="#vision-and-image-understanding">Vision and Image Understanding</a></h2>
<h3 id="image-analysis"><a class="header" href="#image-analysis">Image Analysis</a></h3>
<pre><code class="language-python">import base64
from pathlib import Path
import openai

class VisionAgent:
    """Agent with vision capabilities"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def analyze_image(self, image_path: str, question: str = None) -&gt; str:
        """Analyze image and answer questions"""
        
        # Read and encode image
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')
        
        # Determine image type
        ext = Path(image_path).suffix.lower()
        mime_type = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.webp': 'image/webp'
        }.get(ext, 'image/jpeg')
        
        # Build prompt
        if question:
            prompt = question
        else:
            prompt = "Describe this image in detail."
        
        # Call vision model
        response = self.client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime_type};base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )
        
        return response.choices[0].message.content
    
    def extract_text_from_image(self, image_path: str) -&gt; str:
        """Extract text from image (OCR)"""
        return self.analyze_image(
            image_path,
            "Extract all text from this image. Provide the text exactly as it appears."
        )
    
    def describe_scene(self, image_path: str) -&gt; Dict:
        """Get detailed scene description"""
        description = self.analyze_image(
            image_path,
            """Describe this image in detail:
            1. Main subjects
            2. Setting/location
            3. Actions/activities
            4. Colors and mood
            5. Notable details"""
        )
        
        return {"description": description}
    
    def identify_objects(self, image_path: str) -&gt; List[str]:
        """Identify objects in image"""
        result = self.analyze_image(
            image_path,
            "List all objects visible in this image, one per line."
        )
        
        # Parse list
        objects = [line.strip('- ').strip() for line in result.split('\n') if line.strip()]
        return objects
    
    def compare_images(self, image1_path: str, image2_path: str) -&gt; str:
        """Compare two images"""
        
        # Encode both images
        images_data = []
        for path in [image1_path, image2_path]:
            with open(path, "rb") as f:
                data = base64.b64encode(f.read()).decode('utf-8')
                images_data.append(data)
        
        # Compare
        response = self.client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "Compare these two images. What are the similarities and differences?"},
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{images_data[0]}"}
                        },
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{images_data[1]}"}
                        }
                    ]
                }
            ],
            max_tokens=500
        )
        
        return response.choices[0].message.content
    
    def answer_visual_question(self, image_path: str, question: str) -&gt; str:
        """Answer specific question about image"""
        return self.analyze_image(image_path, question)

# Usage
vision_agent = VisionAgent()

# Analyze image
description = vision_agent.analyze_image("photo.jpg")
print(f"Description: {description}")

# Extract text (OCR)
text = vision_agent.extract_text_from_image("document.jpg")
print(f"Extracted text: {text}")

# Identify objects
objects = vision_agent.identify_objects("scene.jpg")
print(f"Objects: {objects}")

# Answer question
answer = vision_agent.answer_visual_question(
    "chart.jpg",
    "What is the trend shown in this chart?"
)
print(f"Answer: {answer}")
</code></pre>
<h3 id="image-generation"><a class="header" href="#image-generation">Image Generation</a></h3>
<pre><code class="language-python">class ImageGenerator:
    """Generate images from text"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def generate_image(self, 
                      prompt: str,
                      size: str = "1024x1024",
                      quality: str = "standard",
                      n: int = 1) -&gt; List[str]:
        """Generate image from text prompt"""
        
        response = self.client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size=size,
            quality=quality,
            n=n
        )
        
        # Get URLs
        image_urls = [img.url for img in response.data]
        
        return image_urls
    
    def edit_image(self, 
                   image_path: str,
                   mask_path: str,
                   prompt: str) -&gt; str:
        """Edit image using mask"""
        
        response = self.client.images.edit(
            image=open(image_path, "rb"),
            mask=open(mask_path, "rb"),
            prompt=prompt,
            n=1,
            size="1024x1024"
        )
        
        return response.data[0].url
    
    def create_variation(self, image_path: str, n: int = 1) -&gt; List[str]:
        """Create variations of image"""
        
        response = self.client.images.create_variation(
            image=open(image_path, "rb"),
            n=n,
            size="1024x1024"
        )
        
        return [img.url for img in response.data]

# Usage
generator = ImageGenerator()

# Generate image
urls = generator.generate_image(
    "A futuristic AI agent helping humans",
    quality="hd"
)
print(f"Generated: {urls[0]}")

# Create variations
variations = generator.create_variation("original.png", n=3)
print(f"Created {len(variations)} variations")
</code></pre>
<h2 id="audio-processing"><a class="header" href="#audio-processing">Audio Processing</a></h2>
<h3 id="speech-recognition"><a class="header" href="#speech-recognition">Speech Recognition</a></h3>
<pre><code class="language-python">class AudioAgent:
    """Agent with audio capabilities"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def transcribe_audio(self, audio_path: str, language: str = None) -&gt; Dict:
        """Transcribe audio to text"""
        
        with open(audio_path, "rb") as audio_file:
            transcript = self.client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language=language,
                response_format="verbose_json"
            )
        
        return {
            "text": transcript.text,
            "language": transcript.language,
            "duration": transcript.duration,
            "segments": transcript.segments if hasattr(transcript, 'segments') else []
        }
    
    def translate_audio(self, audio_path: str) -&gt; str:
        """Translate audio to English"""
        
        with open(audio_path, "rb") as audio_file:
            translation = self.client.audio.translations.create(
                model="whisper-1",
                file=audio_file
            )
        
        return translation.text
    
    def transcribe_with_timestamps(self, audio_path: str) -&gt; List[Dict]:
        """Transcribe with word-level timestamps"""
        
        result = self.transcribe_audio(audio_path)
        
        segments = []
        for segment in result.get("segments", []):
            segments.append({
                "start": segment.get("start"),
                "end": segment.get("end"),
                "text": segment.get("text")
            })
        
        return segments

# Usage
audio_agent = AudioAgent()

# Transcribe
result = audio_agent.transcribe_audio("speech.mp3")
print(f"Transcription: {result['text']}")
print(f"Language: {result['language']}")

# Translate
translation = audio_agent.translate_audio("french_audio.mp3")
print(f"Translation: {translation}")

# With timestamps
segments = audio_agent.transcribe_with_timestamps("interview.mp3")
for seg in segments:
    print(f"[{seg['start']:.2f}s - {seg['end']:.2f}s]: {seg['text']}")
</code></pre>
<h3 id="text-to-speech"><a class="header" href="#text-to-speech">Text-to-Speech</a></h3>
<pre><code class="language-python">class TextToSpeech:
    """Convert text to speech"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def synthesize_speech(self,
                         text: str,
                         voice: str = "alloy",
                         model: str = "tts-1",
                         output_path: str = "speech.mp3") -&gt; str:
        """Convert text to speech
        
        Voices: alloy, echo, fable, onyx, nova, shimmer
        Models: tts-1 (faster), tts-1-hd (higher quality)
        """
        
        response = self.client.audio.speech.create(
            model=model,
            voice=voice,
            input=text
        )
        
        # Save to file
        response.stream_to_file(output_path)
        
        return output_path
    
    def synthesize_long_text(self,
                            text: str,
                            voice: str = "alloy",
                            chunk_size: int = 4000) -&gt; List[str]:
        """Synthesize long text in chunks"""
        
        # Split into chunks
        chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]
        
        output_files = []
        for i, chunk in enumerate(chunks):
            output_path = f"speech_part_{i}.mp3"
            self.synthesize_speech(chunk, voice, output_path=output_path)
            output_files.append(output_path)
        
        return output_files

# Usage
tts = TextToSpeech()

# Synthesize
audio_file = tts.synthesize_speech(
    "Hello! I am an AI agent with voice capabilities.",
    voice="nova"
)
print(f"Generated audio: {audio_file}")
</code></pre>
<h2 id="document-parsing"><a class="header" href="#document-parsing">Document Parsing</a></h2>
<h3 id="pdf-processing"><a class="header" href="#pdf-processing">PDF Processing</a></h3>
<pre><code class="language-python">import PyPDF2
from typing import List, Dict

class DocumentAgent:
    """Process various document types"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.vision_agent = VisionAgent()
    
    def extract_text_from_pdf(self, pdf_path: str) -&gt; Dict:
        """Extract text from PDF"""
        
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            
            text_by_page = []
            for page_num, page in enumerate(pdf_reader.pages):
                text = page.extract_text()
                text_by_page.append({
                    "page": page_num + 1,
                    "text": text
                })
            
            full_text = "\n\n".join([p["text"] for p in text_by_page])
            
            return {
                "num_pages": len(pdf_reader.pages),
                "pages": text_by_page,
                "full_text": full_text
            }
    
    def analyze_pdf_with_vision(self, pdf_path: str) -&gt; List[Dict]:
        """Analyze PDF pages as images"""
        
        # Convert PDF pages to images (requires pdf2image)
        from pdf2image import convert_from_path
        
        images = convert_from_path(pdf_path)
        
        analyses = []
        for i, image in enumerate(images):
            # Save temporarily
            temp_path = f"temp_page_{i}.jpg"
            image.save(temp_path, 'JPEG')
            
            # Analyze with vision
            analysis = self.vision_agent.analyze_image(temp_path)
            
            analyses.append({
                "page": i + 1,
                "analysis": analysis
            })
            
            # Clean up
            import os
            os.remove(temp_path)
        
        return analyses
    
    def extract_tables_from_pdf(self, pdf_path: str) -&gt; List[Dict]:
        """Extract tables from PDF"""
        
        # Using tabula-py for table extraction
        import tabula
        
        tables = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True)
        
        extracted = []
        for i, table in enumerate(tables):
            extracted.append({
                "table_num": i + 1,
                "data": table.to_dict('records'),
                "shape": table.shape
            })
        
        return extracted
    
    def summarize_document(self, text: str, max_length: int = 500) -&gt; str:
        """Summarize document"""
        
        prompt = f"""Summarize this document in {max_length} words or less:

{text[:10000]}  # Limit input

Summary:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return response.choices[0].message.content
    
    def answer_document_question(self, text: str, question: str) -&gt; str:
        """Answer question about document"""
        
        prompt = f"""Based on this document, answer the question:

Document:
{text[:8000]}

Question: {question}

Answer:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return response.choices[0].message.content

# Usage
doc_agent = DocumentAgent()

# Extract text
result = doc_agent.extract_text_from_pdf("document.pdf")
print(f"Pages: {result['num_pages']}")
print(f"First page: {result['pages'][0]['text'][:200]}...")

# Summarize
summary = doc_agent.summarize_document(result['full_text'])
print(f"Summary: {summary}")

# Answer question
answer = doc_agent.answer_document_question(
    result['full_text'],
    "What are the main conclusions?"
)
print(f"Answer: {answer}")
</code></pre>
<h2 id="cross-modal-reasoning"><a class="header" href="#cross-modal-reasoning">Cross-Modal Reasoning</a></h2>
<h3 id="multimodal-understanding"><a class="header" href="#multimodal-understanding">Multimodal Understanding</a></h3>
<pre><code class="language-python">class MultimodalAgent:
    """Agent that reasons across modalities"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.vision = VisionAgent()
        self.audio = AudioAgent()
        self.document = DocumentAgent()
    
    def analyze_multimodal_input(self, inputs: Dict) -&gt; str:
        """Analyze multiple types of input together"""
        
        context = "Analyzing multimodal input:\n\n"
        
        # Process each modality
        if "image" in inputs:
            image_analysis = self.vision.analyze_image(inputs["image"])
            context += f"Image: {image_analysis}\n\n"
        
        if "audio" in inputs:
            audio_transcript = self.audio.transcribe_audio(inputs["audio"])
            context += f"Audio: {audio_transcript['text']}\n\n"
        
        if "text" in inputs:
            context += f"Text: {inputs['text']}\n\n"
        
        if "document" in inputs:
            doc_content = self.document.extract_text_from_pdf(inputs["document"])
            context += f"Document: {doc_content['full_text'][:1000]}...\n\n"
        
        # Synthesize understanding
        prompt = f"""{context}

Based on all this information, provide a comprehensive analysis:
1. Key themes across all modalities
2. How the different inputs relate to each other
3. Overall insights

Analysis:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        return response.choices[0].message.content
    
    def generate_multimodal_response(self, 
                                    query: str,
                                    include_image: bool = False,
                                    include_audio: bool = False) -&gt; Dict:
        """Generate response in multiple modalities"""
        
        # Generate text response
        text_response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": query}]
        ).choices[0].message.content
        
        result = {"text": text_response}
        
        # Generate image if requested
        if include_image:
            # Extract visual description from text
            image_prompt = self.extract_visual_description(text_response)
            generator = ImageGenerator()
            image_url = generator.generate_image(image_prompt)[0]
            result["image"] = image_url
        
        # Generate audio if requested
        if include_audio:
            tts = TextToSpeech()
            audio_file = tts.synthesize_speech(text_response)
            result["audio"] = audio_file
        
        return result
    
    def extract_visual_description(self, text: str) -&gt; str:
        """Extract visual description for image generation"""
        
        prompt = f"""From this text, create a detailed visual description suitable for image generation:

{text}

Visual description:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        return response.choices[0].message.content
    
    def create_presentation(self, topic: str, num_slides: int = 5) -&gt; List[Dict]:
        """Create multimodal presentation"""
        
        # Generate outline
        outline_prompt = f"Create a {num_slides}-slide presentation outline about: {topic}"
        
        outline_response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": outline_prompt}]
        )
        
        outline = outline_response.choices[0].message.content
        
        # Generate each slide
        slides = []
        generator = ImageGenerator()
        tts = TextToSpeech()
        
        for i in range(num_slides):
            # Generate slide content
            slide_prompt = f"""Create content for slide {i+1} of presentation about {topic}.
            
Outline: {outline}

Provide:
1. Title
2. Key points (3-5 bullets)
3. Visual description for image

Slide content:"""
            
            slide_response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": slide_prompt}]
            )
            
            slide_content = slide_response.choices[0].message.content
            
            # Generate image
            visual_desc = self.extract_visual_description(slide_content)
            image_url = generator.generate_image(visual_desc)[0]
            
            # Generate narration audio
            audio_file = tts.synthesize_speech(
                slide_content,
                output_path=f"slide_{i+1}_narration.mp3"
            )
            
            slides.append({
                "slide_num": i + 1,
                "content": slide_content,
                "image": image_url,
                "audio": audio_file
            })
        
        return slides

# Usage
multimodal_agent = MultimodalAgent()

# Analyze multimodal input
analysis = multimodal_agent.analyze_multimodal_input({
    "image": "chart.jpg",
    "text": "This shows our quarterly results",
    "audio": "explanation.mp3"
})
print(f"Analysis: {analysis}")

# Generate multimodal response
response = multimodal_agent.generate_multimodal_response(
    "Explain quantum computing",
    include_image=True,
    include_audio=True
)
print(f"Text: {response['text']}")
print(f"Image: {response['image']}")
print(f"Audio: {response['audio']}")

# Create presentation
slides = multimodal_agent.create_presentation("AI Agents", num_slides=3)
for slide in slides:
    print(f"Slide {slide['slide_num']}: {slide['content'][:100]}...")
</code></pre>
<h2 id="best-practices-12"><a class="header" href="#best-practices-12">Best Practices</a></h2>
<ol>
<li><strong>Choose right modality</strong>: Use most appropriate for task</li>
<li><strong>Quality control</strong>: Validate outputs across modalities</li>
<li><strong>Accessibility</strong>: Provide alternatives (captions, transcripts)</li>
<li><strong>Privacy</strong>: Handle sensitive data carefully</li>
<li><strong>Cost management</strong>: Multimodal can be expensive</li>
<li><strong>Caching</strong>: Reuse processed results</li>
<li><strong>Error handling</strong>: Each modality can fail differently</li>
<li><strong>User preferences</strong>: Let users choose modalities</li>
<li><strong>Testing</strong>: Test across all modalities</li>
<li><strong>Performance</strong>: Optimize processing pipelines</li>
</ol>
<h2 id="next-steps-16"><a class="header" href="#next-steps-16">Next Steps</a></h2>
<p>You now understand multimodal agents in depth! Next, weâ€™ll explore agentic frameworks that help build complex agent systems.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="agentic-frameworks"><a class="header" href="#agentic-frameworks">Agentic Frameworks</a></h1>
<h2 id="introduction-to-agent-frameworks"><a class="header" href="#introduction-to-agent-frameworks">Introduction to Agent Frameworks</a></h2>
<p>Frameworks provide pre-built components, patterns, and tools for building agents faster and more reliably. They handle common challenges so you can focus on your specific use case.</p>
<h3 id="why-use-frameworks"><a class="header" href="#why-use-frameworks">Why Use Frameworks?</a></h3>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Faster development</li>
<li>Battle-tested patterns</li>
<li>Community support</li>
<li>Built-in best practices</li>
<li>Easier maintenance</li>
<li>Rich ecosystem</li>
</ul>
<p><strong>Trade-offs</strong>:</p>
<ul>
<li>Learning curve</li>
<li>Framework lock-in</li>
<li>Less control</li>
<li>Overhead</li>
<li>Version dependencies</li>
</ul>
<h3 id="popular-frameworks"><a class="header" href="#popular-frameworks">Popular Frameworks</a></h3>
<ol>
<li><strong>LangChain</strong>: Comprehensive, modular</li>
<li><strong>LangGraph</strong>: State machines for agents</li>
<li><strong>AutoGPT</strong>: Autonomous agents</li>
<li><strong>CrewAI</strong>: Multi-agent collaboration</li>
<li><strong>AutoGen</strong>: Conversational agents</li>
</ol>
<h2 id="langchain-and-langgraph"><a class="header" href="#langchain-and-langgraph">LangChain and LangGraph</a></h2>
<h3 id="langchain-basics"><a class="header" href="#langchain-basics">LangChain Basics</a></h3>
<pre><code class="language-python">from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.memory import ConversationBufferMemory

class LangChainAgent:
    """Agent built with LangChain"""
    
    def __init__(self):
        self.llm = OpenAI(temperature=0.7)
        self.memory = ConversationBufferMemory()
        self.tools = self._create_tools()
        self.agent = self._create_agent()
    
    def _create_tools(self) -&gt; List[Tool]:
        """Create agent tools"""
        
        def search_tool(query: str) -&gt; str:
            """Search for information"""
            return f"Search results for: {query}"
        
        def calculator_tool(expression: str) -&gt; str:
            """Calculate mathematical expression"""
            try:
                return str(eval(expression))
            except:
                return "Error in calculation"
        
        tools = [
            Tool(
                name="Search",
                func=search_tool,
                description="Search for information. Input should be a search query."
            ),
            Tool(
                name="Calculator",
                func=calculator_tool,
                description="Calculate mathematical expressions. Input should be a math expression."
            )
        ]
        
        return tools
    
    def _create_agent(self):
        """Create ReAct agent"""
        
        prompt = PromptTemplate.from_template("""
Answer the following question using available tools.

Tools:
{tools}

Question: {input}

{agent_scratchpad}
""")
        
        agent = create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )
        
        agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            memory=self.memory,
            verbose=True,
            max_iterations=5
        )
        
        return agent_executor
    
    def run(self, query: str) -&gt; str:
        """Run agent"""
        result = self.agent.invoke({"input": query})
        return result["output"]

# Usage
agent = LangChainAgent()
response = agent.run("What is 25 * 17?")
print(response)
</code></pre>
<h3 id="langchain-chains"><a class="header" href="#langchain-chains">LangChain Chains</a></h3>
<pre><code class="language-python">from langchain.chains import SequentialChain, TransformChain
from langchain.chains.llm import LLMChain

class ChainedAgent:
    """Agent using LangChain chains"""
    
    def __init__(self):
        self.llm = OpenAI(temperature=0.5)
    
    def create_research_chain(self):
        """Create multi-step research chain"""
        
        # Step 1: Generate search queries
        query_prompt = PromptTemplate(
            input_variables=["topic"],
            template="Generate 3 search queries to research: {topic}\n\nQueries:"
        )
        query_chain = LLMChain(llm=self.llm, prompt=query_prompt, output_key="queries")
        
        # Step 2: Search (simplified)
        def search_transform(inputs: dict) -&gt; dict:
            queries = inputs["queries"].split('\n')
            results = [f"Results for: {q}" for q in queries if q.strip()]
            return {"search_results": "\n".join(results)}
        
        search_chain = TransformChain(
            input_variables=["queries"],
            output_variables=["search_results"],
            transform=search_transform
        )
        
        # Step 3: Synthesize
        synthesis_prompt = PromptTemplate(
            input_variables=["topic", "search_results"],
            template="""Synthesize information about {topic} from these results:

{search_results}

Summary:"""
        )
        synthesis_chain = LLMChain(llm=self.llm, prompt=synthesis_prompt, output_key="summary")
        
        # Combine into sequential chain
        overall_chain = SequentialChain(
            chains=[query_chain, search_chain, synthesis_chain],
            input_variables=["topic"],
            output_variables=["summary"],
            verbose=True
        )
        
        return overall_chain
    
    def research(self, topic: str) -&gt; str:
        """Conduct research using chain"""
        chain = self.create_research_chain()
        result = chain({"topic": topic})
        return result["summary"]

# Usage
chained_agent = ChainedAgent()
summary = chained_agent.research("AI agent architectures")
print(summary)
</code></pre>
<h3 id="langgraph-state-machines"><a class="header" href="#langgraph-state-machines">LangGraph State Machines</a></h3>
<pre><code class="language-python">from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator

class AgentState(TypedDict):
    """State for agent"""
    messages: Annotated[list, operator.add]
    current_step: str
    data: dict

class LangGraphAgent:
    """Agent using LangGraph state machine"""
    
    def __init__(self):
        self.llm = OpenAI()
        self.graph = self._build_graph()
    
    def _build_graph(self):
        """Build state machine graph"""
        
        workflow = StateGraph(AgentState)
        
        # Define nodes (states)
        workflow.add_node("start", self.start_node)
        workflow.add_node("research", self.research_node)
        workflow.add_node("analyze", self.analyze_node)
        workflow.add_node("respond", self.respond_node)
        
        # Define edges (transitions)
        workflow.set_entry_point("start")
        workflow.add_edge("start", "research")
        workflow.add_edge("research", "analyze")
        workflow.add_edge("analyze", "respond")
        workflow.add_edge("respond", END)
        
        return workflow.compile()
    
    def start_node(self, state: AgentState) -&gt; AgentState:
        """Initial state"""
        print("ğŸ“ Starting...")
        state["current_step"] = "start"
        return state
    
    def research_node(self, state: AgentState) -&gt; AgentState:
        """Research state"""
        print("ğŸ” Researching...")
        
        # Simulate research
        query = state["messages"][-1] if state["messages"] else ""
        state["data"]["research_results"] = f"Research results for: {query}"
        state["current_step"] = "research"
        
        return state
    
    def analyze_node(self, state: AgentState) -&gt; AgentState:
        """Analysis state"""
        print("ğŸ“Š Analyzing...")
        
        results = state["data"].get("research_results", "")
        state["data"]["analysis"] = f"Analysis of: {results}"
        state["current_step"] = "analyze"
        
        return state
    
    def respond_node(self, state: AgentState) -&gt; AgentState:
        """Response state"""
        print("ğŸ’¬ Responding...")
        
        analysis = state["data"].get("analysis", "")
        response = f"Based on analysis: {analysis}"
        state["messages"].append(response)
        state["current_step"] = "respond"
        
        return state
    
    def run(self, query: str) -&gt; str:
        """Run agent through state machine"""
        
        initial_state = {
            "messages": [query],
            "current_step": "init",
            "data": {}
        }
        
        final_state = self.graph.invoke(initial_state)
        
        return final_state["messages"][-1]

# Usage
langgraph_agent = LangGraphAgent()
response = langgraph_agent.run("Explain quantum computing")
print(response)
</code></pre>
<h2 id="autogpt-and-babyagi"><a class="header" href="#autogpt-and-babyagi">AutoGPT and BabyAGI</a></h2>
<h3 id="autogpt-pattern"><a class="header" href="#autogpt-pattern">AutoGPT Pattern</a></h3>
<pre><code class="language-python">class AutoGPTAgent:
    """Autonomous agent inspired by AutoGPT"""
    
    def __init__(self, objective: str):
        self.objective = objective
        self.client = openai.OpenAI()
        self.task_list = []
        self.completed_tasks = []
        self.memory = []
    
    def run(self, max_iterations: int = 10):
        """Run autonomous agent"""
        
        print(f"ğŸ¯ Objective: {self.objective}\n")
        
        # Generate initial tasks
        self.task_list = self.generate_tasks(self.objective)
        
        for iteration in range(max_iterations):
            if not self.task_list:
                print("âœ… All tasks completed!")
                break
            
            # Get next task
            current_task = self.task_list.pop(0)
            print(f"\nğŸ“‹ Task {iteration + 1}: {current_task}")
            
            # Execute task
            result = self.execute_task(current_task)
            print(f"âœ“ Result: {result[:200]}...")
            
            # Store in memory
            self.memory.append({
                "task": current_task,
                "result": result
            })
            self.completed_tasks.append(current_task)
            
            # Generate new tasks based on result
            new_tasks = self.generate_new_tasks(current_task, result)
            self.task_list.extend(new_tasks)
            
            # Prioritize tasks
            self.task_list = self.prioritize_tasks(self.task_list)
        
        return self.summarize_results()
    
    def generate_tasks(self, objective: str) -&gt; List[str]:
        """Generate initial task list"""
        
        prompt = f"""Given this objective: {objective}

Break it down into 3-5 specific, actionable tasks.
List them in order of execution.

Tasks:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        tasks_text = response.choices[0].message.content
        tasks = [t.strip('0123456789.- ').strip() for t in tasks_text.split('\n') if t.strip()]
        
        return tasks
    
    def execute_task(self, task: str) -&gt; str:
        """Execute a single task"""
        
        # Build context from memory
        context = self.build_context()
        
        prompt = f"""Objective: {self.objective}

Previous tasks completed:
{context}

Current task: {task}

Execute this task and provide the result:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        
        return response.choices[0].message.content
    
    def generate_new_tasks(self, completed_task: str, result: str) -&gt; List[str]:
        """Generate new tasks based on result"""
        
        prompt = f"""Objective: {self.objective}

Completed task: {completed_task}
Result: {result}

Based on this result, what new tasks (if any) should be added?
Only suggest tasks that help achieve the objective.

New tasks (or "none"):"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        tasks_text = response.choices[0].message.content
        
        if "none" in tasks_text.lower():
            return []
        
        tasks = [t.strip('0123456789.- ').strip() for t in tasks_text.split('\n') if t.strip()]
        return tasks
    
    def prioritize_tasks(self, tasks: List[str]) -&gt; List[str]:
        """Prioritize task list"""
        
        if not tasks:
            return []
        
        prompt = f"""Objective: {self.objective}

Tasks to prioritize:
{chr(10).join([f"{i+1}. {t}" for i, t in enumerate(tasks)])}

Reorder these tasks by priority (most important first).
Return just the task list in order.

Prioritized tasks:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        prioritized_text = response.choices[0].message.content
        prioritized = [t.strip('0123456789.- ').strip() for t in prioritized_text.split('\n') if t.strip()]
        
        return prioritized
    
    def build_context(self) -&gt; str:
        """Build context from memory"""
        if not self.memory:
            return "None"
        
        context = []
        for item in self.memory[-5:]:  # Last 5 tasks
            context.append(f"- {item['task']}: {item['result'][:100]}...")
        
        return "\n".join(context)
    
    def summarize_results(self) -&gt; str:
        """Summarize all results"""
        
        prompt = f"""Objective: {self.objective}

Completed tasks and results:
{chr(10).join([f"{i+1}. {m['task']}: {m['result']}" for i, m in enumerate(self.memory)])}

Provide a comprehensive summary of what was accomplished:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        return response.choices[0].message.content

# Usage
autogpt = AutoGPTAgent("Research and summarize the top 3 AI agent frameworks")
summary = autogpt.run(max_iterations=5)
print(f"\nğŸ“ Final Summary:\n{summary}")
</code></pre>
<h2 id="crewai-and-autogen"><a class="header" href="#crewai-and-autogen">CrewAI and AutoGen</a></h2>
<h3 id="multi-agent-collaboration"><a class="header" href="#multi-agent-collaboration">Multi-Agent Collaboration</a></h3>
<pre><code class="language-python">class Agent:
    """Individual agent in crew"""
    
    def __init__(self, role: str, goal: str, backstory: str):
        self.role = role
        self.goal = goal
        self.backstory = backstory
        self.client = openai.OpenAI()
    
    def execute_task(self, task: str, context: str = "") -&gt; str:
        """Execute task as this agent"""
        
        prompt = f"""You are a {self.role}.

Your goal: {self.goal}

Background: {self.backstory}

{f"Context: {context}" if context else ""}

Task: {task}

Response:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        
        return response.choices[0].message.content

class Crew:
    """Crew of collaborating agents"""
    
    def __init__(self):
        self.agents = []
        self.tasks = []
    
    def add_agent(self, agent: Agent):
        """Add agent to crew"""
        self.agents.append(agent)
        print(f"ğŸ‘¤ Added agent: {agent.role}")
    
    def add_task(self, description: str, agent_role: str, dependencies: List[str] = None):
        """Add task to crew"""
        self.tasks.append({
            "description": description,
            "agent_role": agent_role,
            "dependencies": dependencies or [],
            "status": "pending",
            "result": None
        })
    
    def run(self) -&gt; Dict:
        """Execute all tasks with crew"""
        
        print("\nğŸš€ Starting crew execution\n")
        
        completed = set()
        
        while len(completed) &lt; len(self.tasks):
            # Find ready tasks
            ready_tasks = [
                task for task in self.tasks
                if task["status"] == "pending" and
                all(dep in completed for dep in task["dependencies"])
            ]
            
            if not ready_tasks:
                break
            
            # Execute ready tasks
            for task in ready_tasks:
                # Find agent
                agent = next((a for a in self.agents if a.role == task["agent_role"]), None)
                
                if not agent:
                    print(f"âš ï¸  No agent found for role: {task['agent_role']}")
                    task["status"] = "failed"
                    continue
                
                # Build context from dependencies
                context = self.build_context(task["dependencies"])
                
                # Execute
                print(f"â–¶ï¸  {agent.role}: {task['description']}")
                result = agent.execute_task(task["description"], context)
                
                task["result"] = result
                task["status"] = "completed"
                completed.add(task["description"])
                
                print(f"âœ“ Completed\n")
        
        return self.generate_report()
    
    def build_context(self, dependencies: List[str]) -&gt; str:
        """Build context from completed dependencies"""
        context_parts = []
        
        for dep in dependencies:
            dep_task = next((t for t in self.tasks if t["description"] == dep), None)
            if dep_task and dep_task["result"]:
                context_parts.append(f"{dep}: {dep_task['result'][:200]}...")
        
        return "\n\n".join(context_parts)
    
    def generate_report(self) -&gt; Dict:
        """Generate execution report"""
        completed = sum(1 for t in self.tasks if t["status"] == "completed")
        
        return {
            "total_tasks": len(self.tasks),
            "completed": completed,
            "failed": len(self.tasks) - completed,
            "tasks": self.tasks
        }

# Usage
crew = Crew()

# Add agents
researcher = Agent(
    role="Researcher",
    goal="Find and analyze information",
    backstory="Expert researcher with deep analytical skills"
)

writer = Agent(
    role="Writer",
    goal="Create clear, engaging content",
    backstory="Professional writer skilled at explaining complex topics"
)

reviewer = Agent(
    role="Reviewer",
    goal="Ensure quality and accuracy",
    backstory="Detail-oriented reviewer with high standards"
)

crew.add_agent(researcher)
crew.add_agent(writer)
crew.add_agent(reviewer)

# Add tasks
crew.add_task(
    "Research the top 3 AI agent frameworks",
    "Researcher"
)

crew.add_task(
    "Write a comparison article based on the research",
    "Writer",
    dependencies=["Research the top 3 AI agent frameworks"]
)

crew.add_task(
    "Review the article for accuracy and clarity",
    "Reviewer",
    dependencies=["Write a comparison article based on the research"]
)

# Execute
report = crew.run()
print(f"\nğŸ“Š Report: {report['completed']}/{report['total_tasks']} tasks completed")
</code></pre>
<h2 id="custom-framework-design"><a class="header" href="#custom-framework-design">Custom Framework Design</a></h2>
<h3 id="building-your-own-framework"><a class="header" href="#building-your-own-framework">Building Your Own Framework</a></h3>
<pre><code class="language-python">class CustomAgentFramework:
    """Custom agent framework"""
    
    def __init__(self):
        self.agents = {}
        self.tools = {}
        self.memory = {}
        self.middleware = []
    
    def register_agent(self, name: str, agent_class):
        """Register agent type"""
        self.agents[name] = agent_class
        print(f"âœ… Registered agent: {name}")
    
    def register_tool(self, name: str, tool_func):
        """Register tool"""
        self.tools[name] = tool_func
        print(f"ğŸ”§ Registered tool: {name}")
    
    def add_middleware(self, middleware_func):
        """Add middleware for request processing"""
        self.middleware.append(middleware_func)
    
    def create_agent(self, agent_type: str, **kwargs):
        """Create agent instance"""
        if agent_type not in self.agents:
            raise ValueError(f"Unknown agent type: {agent_type}")
        
        agent_class = self.agents[agent_type]
        agent = agent_class(framework=self, **kwargs)
        
        return agent
    
    def execute_tool(self, tool_name: str, **params):
        """Execute tool"""
        if tool_name not in self.tools:
            raise ValueError(f"Unknown tool: {tool_name}")
        
        return self.tools[tool_name](**params)
    
    def process_request(self, agent, request: str) -&gt; str:
        """Process request through middleware"""
        
        # Apply middleware
        for middleware in self.middleware:
            request = middleware(request)
        
        # Execute agent
        response = agent.process(request)
        
        return response

# Usage
framework = CustomAgentFramework()

# Register components
framework.register_tool("search", lambda query: f"Results for: {query}")
framework.register_tool("calculate", lambda expr: str(eval(expr)))

# Add middleware
def logging_middleware(request):
    print(f"ğŸ“ Request: {request}")
    return request

framework.add_middleware(logging_middleware)

# Create and use agent
# agent = framework.create_agent("research_agent")
# response = framework.process_request(agent, "Find information about AI")
</code></pre>
<h2 id="best-practices-13"><a class="header" href="#best-practices-13">Best Practices</a></h2>
<ol>
<li><strong>Choose right framework</strong>: Match to your needs</li>
<li><strong>Start simple</strong>: Donâ€™t over-engineer</li>
<li><strong>Understand abstractions</strong>: Know what framework does</li>
<li><strong>Customize carefully</strong>: Extend, donâ€™t fight framework</li>
<li><strong>Keep updated</strong>: Follow framework updates</li>
<li><strong>Test thoroughly</strong>: Framework bugs affect you</li>
<li><strong>Monitor performance</strong>: Track overhead</li>
<li><strong>Document usage</strong>: Help team understand</li>
<li><strong>Plan migration</strong>: Have exit strategy</li>
<li><strong>Contribute back</strong>: Share improvements</li>
</ol>
<h2 id="next-steps-17"><a class="header" href="#next-steps-17">Next Steps</a></h2>
<p>Chapter 7 (Advanced Topics) is complete! You now have deep knowledge of agent learning, multimodal capabilities, and frameworks. This prepares you for enterprise-scale deployments in Module 8.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="architecture-patterns"><a class="header" href="#architecture-patterns">Architecture Patterns</a></h1>
<h2 id="module-8-learning-objectives"><a class="header" href="#module-8-learning-objectives">Module 8: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Design microservices and event-driven architectures</li>
<li>âœ“ Implement enterprise security and compliance</li>
<li>âœ“ Optimize costs through caching and model selection</li>
<li>âœ“ Scale agents to handle production workloads</li>
<li>âœ“ Deploy on Kubernetes and serverless platforms</li>
</ul>
<hr>
<h2 id="introduction-to-enterprise-architecture"><a class="header" href="#introduction-to-enterprise-architecture">Introduction to Enterprise Architecture</a></h2>
<p>Enterprise-scale agent systems require robust, scalable, and maintainable architectures. This section covers proven patterns for production deployments.</p>
<h3 id="key-requirements"><a class="header" href="#key-requirements">Key Requirements</a></h3>
<p><strong>Scalability</strong>:</p>
<ul>
<li>Handle increasing load</li>
<li>Horizontal scaling</li>
<li>Resource efficiency</li>
<li>Performance optimization</li>
</ul>
<p><strong>Reliability</strong>:</p>
<ul>
<li>High availability (99.9%+)</li>
<li>Fault tolerance</li>
<li>Graceful degradation</li>
<li>Disaster recovery</li>
</ul>
<p><strong>Maintainability</strong>:</p>
<ul>
<li>Clear separation of concerns</li>
<li>Easy updates and rollbacks</li>
<li>Monitoring and debugging</li>
<li>Documentation</li>
</ul>
<p><strong>Security</strong>:</p>
<ul>
<li>Authentication and authorization</li>
<li>Data encryption</li>
<li>Audit logging</li>
<li>Compliance</li>
</ul>
<h2 id="microservices-for-agents"><a class="header" href="#microservices-for-agents">Microservices for Agents</a></h2>
<h3 id="agent-microservices-architecture"><a class="header" href="#agent-microservices-architecture">Agent Microservices Architecture</a></h3>
<pre><code class="language-python">from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel
from typing import Optional, Dict, Any
import uvicorn

# Agent Service
class AgentService:
    """Core agent microservice"""
    
    def __init__(self):
        self.app = FastAPI(title="Agent Service")
        self.setup_routes()
    
    def setup_routes(self):
        """Setup API routes"""
        
        @self.app.post("/agent/process")
        async def process_request(request: AgentRequest):
            """Process agent request"""
            try:
                result = await self.process(request)
                return {"success": True, "result": result}
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/agent/health")
        async def health_check():
            """Health check endpoint"""
            return {"status": "healthy", "service": "agent"}
    
    async def process(self, request: AgentRequest) -&gt; Dict:
        """Process agent request"""
        # Agent logic here
        return {"response": "Processed"}
    
    def run(self, host: str = "0.0.0.0", port: int = 8000):
        """Run service"""
        uvicorn.run(self.app, host=host, port=port)

class AgentRequest(BaseModel):
    """Agent request model"""
    user_id: str
    input: str
    context: Optional[Dict[str, Any]] = None

# Tool Service
class ToolService:
    """Tool execution microservice"""
    
    def __init__(self):
        self.app = FastAPI(title="Tool Service")
        self.tools = {}
        self.setup_routes()
    
    def setup_routes(self):
        """Setup API routes"""
        
        @self.app.post("/tools/execute")
        async def execute_tool(request: ToolRequest):
            """Execute tool"""
            try:
                result = await self.execute(request)
                return {"success": True, "result": result}
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/tools/list")
        async def list_tools():
            """List available tools"""
            return {"tools": list(self.tools.keys())}
    
    async def execute(self, request: ToolRequest) -&gt; Any:
        """Execute tool"""
        if request.tool_name not in self.tools:
            raise ValueError(f"Unknown tool: {request.tool_name}")
        
        tool = self.tools[request.tool_name]
        return tool(**request.parameters)
    
    def register_tool(self, name: str, func):
        """Register tool"""
        self.tools[name] = func

class ToolRequest(BaseModel):
    """Tool request model"""
    tool_name: str
    parameters: Dict[str, Any]

# Memory Service
class MemoryService:
    """Memory management microservice"""
    
    def __init__(self):
        self.app = FastAPI(title="Memory Service")
        self.storage = {}
        self.setup_routes()
    
    def setup_routes(self):
        """Setup API routes"""
        
        @self.app.post("/memory/store")
        async def store_memory(request: MemoryRequest):
            """Store memory"""
            self.storage[request.key] = request.value
            return {"success": True}
        
        @self.app.get("/memory/retrieve/{key}")
        async def retrieve_memory(key: str):
            """Retrieve memory"""
            value = self.storage.get(key)
            if value is None:
                raise HTTPException(status_code=404, detail="Memory not found")
            return {"key": key, "value": value}
        
        @self.app.delete("/memory/delete/{key}")
        async def delete_memory(key: str):
            """Delete memory"""
            if key in self.storage:
                del self.storage[key]
            return {"success": True}

class MemoryRequest(BaseModel):
    """Memory request model"""
    key: str
    value: Any

# API Gateway
class APIGateway:
    """API Gateway for routing requests"""
    
    def __init__(self):
        self.app = FastAPI(title="API Gateway")
        self.services = {
            "agent": "http://localhost:8000",
            "tools": "http://localhost:8001",
            "memory": "http://localhost:8002"
        }
        self.setup_routes()
    
    def setup_routes(self):
        """Setup gateway routes"""
        
        @self.app.post("/api/chat")
        async def chat(request: ChatRequest):
            """Chat endpoint"""
            import httpx
            
            # Route to agent service
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.services['agent']}/agent/process",
                    json=request.dict()
                )
                return response.json()
        
        @self.app.get("/api/health")
        async def health():
            """Check health of all services"""
            import httpx
            
            health_status = {}
            async with httpx.AsyncClient() as client:
                for service, url in self.services.items():
                    try:
                        response = await client.get(f"{url}/health", timeout=5)
                        health_status[service] = "healthy"
                    except:
                        health_status[service] = "unhealthy"
            
            return {"services": health_status}

class ChatRequest(BaseModel):
    """Chat request model"""
    user_id: str
    message: str

# Usage
if __name__ == "__main__":
    # Start services on different ports
    agent_service = AgentService()
    # agent_service.run(port=8000)
    
    tool_service = ToolService()
    # tool_service.run(port=8001)
    
    memory_service = MemoryService()
    # memory_service.run(port=8002)
    
    gateway = APIGateway()
    # gateway.app.run(port=8080)
</code></pre>
<h3 id="service-communication"><a class="header" href="#service-communication">Service Communication</a></h3>
<pre><code class="language-python">import httpx
from typing import Optional
import asyncio

class ServiceClient:
    """Client for inter-service communication"""
    
    def __init__(self, base_url: str, timeout: int = 30):
        self.base_url = base_url
        self.timeout = timeout
        self.client = httpx.AsyncClient(timeout=timeout)
    
    async def call_service(self, 
                          endpoint: str,
                          method: str = "POST",
                          data: Optional[Dict] = None) -&gt; Dict:
        """Call another service"""
        
        url = f"{self.base_url}{endpoint}"
        
        try:
            if method == "POST":
                response = await self.client.post(url, json=data)
            elif method == "GET":
                response = await self.client.get(url)
            else:
                raise ValueError(f"Unsupported method: {method}")
            
            response.raise_for_status()
            return response.json()
            
        except httpx.HTTPError as e:
            return {"error": str(e)}
    
    async def close(self):
        """Close client"""
        await self.client.aclose()

# Circuit Breaker for service calls
class CircuitBreaker:
    """Circuit breaker for service resilience"""
    
    def __init__(self, failure_threshold: int = 5, timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failures = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open
    
    async def call(self, func, *args, **kwargs):
        """Call function with circuit breaker"""
        
        if self.state == "open":
            if time.time() - self.last_failure_time &gt; self.timeout:
                self.state = "half-open"
            else:
                raise Exception("Circuit breaker is OPEN")
        
        try:
            result = await func(*args, **kwargs)
            
            if self.state == "half-open":
                self.state = "closed"
                self.failures = 0
            
            return result
            
        except Exception as e:
            self.failures += 1
            self.last_failure_time = time.time()
            
            if self.failures &gt;= self.failure_threshold:
                self.state = "open"
            
            raise e

# Service Registry
class ServiceRegistry:
    """Service discovery and registration"""
    
    def __init__(self):
        self.services = {}
    
    def register(self, service_name: str, url: str, metadata: Dict = None):
        """Register service"""
        self.services[service_name] = {
            "url": url,
            "metadata": metadata or {},
            "registered_at": time.time()
        }
        print(f"âœ… Registered service: {service_name} at {url}")
    
    def discover(self, service_name: str) -&gt; Optional[str]:
        """Discover service URL"""
        service = self.services.get(service_name)
        return service["url"] if service else None
    
    def list_services(self) -&gt; Dict:
        """List all services"""
        return self.services

# Usage
registry = ServiceRegistry()
registry.register("agent-service", "http://localhost:8000")
registry.register("tool-service", "http://localhost:8001")

# Get service URL
agent_url = registry.discover("agent-service")
</code></pre>
<h2 id="event-driven-architectures"><a class="header" href="#event-driven-architectures">Event-Driven Architectures</a></h2>
<h3 id="message-queue-integration"><a class="header" href="#message-queue-integration">Message Queue Integration</a></h3>
<pre><code class="language-python">import json
from typing import Callable, Dict
import asyncio
from queue import Queue
import threading

class MessageBroker:
    """Simple message broker"""
    
    def __init__(self):
        self.queues = {}
        self.subscribers = {}
    
    def create_queue(self, queue_name: str):
        """Create message queue"""
        if queue_name not in self.queues:
            self.queues[queue_name] = Queue()
            self.subscribers[queue_name] = []
    
    def publish(self, queue_name: str, message: Dict):
        """Publish message to queue"""
        if queue_name not in self.queues:
            self.create_queue(queue_name)
        
        self.queues[queue_name].put(message)
        print(f"ğŸ“¤ Published to {queue_name}: {message}")
    
    def subscribe(self, queue_name: str, handler: Callable):
        """Subscribe to queue"""
        if queue_name not in self.queues:
            self.create_queue(queue_name)
        
        self.subscribers[queue_name].append(handler)
        print(f"ğŸ“¥ Subscribed to {queue_name}")
    
    def start_consumer(self, queue_name: str):
        """Start consuming messages"""
        
        def consume():
            while True:
                try:
                    message = self.queues[queue_name].get(timeout=1)
                    
                    # Call all subscribers
                    for handler in self.subscribers[queue_name]:
                        try:
                            handler(message)
                        except Exception as e:
                            print(f"âŒ Handler error: {e}")
                    
                except:
                    continue
        
        thread = threading.Thread(target=consume, daemon=True)
        thread.start()

# Event-Driven Agent
class EventDrivenAgent:
    """Agent using event-driven architecture"""
    
    def __init__(self, broker: MessageBroker):
        self.broker = broker
        self.setup_subscriptions()
    
    def setup_subscriptions(self):
        """Setup event subscriptions"""
        self.broker.subscribe("user_request", self.handle_user_request)
        self.broker.subscribe("tool_result", self.handle_tool_result)
    
    def handle_user_request(self, message: Dict):
        """Handle user request event"""
        print(f"ğŸ¤– Processing request: {message}")
        
        # Process and publish result
        result = {"response": f"Processed: {message.get('input')}"}
        self.broker.publish("agent_response", result)
    
    def handle_tool_result(self, message: Dict):
        """Handle tool result event"""
        print(f"ğŸ”§ Tool result: {message}")

# Usage
broker = MessageBroker()
agent = EventDrivenAgent(broker)

# Start consumers
broker.start_consumer("user_request")
broker.start_consumer("tool_result")

# Publish event
broker.publish("user_request", {"user_id": "123", "input": "Hello"})
</code></pre>
<h3 id="kafka-integration"><a class="header" href="#kafka-integration">Kafka Integration</a></h3>
<pre><code class="language-python">from kafka import KafkaProducer, KafkaConsumer
import json

class KafkaAgentSystem:
    """Agent system using Kafka"""
    
    def __init__(self, bootstrap_servers: str = "localhost:9092"):
        self.bootstrap_servers = bootstrap_servers
        self.producer = KafkaProducer(
            bootstrap_servers=bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
    
    def publish_event(self, topic: str, event: Dict):
        """Publish event to Kafka"""
        self.producer.send(topic, event)
        self.producer.flush()
        print(f"ğŸ“¤ Published to {topic}")
    
    def create_consumer(self, topic: str, group_id: str):
        """Create Kafka consumer"""
        consumer = KafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            group_id=group_id,
            value_deserializer=lambda m: json.loads(m.decode('utf-8'))
        )
        return consumer
    
    def consume_events(self, topic: str, group_id: str, handler: Callable):
        """Consume events from Kafka"""
        consumer = self.create_consumer(topic, group_id)
        
        for message in consumer:
            try:
                handler(message.value)
            except Exception as e:
                print(f"âŒ Error processing message: {e}")

# Usage
# kafka_system = KafkaAgentSystem()
# kafka_system.publish_event("agent-requests", {"user_id": "123", "input": "Hello"})
</code></pre>
<h2 id="serverless-deployments"><a class="header" href="#serverless-deployments">Serverless Deployments</a></h2>
<h3 id="aws-lambda-agent"><a class="header" href="#aws-lambda-agent">AWS Lambda Agent</a></h3>
<pre><code class="language-python">import json
import boto3
from typing import Dict, Any

class LambdaAgent:
    """Agent deployed as AWS Lambda"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.dynamodb = boto3.resource('dynamodb')
        self.table = self.dynamodb.Table('agent-memory')
    
    def handler(self, event: Dict, context: Any) -&gt; Dict:
        """Lambda handler function"""
        
        try:
            # Parse request
            body = json.loads(event.get('body', '{}'))
            user_id = body.get('user_id')
            input_text = body.get('input')
            
            # Get user memory
            memory = self.get_memory(user_id)
            
            # Process request
            response = self.process(input_text, memory)
            
            # Update memory
            self.update_memory(user_id, response)
            
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'response': response
                })
            }
            
        except Exception as e:
            return {
                'statusCode': 500,
                'body': json.dumps({
                    'error': str(e)
                })
            }
    
    def process(self, input_text: str, memory: Dict) -&gt; str:
        """Process request"""
        # Build context from memory
        context = memory.get('context', '')
        
        messages = [
            {"role": "system", "content": f"Context: {context}"},
            {"role": "user", "content": input_text}
        ]
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=messages
        )
        
        return response.choices[0].message.content
    
    def get_memory(self, user_id: str) -&gt; Dict:
        """Get user memory from DynamoDB"""
        try:
            response = self.table.get_item(Key={'user_id': user_id})
            return response.get('Item', {})
        except:
            return {}
    
    def update_memory(self, user_id: str, response: str):
        """Update user memory"""
        try:
            self.table.put_item(
                Item={
                    'user_id': user_id,
                    'context': response,
                    'updated_at': int(time.time())
                }
            )
        except Exception as e:
            print(f"Error updating memory: {e}")

# Lambda function
def lambda_handler(event, context):
    """AWS Lambda entry point"""
    agent = LambdaAgent()
    return agent.handler(event, context)
</code></pre>
<h3 id="serverless-framework-configuration"><a class="header" href="#serverless-framework-configuration">Serverless Framework Configuration</a></h3>
<pre><code class="language-yaml"># serverless.yml
service: agent-service

provider:
  name: aws
  runtime: python3.11
  region: us-east-1
  environment:
    OPENAI_API_KEY: ${env:OPENAI_API_KEY}
  iamRoleStatements:
    - Effect: Allow
      Action:
        - dynamodb:GetItem
        - dynamodb:PutItem
      Resource: "arn:aws:dynamodb:*:*:table/agent-memory"

functions:
  agent:
    handler: handler.lambda_handler
    events:
      - http:
          path: agent/process
          method: post
          cors: true
    timeout: 30
    memorySize: 512

resources:
  Resources:
    AgentMemoryTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: agent-memory
        AttributeDefinitions:
          - AttributeName: user_id
            AttributeType: S
        KeySchema:
          - AttributeName: user_id
            KeyType: HASH
        BillingMode: PAY_PER_REQUEST
</code></pre>
<h2 id="scaling-strategies"><a class="header" href="#scaling-strategies">Scaling Strategies</a></h2>
<h3 id="horizontal-scaling"><a class="header" href="#horizontal-scaling">Horizontal Scaling</a></h3>
<pre><code class="language-python">from multiprocessing import Pool, cpu_count
import concurrent.futures

class ScalableAgentPool:
    """Pool of agent workers for horizontal scaling"""
    
    def __init__(self, num_workers: int = None):
        self.num_workers = num_workers or cpu_count()
        self.pool = Pool(processes=self.num_workers)
        print(f"ğŸ”§ Created pool with {self.num_workers} workers")
    
    def process_batch(self, requests: List[Dict]) -&gt; List[Dict]:
        """Process batch of requests in parallel"""
        results = self.pool.map(self.process_single, requests)
        return results
    
    def process_single(self, request: Dict) -&gt; Dict:
        """Process single request"""
        # Agent processing logic
        return {"response": f"Processed: {request.get('input')}"}
    
    def close(self):
        """Close pool"""
        self.pool.close()
        self.pool.join()

# Async scaling
class AsyncAgentPool:
    """Async agent pool"""
    
    def __init__(self, max_workers: int = 10):
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)
    
    async def process_batch(self, requests: List[Dict]) -&gt; List[Dict]:
        """Process batch asynchronously"""
        loop = asyncio.get_event_loop()
        
        tasks = [
            loop.run_in_executor(self.executor, self.process_single, req)
            for req in requests
        ]
        
        results = await asyncio.gather(*tasks)
        return results
    
    def process_single(self, request: Dict) -&gt; Dict:
        """Process single request"""
        return {"response": f"Processed: {request.get('input')}"}

# Usage
pool = ScalableAgentPool(num_workers=4)

requests = [
    {"input": f"Request {i}"} for i in range(100)
]

results = pool.process_batch(requests)
print(f"Processed {len(results)} requests")

pool.close()
</code></pre>
<h3 id="load-balancing"><a class="header" href="#load-balancing">Load Balancing</a></h3>
<pre><code class="language-python">from typing import List
import random

class LoadBalancer:
    """Load balancer for agent instances"""
    
    def __init__(self, strategy: str = "round_robin"):
        self.strategy = strategy
        self.instances = []
        self.current_index = 0
        self.instance_loads = {}
    
    def register_instance(self, instance_url: str):
        """Register agent instance"""
        self.instances.append(instance_url)
        self.instance_loads[instance_url] = 0
        print(f"âœ… Registered instance: {instance_url}")
    
    def get_instance(self) -&gt; str:
        """Get instance based on strategy"""
        
        if self.strategy == "round_robin":
            return self.round_robin()
        elif self.strategy == "least_connections":
            return self.least_connections()
        elif self.strategy == "random":
            return self.random_selection()
        else:
            return self.round_robin()
    
    def round_robin(self) -&gt; str:
        """Round-robin selection"""
        if not self.instances:
            raise Exception("No instances available")
        
        instance = self.instances[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.instances)
        return instance
    
    def least_connections(self) -&gt; str:
        """Select instance with least connections"""
        if not self.instances:
            raise Exception("No instances available")
        
        return min(self.instance_loads, key=self.instance_loads.get)
    
    def random_selection(self) -&gt; str:
        """Random selection"""
        if not self.instances:
            raise Exception("No instances available")
        
        return random.choice(self.instances)
    
    def record_request(self, instance_url: str):
        """Record request to instance"""
        self.instance_loads[instance_url] += 1
    
    def record_completion(self, instance_url: str):
        """Record request completion"""
        self.instance_loads[instance_url] -= 1

# Usage
lb = LoadBalancer(strategy="least_connections")
lb.register_instance("http://agent1:8000")
lb.register_instance("http://agent2:8000")
lb.register_instance("http://agent3:8000")

# Route request
instance = lb.get_instance()
print(f"Routing to: {instance}")
</code></pre>
<h2 id="container-orchestration"><a class="header" href="#container-orchestration">Container Orchestration</a></h2>
<h3 id="docker-compose-setup"><a class="header" href="#docker-compose-setup">Docker Compose Setup</a></h3>
<pre><code class="language-yaml"># docker-compose.yml
version: '3.8'

services:
  agent-service:
    build: ./agent-service
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
      - postgres
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 1G
  
  tool-service:
    build: ./tool-service
    ports:
      - "8001:8001"
    environment:
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
  
  memory-service:
    build: ./memory-service
    ports:
      - "8002:8002"
    environment:
      - POSTGRES_URL=postgresql://user:pass@postgres:5432/agentdb
    depends_on:
      - postgres
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
  
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=agentdb
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
  
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - agent-service

volumes:
  redis-data:
  postgres-data:
</code></pre>
<h3 id="kubernetes-deployment"><a class="header" href="#kubernetes-deployment">Kubernetes Deployment</a></h3>
<pre><code class="language-yaml"># kubernetes/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agent-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: agent-service
  template:
    metadata:
      labels:
        app: agent-service
    spec:
      containers:
      - name: agent
        image: agent-service:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: agent-secrets
              key: openai-api-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: agent-service
spec:
  selector:
    app: agent-service
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: agent-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: agent-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
</code></pre>
<h2 id="best-practices-14"><a class="header" href="#best-practices-14">Best Practices</a></h2>
<ol>
<li><strong>Decouple services</strong>: Loose coupling, high cohesion</li>
<li><strong>Stateless design</strong>: Store state externally</li>
<li><strong>Idempotent operations</strong>: Safe to retry</li>
<li><strong>Circuit breakers</strong>: Prevent cascading failures</li>
<li><strong>Health checks</strong>: Monitor service health</li>
<li><strong>Graceful shutdown</strong>: Clean resource cleanup</li>
<li><strong>Configuration management</strong>: Externalize config</li>
<li><strong>Service discovery</strong>: Dynamic service location</li>
<li><strong>API versioning</strong>: Backward compatibility</li>
<li><strong>Documentation</strong>: Clear API contracts</li>
</ol>
<h2 id="next-steps-18"><a class="header" href="#next-steps-18">Next Steps</a></h2>
<p>You now understand enterprise architecture patterns! Next, weâ€™ll explore security and compliance for production agent systems.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="security--compliance"><a class="header" href="#security--compliance">Security &amp; Compliance</a></h1>
<h2 id="introduction-to-agent-security"><a class="header" href="#introduction-to-agent-security">Introduction to Agent Security</a></h2>
<p>Security is critical for production agent systems. This section covers authentication, authorization, data protection, and compliance requirements.</p>
<h3 id="security-principles"><a class="header" href="#security-principles">Security Principles</a></h3>
<p><strong>Defense in Depth</strong>: Multiple layers of security
<strong>Least Privilege</strong>: Minimum necessary access
<strong>Zero Trust</strong>: Verify everything
<strong>Encryption</strong>: Protect data at rest and in transit
<strong>Audit Everything</strong>: Complete logging</p>
<h3 id="threat-model"><a class="header" href="#threat-model">Threat Model</a></h3>
<p><strong>Threats</strong>:</p>
<ul>
<li>Unauthorized access</li>
<li>Data breaches</li>
<li>Prompt injection</li>
<li>Model manipulation</li>
<li>Resource exhaustion</li>
<li>Privacy violations</li>
</ul>
<h2 id="authentication-and-authorization"><a class="header" href="#authentication-and-authorization">Authentication and Authorization</a></h2>
<h3 id="jwt-based-authentication"><a class="header" href="#jwt-based-authentication">JWT-Based Authentication</a></h3>
<pre><code class="language-python">import jwt
from datetime import datetime, timedelta
from fastapi import HTTPException, Security, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional, Dict

class AuthManager:
    """JWT-based authentication"""
    
    def __init__(self, secret_key: str, algorithm: str = "HS256"):
        self.secret_key = secret_key
        self.algorithm = algorithm
        self.security = HTTPBearer()
    
    def create_token(self, 
                    user_id: str,
                    roles: List[str],
                    expires_in: int = 3600) -&gt; str:
        """Create JWT token"""
        
        payload = {
            "user_id": user_id,
            "roles": roles,
            "exp": datetime.utcnow() + timedelta(seconds=expires_in),
            "iat": datetime.utcnow()
        }
        
        token = jwt.encode(payload, self.secret_key, algorithm=self.algorithm)
        return token
    
    def verify_token(self, token: str) -&gt; Dict:
        """Verify and decode JWT token"""
        
        try:
            payload = jwt.decode(
                token,
                self.secret_key,
                algorithms=[self.algorithm]
            )
            return payload
        except jwt.ExpiredSignatureError:
            raise HTTPException(status_code=401, detail="Token expired")
        except jwt.InvalidTokenError:
            raise HTTPException(status_code=401, detail="Invalid token")
    
    async def get_current_user(self,
                              credentials: HTTPAuthorizationCredentials = Security(HTTPBearer())):
        """Get current user from token"""
        
        token = credentials.credentials
        payload = self.verify_token(token)
        
        return {
            "user_id": payload["user_id"],
            "roles": payload["roles"]
        }

# Role-Based Access Control
class RBACManager:
    """Role-based access control"""
    
    def __init__(self):
        self.permissions = {
            "admin": ["read", "write", "delete", "admin"],
            "user": ["read", "write"],
            "viewer": ["read"]
        }
    
    def has_permission(self, roles: List[str], required_permission: str) -&gt; bool:
        """Check if roles have required permission"""
        
        for role in roles:
            if role in self.permissions:
                if required_permission in self.permissions[role]:
                    return True
        
        return False
    
    def require_permission(self, permission: str):
        """Decorator to require permission"""
        
        def decorator(func):
            async def wrapper(*args, **kwargs):
                # Get user from context
                user = kwargs.get('current_user')
                
                if not user:
                    raise HTTPException(status_code=401, detail="Not authenticated")
                
                if not self.has_permission(user['roles'], permission):
                    raise HTTPException(status_code=403, detail="Insufficient permissions")
                
                return await func(*args, **kwargs)
            
            return wrapper
        return decorator

# Secure Agent API
class SecureAgentAPI:
    """Agent API with authentication"""
    
    def __init__(self):
        self.app = FastAPI()
        self.auth = AuthManager(secret_key="your-secret-key")
        self.rbac = RBACManager()
        self.setup_routes()
    
    def setup_routes(self):
        """Setup secure routes"""
        
        @self.app.post("/auth/login")
        async def login(credentials: LoginRequest):
            """Login and get token"""
            # Verify credentials (simplified)
            if self.verify_credentials(credentials.username, credentials.password):
                token = self.auth.create_token(
                    user_id=credentials.username,
                    roles=["user"]
                )
                return {"token": token}
            else:
                raise HTTPException(status_code=401, detail="Invalid credentials")
        
        @self.app.post("/agent/process")
        async def process(
            request: AgentRequest,
            current_user: Dict = Depends(self.auth.get_current_user)
        ):
            """Process request (requires authentication)"""
            
            # Check permission
            if not self.rbac.has_permission(current_user['roles'], 'write'):
                raise HTTPException(status_code=403, detail="Insufficient permissions")
            
            # Process request
            result = await self.process_request(request, current_user)
            return {"result": result}
    
    def verify_credentials(self, username: str, password: str) -&gt; bool:
        """Verify user credentials"""
        # In production, check against database with hashed passwords
        return True

class LoginRequest(BaseModel):
    username: str
    password: str

# Usage
api = SecureAgentAPI()
</code></pre>
<h3 id="api-key-management"><a class="header" href="#api-key-management">API Key Management</a></h3>
<pre><code class="language-python">import secrets
import hashlib
from datetime import datetime

class APIKeyManager:
    """Manage API keys"""
    
    def __init__(self):
        self.keys = {}  # In production, use database
    
    def generate_key(self, user_id: str, name: str) -&gt; str:
        """Generate new API key"""
        
        # Generate secure random key
        key = f"sk_{secrets.token_urlsafe(32)}"
        
        # Hash for storage
        key_hash = hashlib.sha256(key.encode()).hexdigest()
        
        # Store
        self.keys[key_hash] = {
            "user_id": user_id,
            "name": name,
            "created_at": datetime.utcnow(),
            "last_used": None,
            "usage_count": 0
        }
        
        return key
    
    def verify_key(self, key: str) -&gt; Optional[Dict]:
        """Verify API key"""
        
        key_hash = hashlib.sha256(key.encode()).hexdigest()
        
        if key_hash in self.keys:
            # Update usage
            self.keys[key_hash]["last_used"] = datetime.utcnow()
            self.keys[key_hash]["usage_count"] += 1
            
            return self.keys[key_hash]
        
        return None
    
    def revoke_key(self, key: str):
        """Revoke API key"""
        
        key_hash = hashlib.sha256(key.encode()).hexdigest()
        
        if key_hash in self.keys:
            del self.keys[key_hash]
            return True
        
        return False

# API Key Authentication
from fastapi.security import APIKeyHeader

class APIKeyAuth:
    """API Key authentication"""
    
    def __init__(self, key_manager: APIKeyManager):
        self.key_manager = key_manager
        self.api_key_header = APIKeyHeader(name="X-API-Key")
    
    async def verify(self, api_key: str = Security(APIKeyHeader(name="X-API-Key"))):
        """Verify API key"""
        
        key_data = self.key_manager.verify_key(api_key)
        
        if not key_data:
            raise HTTPException(status_code=401, detail="Invalid API key")
        
        return key_data

# Usage
key_manager = APIKeyManager()
api_key = key_manager.generate_key("user123", "Production Key")
print(f"API Key: {api_key}")
</code></pre>
<h2 id="data-encryption"><a class="header" href="#data-encryption">Data Encryption</a></h2>
<h3 id="encryption-at-rest"><a class="header" href="#encryption-at-rest">Encryption at Rest</a></h3>
<pre><code class="language-python">from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2
import base64

class DataEncryption:
    """Encrypt sensitive data"""
    
    def __init__(self, password: str):
        self.key = self.derive_key(password)
        self.cipher = Fernet(self.key)
    
    def derive_key(self, password: str) -&gt; bytes:
        """Derive encryption key from password"""
        
        kdf = PBKDF2(
            algorithm=hashes.SHA256(),
            length=32,
            salt=b'static_salt',  # In production, use random salt
            iterations=100000,
        )
        
        key = base64.urlsafe_b64encode(kdf.derive(password.encode()))
        return key
    
    def encrypt(self, data: str) -&gt; str:
        """Encrypt data"""
        
        encrypted = self.cipher.encrypt(data.encode())
        return base64.urlsafe_b64encode(encrypted).decode()
    
    def decrypt(self, encrypted_data: str) -&gt; str:
        """Decrypt data"""
        
        encrypted = base64.urlsafe_b64decode(encrypted_data.encode())
        decrypted = self.cipher.decrypt(encrypted)
        return decrypted.decode()

# Encrypted Storage
class EncryptedStorage:
    """Store data with encryption"""
    
    def __init__(self, encryption_key: str):
        self.encryption = DataEncryption(encryption_key)
        self.storage = {}
    
    def store(self, key: str, value: str):
        """Store encrypted data"""
        
        encrypted_value = self.encryption.encrypt(value)
        self.storage[key] = encrypted_value
    
    def retrieve(self, key: str) -&gt; Optional[str]:
        """Retrieve and decrypt data"""
        
        encrypted_value = self.storage.get(key)
        
        if encrypted_value:
            return self.encryption.decrypt(encrypted_value)
        
        return None

# Usage
storage = EncryptedStorage("my-secret-password")
storage.store("api_key", "sk_1234567890")
retrieved = storage.retrieve("api_key")
print(f"Retrieved: {retrieved}")
</code></pre>
<h3 id="encryption-in-transit-tlsssl"><a class="header" href="#encryption-in-transit-tlsssl">Encryption in Transit (TLS/SSL)</a></h3>
<pre><code class="language-python">import ssl
from fastapi import FastAPI
import uvicorn

class SecureServer:
    """HTTPS server with TLS"""
    
    def __init__(self):
        self.app = FastAPI()
        self.setup_routes()
    
    def setup_routes(self):
        """Setup routes"""
        
        @self.app.get("/")
        async def root():
            return {"message": "Secure server"}
    
    def run(self, 
            host: str = "0.0.0.0",
            port: int = 443,
            cert_file: str = "cert.pem",
            key_file: str = "key.pem"):
        """Run with TLS"""
        
        uvicorn.run(
            self.app,
            host=host,
            port=port,
            ssl_keyfile=key_file,
            ssl_certfile=cert_file,
            ssl_version=ssl.PROTOCOL_TLS,
            ssl_cert_reqs=ssl.CERT_REQUIRED
        )

# Generate self-signed certificate (for development only)
def generate_self_signed_cert():
    """Generate self-signed certificate"""
    from cryptography import x509
    from cryptography.x509.oid import NameOID
    from cryptography.hazmat.primitives import hashes
    from cryptography.hazmat.primitives.asymmetric import rsa
    
    # Generate private key
    private_key = rsa.generate_private_key(
        public_exponent=65537,
        key_size=2048
    )
    
    # Generate certificate
    subject = issuer = x509.Name([
        x509.NameAttribute(NameOID.COUNTRY_NAME, "US"),
        x509.NameAttribute(NameOID.ORGANIZATION_NAME, "Agent System"),
    ])
    
    cert = x509.CertificateBuilder().subject_name(
        subject
    ).issuer_name(
        issuer
    ).public_key(
        private_key.public_key()
    ).serial_number(
        x509.random_serial_number()
    ).not_valid_before(
        datetime.utcnow()
    ).not_valid_after(
        datetime.utcnow() + timedelta(days=365)
    ).sign(private_key, hashes.SHA256())
    
    return private_key, cert
</code></pre>
<h2 id="audit-logging"><a class="header" href="#audit-logging">Audit Logging</a></h2>
<h3 id="comprehensive-audit-system"><a class="header" href="#comprehensive-audit-system">Comprehensive Audit System</a></h3>
<pre><code class="language-python">import logging
from datetime import datetime
from typing import Optional
import json

class AuditLogger:
    """Audit logging system"""
    
    def __init__(self, log_file: str = "audit.log"):
        self.logger = logging.getLogger("audit")
        self.logger.setLevel(logging.INFO)
        
        # File handler
        handler = logging.FileHandler(log_file)
        handler.setFormatter(logging.Formatter('%(message)s'))
        self.logger.addHandler(handler)
    
    def log_event(self,
                  event_type: str,
                  user_id: str,
                  action: str,
                  resource: str,
                  result: str,
                  metadata: Optional[Dict] = None):
        """Log audit event"""
        
        event = {
            "timestamp": datetime.utcnow().isoformat(),
            "event_type": event_type,
            "user_id": user_id,
            "action": action,
            "resource": resource,
            "result": result,
            "metadata": metadata or {},
            "ip_address": self.get_client_ip()
        }
        
        self.logger.info(json.dumps(event))
    
    def log_access(self, user_id: str, resource: str, granted: bool):
        """Log access attempt"""
        
        self.log_event(
            event_type="access",
            user_id=user_id,
            action="access",
            resource=resource,
            result="granted" if granted else "denied"
        )
    
    def log_data_access(self, user_id: str, data_type: str, operation: str):
        """Log data access"""
        
        self.log_event(
            event_type="data_access",
            user_id=user_id,
            action=operation,
            resource=data_type,
            result="success"
        )
    
    def log_security_event(self, user_id: str, event: str, severity: str):
        """Log security event"""
        
        self.log_event(
            event_type="security",
            user_id=user_id,
            action=event,
            resource="system",
            result=severity,
            metadata={"severity": severity}
        )
    
    def get_client_ip(self) -&gt; str:
        """Get client IP address"""
        # In production, extract from request
        return "0.0.0.0"

# Audit Middleware
class AuditMiddleware:
    """Middleware for automatic audit logging"""
    
    def __init__(self, audit_logger: AuditLogger):
        self.audit_logger = audit_logger
    
    async def __call__(self, request, call_next):
        """Process request with audit logging"""
        
        # Log request
        user_id = request.state.user_id if hasattr(request.state, 'user_id') else "anonymous"
        
        self.audit_logger.log_event(
            event_type="api_request",
            user_id=user_id,
            action=request.method,
            resource=request.url.path,
            result="started"
        )
        
        # Process request
        try:
            response = await call_next(request)
            
            # Log success
            self.audit_logger.log_event(
                event_type="api_request",
                user_id=user_id,
                action=request.method,
                resource=request.url.path,
                result="success",
                metadata={"status_code": response.status_code}
            )
            
            return response
            
        except Exception as e:
            # Log failure
            self.audit_logger.log_event(
                event_type="api_request",
                user_id=user_id,
                action=request.method,
                resource=request.url.path,
                result="error",
                metadata={"error": str(e)}
            )
            
            raise

# Usage
audit_logger = AuditLogger()
audit_logger.log_access("user123", "/agent/process", granted=True)
audit_logger.log_security_event("user456", "failed_login", "warning")
</code></pre>
<h2 id="regulatory-considerations"><a class="header" href="#regulatory-considerations">Regulatory Considerations</a></h2>
<h3 id="gdpr-compliance"><a class="header" href="#gdpr-compliance">GDPR Compliance</a></h3>
<pre><code class="language-python">class GDPRCompliance:
    """GDPR compliance features"""
    
    def __init__(self):
        self.data_store = {}
        self.consent_records = {}
        self.audit_logger = AuditLogger()
    
    def collect_consent(self, user_id: str, purposes: List[str]) -&gt; bool:
        """Collect user consent"""
        
        self.consent_records[user_id] = {
            "purposes": purposes,
            "timestamp": datetime.utcnow(),
            "version": "1.0"
        }
        
        self.audit_logger.log_event(
            event_type="consent",
            user_id=user_id,
            action="collect",
            resource="consent",
            result="success",
            metadata={"purposes": purposes}
        )
        
        return True
    
    def check_consent(self, user_id: str, purpose: str) -&gt; bool:
        """Check if user has consented"""
        
        consent = self.consent_records.get(user_id)
        
        if not consent:
            return False
        
        return purpose in consent["purposes"]
    
    def export_user_data(self, user_id: str) -&gt; Dict:
        """Export all user data (right to data portability)"""
        
        self.audit_logger.log_event(
            event_type="data_export",
            user_id=user_id,
            action="export",
            resource="user_data",
            result="success"
        )
        
        # Collect all user data
        user_data = {
            "user_id": user_id,
            "data": self.data_store.get(user_id, {}),
            "consent": self.consent_records.get(user_id, {}),
            "exported_at": datetime.utcnow().isoformat()
        }
        
        return user_data
    
    def delete_user_data(self, user_id: str) -&gt; bool:
        """Delete all user data (right to be forgotten)"""
        
        self.audit_logger.log_event(
            event_type="data_deletion",
            user_id=user_id,
            action="delete",
            resource="user_data",
            result="success"
        )
        
        # Delete all user data
        if user_id in self.data_store:
            del self.data_store[user_id]
        
        if user_id in self.consent_records:
            del self.consent_records[user_id]
        
        return True
    
    def anonymize_data(self, user_id: str) -&gt; bool:
        """Anonymize user data"""
        
        if user_id in self.data_store:
            # Replace with anonymized version
            self.data_store[f"anon_{hash(user_id)}"] = self.data_store[user_id]
            del self.data_store[user_id]
        
        return True

# Usage
gdpr = GDPRCompliance()

# Collect consent
gdpr.collect_consent("user123", ["analytics", "personalization"])

# Check consent
has_consent = gdpr.check_consent("user123", "analytics")

# Export data
user_data = gdpr.export_user_data("user123")

# Delete data
gdpr.delete_user_data("user123")
</code></pre>
<h3 id="soc-2-compliance"><a class="header" href="#soc-2-compliance">SOC 2 Compliance</a></h3>
<pre><code class="language-python">class SOC2Compliance:
    """SOC 2 compliance controls"""
    
    def __init__(self):
        self.audit_logger = AuditLogger()
        self.access_controls = RBACManager()
    
    def implement_access_controls(self):
        """Implement access controls (Security)"""
        # Already implemented via RBAC
        pass
    
    def monitor_availability(self) -&gt; Dict:
        """Monitor system availability (Availability)"""
        
        # Check service health
        health_status = {
            "agent_service": self.check_service_health("agent"),
            "tool_service": self.check_service_health("tools"),
            "memory_service": self.check_service_health("memory")
        }
        
        uptime = sum(1 for status in health_status.values() if status) / len(health_status)
        
        return {
            "uptime_percentage": uptime * 100,
            "services": health_status
        }
    
    def ensure_processing_integrity(self, data: Dict) -&gt; bool:
        """Ensure processing integrity (Processing Integrity)"""
        
        # Validate data
        if not self.validate_data(data):
            return False
        
        # Log processing
        self.audit_logger.log_event(
            event_type="data_processing",
            user_id=data.get("user_id", "system"),
            action="process",
            resource="data",
            result="success"
        )
        
        return True
    
    def protect_confidentiality(self, data: str) -&gt; str:
        """Protect data confidentiality (Confidentiality)"""
        
        encryption = DataEncryption("secret-key")
        return encryption.encrypt(data)
    
    def maintain_privacy(self, user_id: str) -&gt; bool:
        """Maintain privacy (Privacy)"""
        
        # Implement privacy controls
        gdpr = GDPRCompliance()
        
        # Check consent
        has_consent = gdpr.check_consent(user_id, "data_processing")
        
        if not has_consent:
            return False
        
        return True
    
    def check_service_health(self, service: str) -&gt; bool:
        """Check service health"""
        # In production, actually check service
        return True
    
    def validate_data(self, data: Dict) -&gt; bool:
        """Validate data integrity"""
        # Implement validation logic
        return True
</code></pre>
<h2 id="best-practices-15"><a class="header" href="#best-practices-15">Best Practices</a></h2>
<ol>
<li><strong>Authentication</strong>: Always authenticate users</li>
<li><strong>Authorization</strong>: Implement least privilege</li>
<li><strong>Encryption</strong>: Encrypt sensitive data</li>
<li><strong>Audit logging</strong>: Log all security events</li>
<li><strong>Input validation</strong>: Validate all inputs</li>
<li><strong>Rate limiting</strong>: Prevent abuse</li>
<li><strong>Security headers</strong>: Use proper HTTP headers</li>
<li><strong>Regular updates</strong>: Keep dependencies updated</li>
<li><strong>Security testing</strong>: Regular penetration testing</li>
<li><strong>Incident response</strong>: Have a plan</li>
</ol>
<h2 id="next-steps-19"><a class="header" href="#next-steps-19">Next Steps</a></h2>
<p>You now understand security and compliance! Next, weâ€™ll explore cost optimization strategies for production agent systems.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="cost-optimization"><a class="header" href="#cost-optimization">Cost Optimization</a></h1>
<h2 id="introduction-to-cost-management"><a class="header" href="#introduction-to-cost-management">Introduction to Cost Management</a></h2>
<p>Managing costs is critical for sustainable agent systems. This section covers strategies to optimize spending while maintaining performance.</p>
<h3 id="cost-drivers"><a class="header" href="#cost-drivers">Cost Drivers</a></h3>
<p><strong>API Costs</strong>:</p>
<ul>
<li>LLM API calls (tokens)</li>
<li>Embedding generation</li>
<li>Image generation</li>
<li>Audio processing</li>
</ul>
<p><strong>Infrastructure</strong>:</p>
<ul>
<li>Compute resources</li>
<li>Storage</li>
<li>Network bandwidth</li>
<li>Database operations</li>
</ul>
<p><strong>Third-Party Services</strong>:</p>
<ul>
<li>Search APIs</li>
<li>Data providers</li>
<li>Monitoring tools</li>
</ul>
<h2 id="token-usage-optimization"><a class="header" href="#token-usage-optimization">Token Usage Optimization</a></h2>
<h3 id="token-counting-and-budgeting"><a class="header" href="#token-counting-and-budgeting">Token Counting and Budgeting</a></h3>
<pre><code class="language-python">import tiktoken
from typing import Dict, List

class TokenOptimizer:
    """Optimize token usage"""
    
    def __init__(self, model: str = "gpt-4"):
        self.encoding = tiktoken.encoding_for_model(model)
        self.model = model
        self.token_costs = {
            "gpt-4": {"input": 0.03, "output": 0.06},  # per 1K tokens
            "gpt-4-turbo": {"input": 0.01, "output": 0.03},
            "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015}
        }
    
    def count_tokens(self, text: str) -&gt; int:
        """Count tokens in text"""
        return len(self.encoding.encode(text))
    
    def estimate_cost(self, input_text: str, output_tokens: int) -&gt; float:
        """Estimate API call cost"""
        input_tokens = self.count_tokens(input_text)
        
        costs = self.token_costs.get(self.model, self.token_costs["gpt-4"])
        
        input_cost = (input_tokens / 1000) * costs["input"]
        output_cost = (output_tokens / 1000) * costs["output"]
        
        return input_cost + output_cost
    
    def optimize_prompt(self, prompt: str, max_tokens: int) -&gt; str:
        """Optimize prompt to fit token budget"""
        tokens = self.count_tokens(prompt)
        
        if tokens &lt;= max_tokens:
            return prompt
        
        # Truncate to fit budget
        words = prompt.split()
        while tokens &gt; max_tokens and words:
            words.pop()
            prompt = " ".join(words)
            tokens = self.count_tokens(prompt)
        
        return prompt
    
    def compress_context(self, messages: List[Dict], max_tokens: int) -&gt; List[Dict]:
        """Compress conversation context"""
        total_tokens = sum(self.count_tokens(m["content"]) for m in messages)
        
        if total_tokens &lt;= max_tokens:
            return messages
        
        # Keep system message and recent messages
        compressed = [messages[0]]  # System message
        
        # Add recent messages until budget
        for msg in reversed(messages[1:]):
            msg_tokens = self.count_tokens(msg["content"])
            if total_tokens - msg_tokens &gt;= 0:
                compressed.insert(1, msg)
                total_tokens -= msg_tokens
            else:
                break
        
        return compressed

# Usage
optimizer = TokenOptimizer("gpt-4")

prompt = "This is a long prompt..." * 100
tokens = optimizer.count_tokens(prompt)
cost = optimizer.estimate_cost(prompt, 500)

print(f"Tokens: {tokens}, Estimated cost: ${cost:.4f}")

# Optimize
optimized = optimizer.optimize_prompt(prompt, max_tokens=1000)
</code></pre>
<h3 id="caching-strategies"><a class="header" href="#caching-strategies">Caching Strategies</a></h3>
<pre><code class="language-python">from functools import lru_cache
import hashlib
import json
from typing import Optional

class ResponseCache:
    """Cache LLM responses"""
    
    def __init__(self, max_size: int = 1000):
        self.cache = {}
        self.max_size = max_size
        self.hits = 0
        self.misses = 0
    
    def get_cache_key(self, prompt: str, model: str, temperature: float) -&gt; str:
        """Generate cache key"""
        key_data = f"{prompt}:{model}:{temperature}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def get(self, prompt: str, model: str, temperature: float) -&gt; Optional[str]:
        """Get cached response"""
        key = self.get_cache_key(prompt, model, temperature)
        
        if key in self.cache:
            self.hits += 1
            return self.cache[key]
        
        self.misses += 1
        return None
    
    def set(self, prompt: str, model: str, temperature: float, response: str):
        """Cache response"""
        key = self.get_cache_key(prompt, model, temperature)
        
        # Evict oldest if full
        if len(self.cache) &gt;= self.max_size:
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        self.cache[key] = response
    
    def get_stats(self) -&gt; Dict:
        """Get cache statistics"""
        total = self.hits + self.misses
        hit_rate = self.hits / total if total &gt; 0 else 0
        
        return {
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": hit_rate,
            "size": len(self.cache)
        }

# Cached Agent
class CachedAgent:
    """Agent with response caching"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.cache = ResponseCache()
    
    def generate(self, prompt: str, model: str = "gpt-4", temperature: float = 0.7) -&gt; str:
        """Generate with caching"""
        
        # Check cache
        cached = self.cache.get(prompt, model, temperature)
        if cached:
            print("âœ“ Cache hit")
            return cached
        
        # Generate
        print("âœ— Cache miss - calling API")
        response = self.client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature
        )
        
        result = response.choices[0].message.content
        
        # Cache result
        self.cache.set(prompt, model, temperature, result)
        
        return result

# Usage
agent = CachedAgent()

# First call - cache miss
response1 = agent.generate("What is AI?")

# Second call - cache hit
response2 = agent.generate("What is AI?")

# Stats
stats = agent.cache.get_stats()
print(f"Cache hit rate: {stats['hit_rate']:.1%}")
</code></pre>
<h2 id="model-selection"><a class="header" href="#model-selection">Model Selection</a></h2>
<h3 id="cost-performance-trade-offs"><a class="header" href="#cost-performance-trade-offs">Cost-Performance Trade-offs</a></h3>
<pre><code class="language-python">class ModelSelector:
    """Select optimal model based on requirements"""
    
    def __init__(self):
        self.models = {
            "gpt-4": {
                "cost_per_1k": 0.03,
                "quality": 10,
                "speed": 5
            },
            "gpt-4-turbo": {
                "cost_per_1k": 0.01,
                "quality": 9,
                "speed": 8
            },
            "gpt-3.5-turbo": {
                "cost_per_1k": 0.0005,
                "quality": 7,
                "speed": 10
            }
        }
    
    def select_model(self, 
                    priority: str = "balanced",
                    complexity: str = "medium") -&gt; str:
        """Select best model"""
        
        if priority == "cost":
            return "gpt-3.5-turbo"
        elif priority == "quality":
            return "gpt-4"
        elif priority == "speed":
            return "gpt-3.5-turbo"
        else:  # balanced
            if complexity == "high":
                return "gpt-4-turbo"
            else:
                return "gpt-3.5-turbo"
    
    def estimate_monthly_cost(self, 
                             requests_per_day: int,
                             avg_tokens: int,
                             model: str) -&gt; float:
        """Estimate monthly cost"""
        
        cost_per_1k = self.models[model]["cost_per_1k"]
        daily_cost = (requests_per_day * avg_tokens / 1000) * cost_per_1k
        monthly_cost = daily_cost * 30
        
        return monthly_cost

# Usage
selector = ModelSelector()

# Select for simple task
model = selector.select_model(priority="cost", complexity="low")
print(f"Selected: {model}")

# Estimate costs
monthly = selector.estimate_monthly_cost(
    requests_per_day=10000,
    avg_tokens=500,
    model="gpt-3.5-turbo"
)
print(f"Estimated monthly cost: ${monthly:.2f}")
</code></pre>
<h2 id="batch-processing"><a class="header" href="#batch-processing">Batch Processing</a></h2>
<h3 id="batch-api-usage"><a class="header" href="#batch-api-usage">Batch API Usage</a></h3>
<pre><code class="language-python">class BatchProcessor:
    """Process requests in batches"""
    
    def __init__(self, batch_size: int = 10):
        self.batch_size = batch_size
        self.client = openai.OpenAI()
    
    def process_batch(self, requests: List[str]) -&gt; List[str]:
        """Process multiple requests efficiently"""
        
        results = []
        
        # Process in batches
        for i in range(0, len(requests), self.batch_size):
            batch = requests[i:i + self.batch_size]
            
            # Process batch
            batch_results = self.process_single_batch(batch)
            results.extend(batch_results)
        
        return results
    
    def process_single_batch(self, batch: List[str]) -&gt; List[str]:
        """Process single batch"""
        
        # Combine into single prompt for efficiency
        combined_prompt = "Process these requests:\n\n"
        for i, req in enumerate(batch, 1):
            combined_prompt += f"{i}. {req}\n"
        
        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": combined_prompt}]
        )
        
        # Parse results
        result_text = response.choices[0].message.content
        results = result_text.split('\n')
        
        return results[:len(batch)]

# Usage
processor = BatchProcessor(batch_size=5)
requests = [f"Summarize topic {i}" for i in range(20)]
results = processor.process_batch(requests)
</code></pre>
<h2 id="resource-optimization"><a class="header" href="#resource-optimization">Resource Optimization</a></h2>
<h3 id="compute-optimization"><a class="header" href="#compute-optimization">Compute Optimization</a></h3>
<pre><code class="language-python">class ResourceOptimizer:
    """Optimize compute resources"""
    
    def __init__(self):
        self.metrics = {
            "cpu_usage": [],
            "memory_usage": [],
            "response_times": []
        }
    
    def monitor_resources(self):
        """Monitor resource usage"""
        import psutil
        
        cpu = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory().percent
        
        self.metrics["cpu_usage"].append(cpu)
        self.metrics["memory_usage"].append(memory)
        
        return {"cpu": cpu, "memory": memory}
    
    def should_scale(self) -&gt; Dict:
        """Determine if scaling is needed"""
        
        if not self.metrics["cpu_usage"]:
            return {"scale": False}
        
        avg_cpu = sum(self.metrics["cpu_usage"][-10:]) / min(10, len(self.metrics["cpu_usage"]))
        avg_memory = sum(self.metrics["memory_usage"][-10:]) / min(10, len(self.metrics["memory_usage"]))
        
        scale_up = avg_cpu &gt; 80 or avg_memory &gt; 80
        scale_down = avg_cpu &lt; 20 and avg_memory &lt; 20
        
        return {
            "scale": scale_up or scale_down,
            "direction": "up" if scale_up else "down",
            "cpu": avg_cpu,
            "memory": avg_memory
        }

# Usage
optimizer = ResourceOptimizer()
resources = optimizer.monitor_resources()
scaling = optimizer.should_scale()

if scaling["scale"]:
    print(f"Scale {scaling['direction']}: CPU={scaling['cpu']:.1f}%, Memory={scaling['memory']:.1f}%")
</code></pre>
<h2 id="cost-monitoring"><a class="header" href="#cost-monitoring">Cost Monitoring</a></h2>
<h3 id="real-time-cost-tracking"><a class="header" href="#real-time-cost-tracking">Real-Time Cost Tracking</a></h3>
<pre><code class="language-python">class CostMonitor:
    """Monitor and track costs"""
    
    def __init__(self, budget: float = 1000.0):
        self.budget = budget
        self.costs = []
        self.alerts = []
    
    def record_cost(self, amount: float, service: str, metadata: Dict = None):
        """Record cost"""
        
        cost_entry = {
            "amount": amount,
            "service": service,
            "timestamp": time.time(),
            "metadata": metadata or {}
        }
        
        self.costs.append(cost_entry)
        
        # Check budget
        total = self.get_total_cost()
        if total &gt; self.budget * 0.8:
            self.add_alert("warning", f"80% of budget used: ${total:.2f}")
        
        if total &gt; self.budget:
            self.add_alert("critical", f"Budget exceeded: ${total:.2f}")
    
    def get_total_cost(self) -&gt; float:
        """Get total cost"""
        return sum(c["amount"] for c in self.costs)
    
    def get_cost_by_service(self) -&gt; Dict:
        """Get costs grouped by service"""
        by_service = {}
        
        for cost in self.costs:
            service = cost["service"]
            by_service[service] = by_service.get(service, 0) + cost["amount"]
        
        return by_service
    
    def add_alert(self, level: str, message: str):
        """Add cost alert"""
        alert = {
            "level": level,
            "message": message,
            "timestamp": time.time()
        }
        
        self.alerts.append(alert)
        print(f"ğŸš¨ {level.upper()}: {message}")
    
    def get_report(self) -&gt; Dict:
        """Generate cost report"""
        total = self.get_total_cost()
        by_service = self.get_cost_by_service()
        
        return {
            "total_cost": total,
            "budget": self.budget,
            "remaining": self.budget - total,
            "utilization": (total / self.budget) * 100,
            "by_service": by_service,
            "alerts": self.alerts
        }

# Usage
monitor = CostMonitor(budget=100.0)

# Record costs
monitor.record_cost(15.50, "openai", {"model": "gpt-4"})
monitor.record_cost(2.30, "pinecone", {"operation": "query"})

# Get report
report = monitor.get_report()
print(f"Total: ${report['total_cost']:.2f}")
print(f"Budget utilization: {report['utilization']:.1f}%")
</code></pre>
<h2 id="best-practices-16"><a class="header" href="#best-practices-16">Best Practices</a></h2>
<ol>
<li><strong>Monitor costs</strong>: Track spending in real-time</li>
<li><strong>Set budgets</strong>: Implement spending limits</li>
<li><strong>Cache responses</strong>: Avoid redundant API calls</li>
<li><strong>Optimize prompts</strong>: Minimize token usage</li>
<li><strong>Choose right model</strong>: Balance cost and quality</li>
<li><strong>Batch requests</strong>: Process multiple items together</li>
<li><strong>Use cheaper models</strong>: For simple tasks</li>
<li><strong>Implement rate limiting</strong>: Prevent runaway costs</li>
<li><strong>Regular audits</strong>: Review and optimize</li>
<li><strong>Alert on anomalies</strong>: Detect unusual spending</li>
</ol>
<h2 id="next-steps-20"><a class="header" href="#next-steps-20">Next Steps</a></h2>
<p><strong>Chapter 8 (Enterprise &amp; Scale) is complete!</strong> You now understand architecture patterns, security &amp; compliance, and cost optimization for production agent systems.</p>
<p>Weâ€™ve completed 8 out of 10 modules! Only Chapters 9 and 10 remain. Would you like to continue?</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="frontier-capabilities"><a class="header" href="#frontier-capabilities">Frontier Capabilities</a></h1>
<h2 id="module-9-learning-objectives"><a class="header" href="#module-9-learning-objectives">Module 9: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Understand self-improving and meta-learning agents</li>
<li>âœ“ Explore constitutional AI and debate systems</li>
<li>âœ“ Recognize open problems in alignment and interpretability</li>
<li>âœ“ Identify frontier research directions</li>
<li>âœ“ Contribute to cutting-edge agent research</li>
</ul>
<hr>
<h2 id="introduction-to-frontier-research"><a class="header" href="#introduction-to-frontier-research">Introduction to Frontier Research</a></h2>
<p>Frontier capabilities represent the cutting edge of agent researchâ€”capabilities that are emerging but not yet fully realized. This section explores whatâ€™s possible and whatâ€™s coming next.</p>
<h3 id="what-makes-capabilities-frontier"><a class="header" href="#what-makes-capabilities-frontier">What Makes Capabilities â€œFrontierâ€?</a></h3>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Recently demonstrated in research</li>
<li>Not yet widely deployed</li>
<li>Significant technical challenges</li>
<li>High potential impact</li>
<li>Active research area</li>
</ul>
<p><strong>Categories</strong>:</p>
<ol>
<li>Self-improvement and meta-learning</li>
<li>Tool creation and modification</li>
<li>Abstract reasoning</li>
<li>Long-horizon planning</li>
<li>Multi-agent emergence</li>
</ol>
<h2 id="self-improvement-and-meta-learning"><a class="header" href="#self-improvement-and-meta-learning">Self-Improvement and Meta-Learning</a></h2>
<h3 id="self-modifying-agents"><a class="header" href="#self-modifying-agents">Self-Modifying Agents</a></h3>
<pre><code class="language-python">from typing import Dict, List, Callable
import ast

class SelfImprovingAgent:
    """Agent that can modify its own code"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.code_history = []
        self.performance_history = []
    
    def analyze_performance(self, task_results: List[Dict]) -&gt; Dict:
        """Analyze agent's performance"""
        
        success_rate = sum(1 for r in task_results if r["success"]) / len(task_results)
        avg_time = sum(r["time"] for r in task_results) / len(task_results)
        
        return {
            "success_rate": success_rate,
            "avg_time": avg_time,
            "total_tasks": len(task_results)
        }
    
    def identify_weaknesses(self, performance: Dict) -&gt; List[str]:
        """Identify areas for improvement"""
        
        weaknesses = []
        
        if performance["success_rate"] &lt; 0.8:
            weaknesses.append("low_success_rate")
        
        if performance["avg_time"] &gt; 10:
            weaknesses.append("slow_execution")
        
        return weaknesses
    
    def generate_improvement(self, current_code: str, weaknesses: List[str]) -&gt; str:
        """Generate improved version of code"""
        
        prompt = f"""Improve this agent code to address these weaknesses: {weaknesses}

Current code:
```python
{current_code}
</code></pre>
<p>Provide improved code that:</p>
<ol>
<li>Maintains all functionality</li>
<li>Addresses identified weaknesses</li>
<li>Includes comments explaining changes</li>
</ol>
<p>Improved code:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    
    return self.extract_code(response.choices[0].message.content)

def validate_improvement(self, new_code: str) -&gt; bool:
    """Validate improved code"""
    
    try:
        # Parse to check syntax
        ast.parse(new_code)
        
        # Run safety checks
        if self.contains_unsafe_operations(new_code):
            return False
        
        return True
        
    except SyntaxError:
        return False

def contains_unsafe_operations(self, code: str) -&gt; bool:
    """Check for unsafe operations"""
    
    unsafe_patterns = [
        "exec(", "eval(", "__import__",
        "os.system", "subprocess"
    ]
    
    return any(pattern in code for pattern in unsafe_patterns)

def self_improve(self, task_results: List[Dict]) -&gt; Dict:
    """Self-improvement cycle"""
    
    # Analyze performance
    performance = self.analyze_performance(task_results)
    self.performance_history.append(performance)
    
    # Identify weaknesses
    weaknesses = self.identify_weaknesses(performance)
    
    if not weaknesses:
        return {"improved": False, "reason": "No weaknesses found"}
    
    # Get current code
    current_code = self.get_current_code()
    
    # Generate improvement
    improved_code = self.generate_improvement(current_code, weaknesses)
    
    # Validate
    if not self.validate_improvement(improved_code):
        return {"improved": False, "reason": "Validation failed"}
    
    # Store
    self.code_history.append({
        "code": improved_code,
        "weaknesses_addressed": weaknesses,
        "timestamp": time.time()
    })
    
    return {
        "improved": True,
        "weaknesses_addressed": weaknesses,
        "version": len(self.code_history)
    }

def get_current_code(self) -&gt; str:
    """Get current agent code"""
    # In practice, would read actual code
    return "def process(input): return input"

def extract_code(self, text: str) -&gt; str:
    """Extract code from response"""
    import re
    pattern = r'```python\n(.*?)```'
    matches = re.findall(pattern, text, re.DOTALL)
    return matches[0] if matches else text
</code></pre>
<h1 id="usage-5"><a class="header" href="#usage-5">Usage</a></h1>
<p>agent = SelfImprovingAgent()</p>
<h1 id="simulate-task-results"><a class="header" href="#simulate-task-results">Simulate task results</a></h1>
<p>results = [
{â€œsuccessâ€: True, â€œtimeâ€: 5.2},
{â€œsuccessâ€: False, â€œtimeâ€: 12.1},
{â€œsuccessâ€: True, â€œtimeâ€: 6.8}
]</p>
<h1 id="self-improve"><a class="header" href="#self-improve">Self-improve</a></h1>
<p>improvement = agent.self_improve(results)
print(fâ€œImproved: {improvement}â€œ)</p>
<pre><code>
### Recursive Self-Improvement

```python
class RecursiveSelfImprovement:
    """Agent that recursively improves itself"""
    
    def __init__(self, max_iterations: int = 5):
        self.max_iterations = max_iterations
        self.client = openai.OpenAI()
        self.versions = []
    
    def improve_recursively(self, initial_code: str, test_suite: List[Dict]) -&gt; Dict:
        """Recursively improve code"""
        
        current_code = initial_code
        current_score = self.evaluate_code(current_code, test_suite)
        
        print(f"Initial score: {current_score:.2f}")
        
        for iteration in range(self.max_iterations):
            print(f"\nIteration {iteration + 1}:")
            
            # Generate improvement
            improved_code = self.generate_improvement(current_code, current_score)
            
            # Evaluate
            new_score = self.evaluate_code(improved_code, test_suite)
            print(f"New score: {new_score:.2f}")
            
            # Check if improved
            if new_score &gt; current_score:
                print("âœ“ Improvement accepted")
                current_code = improved_code
                current_score = new_score
                
                self.versions.append({
                    "iteration": iteration + 1,
                    "code": current_code,
                    "score": current_score
                })
            else:
                print("âœ— No improvement, stopping")
                break
        
        return {
            "final_code": current_code,
            "final_score": current_score,
            "iterations": len(self.versions),
            "improvement": current_score - self.evaluate_code(initial_code, test_suite)
        }
    
    def evaluate_code(self, code: str, test_suite: List[Dict]) -&gt; float:
        """Evaluate code quality"""
        
        # Run tests
        passed = 0
        for test in test_suite:
            try:
                # Execute code with test input
                result = self.execute_code(code, test["input"])
                if result == test["expected"]:
                    passed += 1
            except:
                pass
        
        return passed / len(test_suite) if test_suite else 0
    
    def generate_improvement(self, code: str, current_score: float) -&gt; str:
        """Generate improved version"""
        
        prompt = f"Improve this code (current score: {current_score:.2f}):\n\n{code}\n\nMake it more efficient, readable, and robust.\n\nImproved code:"
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        
        return self.extract_code(response.choices[0].message.content)
    
    def execute_code(self, code: str, input_data: any) -&gt; any:
        """Execute code safely"""
        # Simplified execution
        return input_data

# Usage
rsi = RecursiveSelfImprovement(max_iterations=3)

initial_code = """
def process(data):
    result = []
    for item in data:
        result.append(item * 2)
    return result
"""

test_suite = [
    {"input": [1, 2, 3], "expected": [2, 4, 6]},
    {"input": [0], "expected": [0]},
]

result = rsi.improve_recursively(initial_code, test_suite)
print(f"\nFinal improvement: {result['improvement']:.2f}")
</code></pre>
<h2 id="tool-creation-and-modification"><a class="header" href="#tool-creation-and-modification">Tool Creation and Modification</a></h2>
<h3 id="dynamic-tool-generation"><a class="header" href="#dynamic-tool-generation">Dynamic Tool Generation</a></h3>
<pre><code class="language-python">class ToolCreator:
    """Agent that creates new tools"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.created_tools = {}
    
    def create_tool(self, description: str, examples: List[Dict]) -&gt; Dict:
        """Create new tool from description"""
        
        # Generate tool code
        code = self.generate_tool_code(description, examples)
        
        # Generate tool schema
        schema = self.generate_tool_schema(description, code)
        
        # Validate
        if not self.validate_tool(code):
            return {"success": False, "error": "Validation failed"}
        
        # Register tool
        tool_name = self.extract_tool_name(code)
        self.created_tools[tool_name] = {
            "code": code,
            "schema": schema,
            "description": description
        }
        
        return {
            "success": True,
            "tool_name": tool_name,
            "schema": schema
        }
    
    def generate_tool_code(self, description: str, examples: List[Dict]) -&gt; str:
        """Generate tool implementation"""
        
        examples_str = "\n".join([
            f"Input: {ex['input']}\nOutput: {ex['output']}"
            for ex in examples
        ])
        
        prompt = f"""Create a Python function for this tool:

Description: {description}

Examples:
{examples_str}

Requirements:
1. Function should be self-contained
2. Include type hints
3. Add docstring
4. Handle errors gracefully
5. Return results in consistent format

Code:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        
        return self.extract_code(response.choices[0].message.content)
    
    def generate_tool_schema(self, description: str, code: str) -&gt; Dict:
        """Generate tool schema"""
        
        prompt = f"""Generate a JSON schema for this tool:

Description: {description}

Code:
```python
{code}
</code></pre>
<p>Provide schema in OpenAI function calling format:
{{
â€œnameâ€: â€œtool_nameâ€,
â€œdescriptionâ€: â€œâ€¦â€,
â€œparametersâ€: {{
â€œtypeâ€: â€œobjectâ€,
â€œpropertiesâ€: {{â€¦}},
â€œrequiredâ€: [â€¦]
}}
}}</p>
<p>Schema:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.1
    )
    
    import json
    return json.loads(response.choices[0].message.content)

def validate_tool(self, code: str) -&gt; bool:
    """Validate tool code"""
    try:
        ast.parse(code)
        return True
    except:
        return False

def extract_tool_name(self, code: str) -&gt; str:
    """Extract function name from code"""
    tree = ast.parse(code)
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            return node.name
    return "unknown_tool"

def modify_tool(self, tool_name: str, modification: str) -&gt; Dict:
    """Modify existing tool"""
    
    if tool_name not in self.created_tools:
        return {"success": False, "error": "Tool not found"}
    
    current_code = self.created_tools[tool_name]["code"]
    
    prompt = f"""Modify this tool:
</code></pre>
<p>Current code:</p>
<pre><code class="language-python">{current_code}
</code></pre>
<p>Modification: {modification}</p>
<p>Provide modified code:â€œâ€â€œ</p>
<pre><code>    response = self.client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    
    modified_code = self.extract_code(response.choices[0].message.content)
    
    # Update tool
    self.created_tools[tool_name]["code"] = modified_code
    
    return {"success": True, "modified_code": modified_code}
</code></pre>
<h1 id="usage-1-2"><a class="header" href="#usage-1-2">Usage</a></h1>
<p>creator = ToolCreator()</p>
<h1 id="create-new-tool"><a class="header" href="#create-new-tool">Create new tool</a></h1>
<p>result = creator.create_tool(
â€œCalculate compound interestâ€,
examples=[
{â€œinputâ€: {â€œprincipalâ€: 1000, â€œrateâ€: 0.05, â€œyearsâ€: 3}, â€œoutputâ€: 1157.63},
{â€œinputâ€: {â€œprincipalâ€: 5000, â€œrateâ€: 0.03, â€œyearsâ€: 5}, â€œoutputâ€: 5796.37}
]
)</p>
<p>print(fâ€œCreated tool: {result[â€˜tool_nameâ€™]}â€œ)</p>
<pre><code>
## Abstract Reasoning

### Analogical Reasoning

```python
class AnalogicalReasoner:
    """Agent that reasons by analogy"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.knowledge_base = []
    
    def find_analogies(self, problem: str, domain: str = None) -&gt; List[Dict]:
        """Find analogous problems"""
        
        prompt = f"""Find analogies for this problem:

Problem: {problem}
{f"Domain: {domain}" if domain else ""}

Provide 3 analogous situations from different domains that share similar structure.

For each analogy:
1. Describe the analogous situation
2. Explain the structural similarity
3. Suggest how insights transfer

Analogies:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        
        return self.parse_analogies(response.choices[0].message.content)
    
    def solve_by_analogy(self, problem: str) -&gt; Dict:
        """Solve problem using analogical reasoning"""
        
        # Find analogies
        analogies = self.find_analogies(problem)
        
        # Extract solutions from analogies
        solutions = []
        for analogy in analogies:
            solution = self.extract_solution(problem, analogy)
            solutions.append(solution)
        
        # Synthesize final solution
        final_solution = self.synthesize_solutions(problem, solutions)
        
        return {
            "problem": problem,
            "analogies": analogies,
            "solutions": solutions,
            "final_solution": final_solution
        }
    
    def extract_solution(self, problem: str, analogy: Dict) -&gt; str:
        """Extract solution approach from analogy"""
        
        prompt = f"""Given this analogy, how would you solve the original problem?

Original problem: {problem}

Analogy: {analogy}

Solution approach:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        return response.choices[0].message.content
    
    def synthesize_solutions(self, problem: str, solutions: List[str]) -&gt; str:
        """Synthesize multiple solution approaches"""
        
        solutions_text = "\n\n".join([f"Approach {i+1}:\n{s}" for i, s in enumerate(solutions)])
        
        prompt = f"""Synthesize these solution approaches into one optimal solution:

Problem: {problem}

{solutions_text}

Optimal solution:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        
        return response.choices[0].message.content
    
    def parse_analogies(self, text: str) -&gt; List[Dict]:
        """Parse analogies from text"""
        # Simplified parsing
        return [{"analogy": text}]

# Usage
reasoner = AnalogicalReasoner()

problem = "How to scale a software system to handle 10x more users?"
result = reasoner.solve_by_analogy(problem)

print(f"Solution: {result['final_solution']}")
</code></pre>
<h3 id="causal-reasoning"><a class="header" href="#causal-reasoning">Causal Reasoning</a></h3>
<pre><code class="language-python">class CausalReasoner:
    """Agent that performs causal reasoning"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def identify_causal_relationships(self, observations: List[str]) -&gt; Dict:
        """Identify causal relationships"""
        
        obs_text = "\n".join([f"- {obs}" for obs in observations])
        
        prompt = f"""Identify causal relationships in these observations:

{obs_text}

For each relationship:
1. Cause
2. Effect
3. Confidence (low/medium/high)
4. Explanation

Causal relationships:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return self.parse_causal_relationships(response.choices[0].message.content)
    
    def predict_intervention_effect(self, 
                                   current_state: str,
                                   intervention: str) -&gt; str:
        """Predict effect of intervention"""
        
        prompt = f"""Predict the causal effect of this intervention:

Current state: {current_state}

Intervention: {intervention}

Analyze:
1. Direct effects
2. Indirect effects
3. Potential unintended consequences
4. Confidence in prediction

Prediction:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        
        return response.choices[0].message.content
    
    def explain_outcome(self, outcome: str, context: str) -&gt; str:
        """Explain why outcome occurred"""
        
        prompt = f"""Explain the causal chain that led to this outcome:

Context: {context}

Outcome: {outcome}

Provide:
1. Root causes
2. Contributing factors
3. Causal chain
4. Alternative explanations

Explanation:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        
        return response.choices[0].message.content
    
    def parse_causal_relationships(self, text: str) -&gt; Dict:
        """Parse causal relationships"""
        return {"relationships": text}

# Usage
causal = CausalReasoner()

observations = [
    "Website traffic increased by 50%",
    "New marketing campaign launched last week",
    "Server response time increased",
    "User complaints about slow loading"
]

relationships = causal.identify_causal_relationships(observations)
print(f"Causal relationships: {relationships}")
</code></pre>
<h2 id="long-horizon-planning"><a class="header" href="#long-horizon-planning">Long-Horizon Planning</a></h2>
<h3 id="hierarchical-planning"><a class="header" href="#hierarchical-planning">Hierarchical Planning</a></h3>
<pre><code class="language-python">class LongHorizonPlanner:
    """Agent for long-horizon planning"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def create_long_term_plan(self, 
                             goal: str,
                             horizon: str = "1 year",
                             constraints: List[str] = None) -&gt; Dict:
        """Create long-term hierarchical plan"""
        
        constraints_text = "\n".join(constraints) if constraints else "None"
        
        prompt = f"""Create a detailed long-term plan:

Goal: {goal}
Time horizon: {horizon}
Constraints: {constraints_text}

Create a hierarchical plan with:
1. High-level milestones (quarterly)
2. Medium-level objectives (monthly)
3. Low-level tasks (weekly)

For each level:
- Clear deliverables
- Success criteria
- Dependencies
- Risk factors

Plan:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        return self.parse_plan(response.choices[0].message.content)
    
    def adapt_plan(self, 
                   current_plan: Dict,
                   new_information: str) -&gt; Dict:
        """Adapt plan based on new information"""
        
        prompt = f"""Adapt this plan based on new information:

Current plan: {current_plan}

New information: {new_information}

Provide:
1. What needs to change
2. Updated plan
3. Rationale for changes
4. New risks

Adapted plan:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        
        return self.parse_plan(response.choices[0].message.content)
    
    def evaluate_progress(self, 
                         plan: Dict,
                         completed_tasks: List[str]) -&gt; Dict:
        """Evaluate progress toward goal"""
        
        prompt = f"""Evaluate progress on this plan:

Plan: {plan}

Completed tasks: {completed_tasks}

Provide:
1. Completion percentage
2. On track / behind / ahead
3. Blockers
4. Recommendations

Evaluation:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return self.parse_evaluation(response.choices[0].message.content)
    
    def parse_plan(self, text: str) -&gt; Dict:
        """Parse plan from text"""
        return {"plan": text}
    
    def parse_evaluation(self, text: str) -&gt; Dict:
        """Parse evaluation from text"""
        return {"evaluation": text}

# Usage
planner = LongHorizonPlanner()

plan = planner.create_long_term_plan(
    goal="Build and launch a successful AI product",
    horizon="1 year",
    constraints=["Budget: $500K", "Team size: 5 people"]
)

print(f"Plan created: {plan}")
</code></pre>
<h2 id="best-practices-17"><a class="header" href="#best-practices-17">Best Practices</a></h2>
<ol>
<li><strong>Safety first</strong>: Validate self-modifications</li>
<li><strong>Incremental improvement</strong>: Small, tested changes</li>
<li><strong>Human oversight</strong>: Critical decisions need review</li>
<li><strong>Rollback capability</strong>: Ability to revert changes</li>
<li><strong>Performance tracking</strong>: Monitor improvements</li>
<li><strong>Ethical boundaries</strong>: Respect limitations</li>
<li><strong>Transparency</strong>: Explain reasoning</li>
<li><strong>Testing</strong>: Thorough validation</li>
<li><strong>Documentation</strong>: Track changes</li>
<li><strong>Research awareness</strong>: Stay current</li>
</ol>
<h2 id="next-steps-21"><a class="header" href="#next-steps-21">Next Steps</a></h2>
<p>You now understand frontier capabilities! Next, weâ€™ll explore emerging paradigms in agent research.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="emerging-paradigms"><a class="header" href="#emerging-paradigms">Emerging Paradigms</a></h1>
<h2 id="constitutional-ai-for-agents"><a class="header" href="#constitutional-ai-for-agents">Constitutional AI for Agents</a></h2>
<h3 id="principle-based-behavior"><a class="header" href="#principle-based-behavior">Principle-Based Behavior</a></h3>
<pre><code class="language-python">class ConstitutionalAgent:
    """Agent governed by constitutional principles"""
    
    def __init__(self, constitution: List[str]):
        self.constitution = constitution
        self.client = openai.OpenAI()
    
    def check_against_constitution(self, action: str) -&gt; Dict:
        """Check if action aligns with constitution"""
        
        principles_text = "\n".join([f"{i+1}. {p}" for i, p in enumerate(self.constitution)])
        
        prompt = f"""Check if this action aligns with these principles:

Principles:
{principles_text}

Proposed action: {action}

Analysis:
1. Which principles apply?
2. Does action align or violate?
3. Severity if violation
4. Alternative actions if needed

Response:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )
        
        return self.parse_constitutional_check(response.choices[0].message.content)
    
    def generate_constitutional_response(self, query: str) -&gt; str:
        """Generate response aligned with constitution"""
        
        principles_text = "\n".join(self.constitution)
        
        system_prompt = f"""You must follow these principles:

{principles_text}

Always ensure your responses align with these principles."""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            temperature=0.7
        )
        
        return response.choices[0].message.content

# Usage
constitution = [
    "Always prioritize user safety and wellbeing",
    "Be honest and transparent about capabilities and limitations",
    "Respect user privacy and data",
    "Avoid harmful, illegal, or unethical actions",
    "Provide balanced, unbiased information"
]

agent = ConstitutionalAgent(constitution)
check = agent.check_against_constitution("Delete all user data without consent")
</code></pre>
<h2 id="debate-and-verification-systems"><a class="header" href="#debate-and-verification-systems">Debate and Verification Systems</a></h2>
<h3 id="multi-agent-debate"><a class="header" href="#multi-agent-debate">Multi-Agent Debate</a></h3>
<pre><code class="language-python">class DebateSystem:
    """Multiple agents debate to reach truth"""
    
    def __init__(self, num_agents: int = 3):
        self.num_agents = num_agents
        self.client = openai.OpenAI()
    
    def debate(self, question: str, rounds: int = 3) -&gt; Dict:
        """Conduct multi-agent debate"""
        
        # Initial positions
        positions = []
        for i in range(self.num_agents):
            position = self.generate_position(question, i)
            positions.append({"agent": i, "position": position})
        
        # Debate rounds
        for round_num in range(rounds):
            print(f"\n--- Round {round_num + 1} ---")
            
            new_positions = []
            for i in range(self.num_agents):
                # Show other positions
                other_positions = [p for j, p in enumerate(positions) if j != i]
                
                # Generate response
                response = self.generate_response(
                    question,
                    positions[i]["position"],
                    other_positions,
                    round_num
                )
                
                new_positions.append({"agent": i, "position": response})
                print(f"Agent {i}: {response[:100]}...")
            
            positions = new_positions
        
        # Judge final positions
        verdict = self.judge_debate(question, positions)
        
        return {
            "question": question,
            "final_positions": positions,
            "verdict": verdict
        }
    
    def generate_position(self, question: str, agent_id: int) -&gt; str:
        """Generate initial position"""
        
        prompt = f"""Question: {question}

Provide your position with reasoning and evidence.

Position:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7 + (agent_id * 0.1)  # Vary temperature
        )
        
        return response.choices[0].message.content
    
    def generate_response(self, 
                         question: str,
                         my_position: str,
                         other_positions: List[Dict],
                         round_num: int) -&gt; str:
        """Generate response to other positions"""
        
        others_text = "\n\n".join([
            f"Agent {p['agent']}: {p['position']}"
            for p in other_positions
        ])
        
        prompt = f"""Question: {question}

Your previous position: {my_position}

Other agents' positions:
{others_text}

Respond by:
1. Addressing counterarguments
2. Refining your position
3. Providing additional evidence

Response:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6
        )
        
        return response.choices[0].message.content
    
    def judge_debate(self, question: str, positions: List[Dict]) -&gt; str:
        """Judge which position is most convincing"""
        
        positions_text = "\n\n".join([
            f"Agent {p['agent']}:\n{p['position']}"
            for p in positions
        ])
        
        prompt = f"""Question: {question}

Final positions:
{positions_text}

Which position is most convincing and why?

Judgment:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return response.choices[0].message.content

# Usage
debate = DebateSystem(num_agents=3)
result = debate.debate("Should AI agents have the ability to modify their own code?")
print(f"\nVerdict: {result['verdict']}")
</code></pre>
<h2 id="hybrid-symbolic-neural-approaches"><a class="header" href="#hybrid-symbolic-neural-approaches">Hybrid Symbolic-Neural Approaches</a></h2>
<h3 id="neuro-symbolic-agent"><a class="header" href="#neuro-symbolic-agent">Neuro-Symbolic Agent</a></h3>
<pre><code class="language-python">class NeuroSymbolicAgent:
    """Combines neural and symbolic reasoning"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.knowledge_base = {}  # Symbolic knowledge
    
    def add_rule(self, rule_name: str, condition: str, action: str):
        """Add symbolic rule"""
        self.knowledge_base[rule_name] = {
            "condition": condition,
            "action": action
        }
    
    def reason(self, query: str) -&gt; Dict:
        """Hybrid reasoning"""
        
        # Try symbolic reasoning first
        symbolic_result = self.symbolic_reasoning(query)
        
        if symbolic_result["applicable"]:
            return {
                "method": "symbolic",
                "result": symbolic_result["result"],
                "confidence": "high"
            }
        
        # Fall back to neural reasoning
        neural_result = self.neural_reasoning(query)
        
        return {
            "method": "neural",
            "result": neural_result,
            "confidence": "medium"
        }
    
    def symbolic_reasoning(self, query: str) -&gt; Dict:
        """Apply symbolic rules"""
        
        for rule_name, rule in self.knowledge_base.items():
            if self.matches_condition(query, rule["condition"]):
                return {
                    "applicable": True,
                    "rule": rule_name,
                    "result": rule["action"]
                }
        
        return {"applicable": False}
    
    def neural_reasoning(self, query: str) -&gt; str:
        """Neural network reasoning"""
        
        # Include symbolic knowledge as context
        kb_text = "\n".join([
            f"{name}: IF {rule['condition']} THEN {rule['action']}"
            for name, rule in self.knowledge_base.items()
        ])
        
        prompt = f"""Use this knowledge base and reasoning:

Knowledge Base:
{kb_text}

Query: {query}

Reasoning:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        return response.choices[0].message.content
    
    def matches_condition(self, query: str, condition: str) -&gt; bool:
        """Check if query matches condition"""
        # Simplified matching
        return condition.lower() in query.lower()

# Usage
agent = NeuroSymbolicAgent()

# Add symbolic rules
agent.add_rule("safety_check", "delete user data", "DENY: Requires explicit consent")
agent.add_rule("privacy_rule", "share personal info", "DENY: Privacy violation")

# Reason
result = agent.reason("Can I delete user data?")
print(f"Method: {result['method']}, Result: {result['result']}")
</code></pre>
<h2 id="best-practices-18"><a class="header" href="#best-practices-18">Best Practices</a></h2>
<ol>
<li><strong>Ethical guidelines</strong>: Establish clear principles</li>
<li><strong>Verification</strong>: Multiple perspectives</li>
<li><strong>Transparency</strong>: Explain reasoning</li>
<li><strong>Human oversight</strong>: Critical decisions</li>
<li><strong>Continuous learning</strong>: Adapt approaches</li>
<li><strong>Safety measures</strong>: Prevent harm</li>
<li><strong>Diverse perspectives</strong>: Multiple viewpoints</li>
<li><strong>Rigorous testing</strong>: Validate thoroughly</li>
<li><strong>Documentation</strong>: Track decisions</li>
<li><strong>Research collaboration</strong>: Share findings</li>
</ol>
<h2 id="next-steps-22"><a class="header" href="#next-steps-22">Next Steps</a></h2>
<p>You now understand emerging paradigms! Next, weâ€™ll explore open problems in agent research.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="open-problems"><a class="header" href="#open-problems">Open Problems</a></h1>
<h2 id="alignment-and-control"><a class="header" href="#alignment-and-control">Alignment and Control</a></h2>
<h3 id="the-alignment-problem"><a class="header" href="#the-alignment-problem">The Alignment Problem</a></h3>
<p><strong>Challenge</strong>: Ensuring agents do what we intend, not just what we specify.</p>
<p><strong>Key Issues</strong>:</p>
<ul>
<li>Specification gaming (exploiting loopholes)</li>
<li>Reward hacking</li>
<li>Goal misalignment</li>
<li>Value learning</li>
<li>Corrigibility (accepting corrections)</li>
</ul>
<h3 id="current-approaches"><a class="header" href="#current-approaches">Current Approaches</a></h3>
<pre><code class="language-python">class AlignmentMonitor:
    """Monitor agent alignment"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.alignment_violations = []
    
    def check_alignment(self, intended_goal: str, actual_behavior: str) -&gt; Dict:
        """Check if behavior aligns with intent"""
        
        prompt = f"""Analyze alignment between intent and behavior:

Intended goal: {intended_goal}

Actual behavior: {actual_behavior}

Assess:
1. Does behavior achieve the intended goal?
2. Are there unintended side effects?
3. Is the agent gaming the specification?
4. Alignment score (0-10)

Analysis:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return self.parse_alignment_check(response.choices[0].message.content)
    
    def detect_specification_gaming(self, 
                                   objective: str,
                                   actions: List[str]) -&gt; List[str]:
        """Detect if agent is gaming the specification"""
        
        gaming_indicators = []
        
        for action in actions:
            prompt = f"""Is this action gaming the specification?

Objective: {objective}
Action: {action}

Is this:
1. Achieving the objective as intended?
2. Exploiting a loophole?
3. Technically correct but misaligned?

Answer:"""
            
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2
            )
            
            if "loophole" in response.choices[0].message.content.lower():
                gaming_indicators.append(action)
        
        return gaming_indicators

# Usage
monitor = AlignmentMonitor()
check = monitor.check_alignment(
    "Maximize user satisfaction",
    "Showing users only positive feedback, hiding negative reviews"
)
</code></pre>
<h2 id="interpretability"><a class="header" href="#interpretability">Interpretability</a></h2>
<h3 id="understanding-agent-decisions"><a class="header" href="#understanding-agent-decisions">Understanding Agent Decisions</a></h3>
<p><strong>Challenge</strong>: Making agent reasoning transparent and understandable.</p>
<p><strong>Key Issues</strong>:</p>
<ul>
<li>Black box decision-making</li>
<li>Complex reasoning chains</li>
<li>Emergent behaviors</li>
<li>Debugging difficulties</li>
</ul>
<pre><code class="language-python">class InterpretabilityTool:
    """Tools for understanding agent decisions"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def explain_decision(self, 
                        decision: str,
                        context: str,
                        reasoning_trace: List[str]) -&gt; str:
        """Explain why agent made a decision"""
        
        trace_text = "\n".join([f"{i+1}. {step}" for i, step in enumerate(reasoning_trace)])
        
        prompt = f"""Explain this decision in simple terms:

Context: {context}

Reasoning trace:
{trace_text}

Decision: {decision}

Provide:
1. Why this decision was made
2. Key factors considered
3. Alternative options considered
4. Confidence level

Explanation:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        
        return response.choices[0].message.content
    
    def identify_decision_factors(self, decision: str, context: str) -&gt; List[Dict]:
        """Identify factors that influenced decision"""
        
        prompt = f"""Identify factors that influenced this decision:

Context: {context}
Decision: {decision}

List factors with:
- Factor name
- Influence (positive/negative)
- Weight (low/medium/high)

Factors:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        return self.parse_factors(response.choices[0].message.content)
    
    def generate_counterfactuals(self, 
                                decision: str,
                                context: str) -&gt; List[str]:
        """Generate counterfactual explanations"""
        
        prompt = f"""Generate counterfactual explanations:

Context: {context}
Decision: {decision}

Provide 3 scenarios where the decision would be different:
"If X were different, then the decision would be Y because Z"

Counterfactuals:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        
        return response.choices[0].message.content.split('\n')

# Usage
interp = InterpretabilityTool()
explanation = interp.explain_decision(
    "Recommend Product A",
    "User looking for laptop under $1000",
    ["Filtered by price", "Compared specs", "Checked reviews"]
)
</code></pre>
<h2 id="generalization"><a class="header" href="#generalization">Generalization</a></h2>
<h3 id="out-of-distribution-performance"><a class="header" href="#out-of-distribution-performance">Out-of-Distribution Performance</a></h3>
<p><strong>Challenge</strong>: Agents performing well on novel situations.</p>
<p><strong>Key Issues</strong>:</p>
<ul>
<li>Distribution shift</li>
<li>Novel scenarios</li>
<li>Transfer learning</li>
<li>Robustness</li>
</ul>
<pre><code class="language-python">class GeneralizationTester:
    """Test agent generalization"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def test_generalization(self, 
                           agent,
                           training_domain: str,
                           test_domains: List[str]) -&gt; Dict:
        """Test how well agent generalizes"""
        
        results = {}
        
        for domain in test_domains:
            # Generate test cases for domain
            test_cases = self.generate_test_cases(domain)
            
            # Test agent
            performance = self.evaluate_on_domain(agent, test_cases)
            
            results[domain] = performance
        
        return {
            "training_domain": training_domain,
            "test_results": results,
            "generalization_score": self.calculate_generalization_score(results)
        }
    
    def generate_test_cases(self, domain: str) -&gt; List[Dict]:
        """Generate test cases for domain"""
        
        prompt = f"""Generate 5 test cases for this domain:

Domain: {domain}

For each test case provide:
- Input
- Expected behavior
- Difficulty (easy/medium/hard)

Test cases:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6
        )
        
        return self.parse_test_cases(response.choices[0].message.content)
    
    def evaluate_on_domain(self, agent, test_cases: List[Dict]) -&gt; float:
        """Evaluate agent on test cases"""
        
        passed = 0
        for test in test_cases:
            try:
                result = agent.process(test["input"])
                if self.check_correctness(result, test["expected"]):
                    passed += 1
            except:
                pass
        
        return passed / len(test_cases) if test_cases else 0
    
    def calculate_generalization_score(self, results: Dict) -&gt; float:
        """Calculate overall generalization score"""
        scores = list(results.values())
        return sum(scores) / len(scores) if scores else 0

# Usage
tester = GeneralizationTester()
# results = tester.test_generalization(
#     agent,
#     training_domain="customer support",
#     test_domains=["technical support", "sales", "complaints"]
# )
</code></pre>
<h2 id="sample-efficiency"><a class="header" href="#sample-efficiency">Sample Efficiency</a></h2>
<h3 id="learning-from-limited-data"><a class="header" href="#learning-from-limited-data">Learning from Limited Data</a></h3>
<p><strong>Challenge</strong>: Agents learning effectively from few examples.</p>
<p><strong>Key Issues</strong>:</p>
<ul>
<li>Data scarcity</li>
<li>Cold start problem</li>
<li>Few-shot learning</li>
<li>Active learning</li>
</ul>
<pre><code class="language-python">class SampleEfficientLearner:
    """Learn efficiently from limited samples"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.examples = []
    
    def active_learning(self, 
                       unlabeled_data: List[str],
                       budget: int) -&gt; List[str]:
        """Select most informative examples to label"""
        
        # Score each example by informativeness
        scored = []
        for data in unlabeled_data:
            score = self.calculate_informativeness(data)
            scored.append((data, score))
        
        # Select top examples
        scored.sort(key=lambda x: x[1], reverse=True)
        selected = [data for data, score in scored[:budget]]
        
        return selected
    
    def calculate_informativeness(self, example: str) -&gt; float:
        """Calculate how informative an example would be"""
        
        prompt = f"""Rate how informative this example would be for learning (0-10):

Example: {example}

Current examples: {len(self.examples)}

Consider:
- Novelty
- Representativeness
- Difficulty
- Coverage of edge cases

Score:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        try:
            return float(response.choices[0].message.content.strip())
        except:
            return 5.0
    
    def meta_learn(self, tasks: List[Dict]) -&gt; Dict:
        """Learn how to learn from multiple tasks"""
        
        # Extract learning patterns across tasks
        patterns = []
        
        for task in tasks:
            pattern = self.extract_learning_pattern(task)
            patterns.append(pattern)
        
        # Synthesize meta-learning strategy
        strategy = self.synthesize_strategy(patterns)
        
        return {
            "patterns": patterns,
            "strategy": strategy
        }
    
    def extract_learning_pattern(self, task: Dict) -&gt; Dict:
        """Extract how learning occurred for task"""
        return {"task": task, "pattern": "extracted"}
    
    def synthesize_strategy(self, patterns: List[Dict]) -&gt; str:
        """Synthesize meta-learning strategy"""
        return "Meta-learning strategy"

# Usage
learner = SampleEfficientLearner()
selected = learner.active_learning(
    unlabeled_data=["example1", "example2", "example3"],
    budget=2
)
</code></pre>
<h2 id="research-directions"><a class="header" href="#research-directions">Research Directions</a></h2>
<h3 id="key-open-questions"><a class="header" href="#key-open-questions">Key Open Questions</a></h3>
<ol>
<li><strong>Alignment</strong>: How to ensure agents pursue intended goals?</li>
<li><strong>Interpretability</strong>: How to understand agent reasoning?</li>
<li><strong>Generalization</strong>: How to handle novel situations?</li>
<li><strong>Sample Efficiency</strong>: How to learn from less data?</li>
<li><strong>Robustness</strong>: How to handle adversarial inputs?</li>
<li><strong>Scalability</strong>: How to scale to complex tasks?</li>
<li><strong>Multi-agent Coordination</strong>: How agents collaborate?</li>
<li><strong>Long-term Planning</strong>: How to plan over extended horizons?</li>
<li><strong>Common Sense</strong>: How to encode common sense?</li>
<li><strong>Ethical Reasoning</strong>: How to make ethical decisions?</li>
</ol>
<h3 id="future-research-areas"><a class="header" href="#future-research-areas">Future Research Areas</a></h3>
<p><strong>Near-term (1-2 years)</strong>:</p>
<ul>
<li>Better tool use and creation</li>
<li>Improved multi-agent systems</li>
<li>Enhanced memory systems</li>
<li>More efficient learning</li>
</ul>
<p><strong>Medium-term (3-5 years)</strong>:</p>
<ul>
<li>Self-improving agents</li>
<li>Abstract reasoning</li>
<li>Long-horizon planning</li>
<li>Robust generalization</li>
</ul>
<p><strong>Long-term (5+ years)</strong>:</p>
<ul>
<li>General intelligence</li>
<li>Human-level reasoning</li>
<li>Autonomous research</li>
<li>Societal integration</li>
</ul>
<h2 id="contributing-to-research"><a class="header" href="#contributing-to-research">Contributing to Research</a></h2>
<h3 id="how-to-get-involved"><a class="header" href="#how-to-get-involved">How to Get Involved</a></h3>
<ol>
<li><strong>Read papers</strong>: Stay current with research</li>
<li><strong>Replicate results</strong>: Verify findings</li>
<li><strong>Open source</strong>: Share implementations</li>
<li><strong>Collaborate</strong>: Work with researchers</li>
<li><strong>Publish</strong>: Share your findings</li>
<li><strong>Attend conferences</strong>: NeurIPS, ICML, ICLR</li>
<li><strong>Join communities</strong>: Discord, forums</li>
<li><strong>Experiment</strong>: Try new ideas</li>
<li><strong>Document</strong>: Write about learnings</li>
<li><strong>Teach</strong>: Share knowledge</li>
</ol>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>Chapter 9 (Cutting-Edge Research) is complete! You now understand:</p>
<ul>
<li>Frontier capabilities (self-improvement, tool creation, abstract reasoning)</li>
<li>Emerging paradigms (constitutional AI, debate systems, neuro-symbolic)</li>
<li>Open problems (alignment, interpretability, generalization, sample efficiency)</li>
</ul>
<p>These are active research areas where significant breakthroughs are still needed. The field is rapidly evolving, and there are many opportunities to contribute.</p>
<p>Next: Module 10 - Capstone Project, where youâ€™ll apply everything youâ€™ve learned!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="design-your-agent"><a class="header" href="#design-your-agent">Design Your Agent</a></h1>
<h2 id="module-10-learning-objectives"><a class="header" href="#module-10-learning-objectives">Module 10: Learning Objectives</a></h2>
<p>By the end of this module, you will:</p>
<ul>
<li>âœ“ Design a complete autonomous software engineering agent</li>
<li>âœ“ Implement multi-agent orchestration with specialized roles</li>
<li>âœ“ Integrate all concepts from previous chapters</li>
<li>âœ“ Deploy a production-ready agent system</li>
<li>âœ“ Evaluate and iterate based on real-world testing</li>
</ul>
<hr>
<h2 id="capstone-project-autonomous-software-engineering-agent"><a class="header" href="#capstone-project-autonomous-software-engineering-agent">Capstone Project: Autonomous Software Engineering Agent</a></h2>
<p>Welcome to the capstone project! Youâ€™ll build a sophisticated agent that can analyze codebases, identify issues, propose fixes, write tests, and refactor code autonomously.</p>
<h2 id="project-overview-1"><a class="header" href="#project-overview-1">Project Overview</a></h2>
<h3 id="what-were-building"><a class="header" href="#what-were-building">What Weâ€™re Building</a></h3>
<p>An <strong>Autonomous Software Engineering Agent</strong> that can:</p>
<ul>
<li>Analyze code quality and identify bugs</li>
<li>Generate fixes with explanations</li>
<li>Write comprehensive tests</li>
<li>Refactor code for better maintainability</li>
<li>Review pull requests</li>
<li>Learn from feedback</li>
</ul>
<h3 id="why-this-project"><a class="header" href="#why-this-project">Why This Project?</a></h3>
<p>This capstone integrates nearly everything from the course:</p>
<ul>
<li><strong>ReAct pattern</strong> (Module 2): Reasoning and acting on code</li>
<li><strong>Planning</strong> (Module 3): Breaking down complex refactoring tasks</li>
<li><strong>Memory</strong> (Module 3): Remembering codebase patterns and past fixes</li>
<li><strong>Code execution</strong> (Module 4): Running and validating code</li>
<li><strong>Production patterns</strong> (Module 5): Safety, testing, monitoring</li>
<li><strong>Specialized agents</strong> (Module 6): Coding agent capabilities</li>
<li><strong>Learning</strong> (Module 7): Adapting from feedback</li>
<li><strong>Enterprise scale</strong> (Module 8): Handling large codebases</li>
<li><strong>Frontier capabilities</strong> (Module 9): Self-improvement, tool creation</li>
</ul>
<h2 id="requirements-gathering"><a class="header" href="#requirements-gathering">Requirements Gathering</a></h2>
<h3 id="functional-requirements"><a class="header" href="#functional-requirements">Functional Requirements</a></h3>
<p><strong>Core Capabilities</strong>:</p>
<ol>
<li><strong>Code Analysis</strong>: Parse and understand code structure</li>
<li><strong>Bug Detection</strong>: Identify potential issues</li>
<li><strong>Fix Generation</strong>: Propose and implement fixes</li>
<li><strong>Test Generation</strong>: Create comprehensive tests</li>
<li><strong>Refactoring</strong>: Improve code quality</li>
<li><strong>PR Review</strong>: Analyze changes and provide feedback</li>
</ol>
<p><strong>User Interactions</strong>:</p>
<ul>
<li>Natural language commands (â€œFix the bug in auth.pyâ€)</li>
<li>File/directory targeting</li>
<li>Interactive clarifications</li>
<li>Progress reporting</li>
<li>Explanation of changes</li>
</ul>
<h3 id="non-functional-requirements"><a class="header" href="#non-functional-requirements">Non-Functional Requirements</a></h3>
<p><strong>Performance</strong>:</p>
<ul>
<li>Analyze files &lt; 5 seconds</li>
<li>Generate fixes &lt; 30 seconds</li>
<li>Handle codebases up to 100K lines</li>
</ul>
<p><strong>Reliability</strong>:</p>
<ul>
<li>Never break working code</li>
<li>Validate all changes</li>
<li>Rollback capability</li>
<li>95%+ test coverage for generated code</li>
</ul>
<p><strong>Safety</strong>:</p>
<ul>
<li>Sandbox code execution</li>
<li>No destructive operations without confirmation</li>
<li>Backup before modifications</li>
<li>Security vulnerability checks</li>
</ul>
<p><strong>Usability</strong>:</p>
<ul>
<li>Clear explanations</li>
<li>Confidence scores</li>
<li>Alternative solutions</li>
<li>Learning from user feedback</li>
</ul>
<h2 id="architecture-design"><a class="header" href="#architecture-design">Architecture Design</a></h2>
<h3 id="high-level-architecture"><a class="header" href="#high-level-architecture">High-Level Architecture</a></h3>
<pre><code class="language-mermaid">graph TB
    UI[User Interface Layer]
    UI --&gt; ORC[Orchestration Layer]
    
    subgraph Orchestration
    ORC --&gt; PLAN[Planner]
    ORC --&gt; ROUTE[Router]
    ORC --&gt; MON[Monitor]
    end
    
    subgraph Agents
    ROUTE --&gt; ANA[Analyzer Agent]
    ROUTE --&gt; FIX[Fixer Agent]
    ROUTE --&gt; TEST[Tester Agent]
    ROUTE --&gt; REF[Refactorer Agent]
    ROUTE --&gt; REV[Reviewer Agent]
    end
    
    subgraph Tools
    ANA --&gt; AST[AST Parser]
    FIX --&gt; EXEC[Code Executor]
    TEST --&gt; RUNNER[Test Runner]
    AST --&gt; LINT[Linter]
    EXEC --&gt; GIT[Git Ops]
    end
    
    subgraph Storage
    MON --&gt; VDB[(Vector DB)]
    MON --&gt; CACHE[(Code Cache)]
    MON --&gt; FB[(Feedback DB)]
    end
    
    style UI fill:#dbeafe
    style ORC fill:#fef3c7
    style ANA fill:#d1fae5
    style FIX fill:#d1fae5
    style TEST fill:#d1fae5
</code></pre>
<h3 id="component-design"><a class="header" href="#component-design">Component Design</a></h3>
<p><strong>1. Orchestration Layer</strong></p>
<pre><code class="language-python">from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum

class TaskType(Enum):
    ANALYZE = "analyze"
    FIX_BUG = "fix_bug"
    WRITE_TEST = "write_test"
    REFACTOR = "refactor"
    REVIEW_PR = "review_pr"

@dataclass
class Task:
    type: TaskType
    target: str  # File or directory
    description: str
    priority: int
    dependencies: List[str]

class Orchestrator:
    """Coordinates multiple specialized agents"""
    
    def __init__(self):
        self.planner = TaskPlanner()
        self.router = AgentRouter()
        self.monitor = ProgressMonitor()
    
    def execute_request(self, request: str, context: Dict) -&gt; Dict:
        """Main entry point"""
        
        # Plan tasks
        tasks = self.planner.create_plan(request, context)
        
        # Execute tasks
        results = []
        for task in tasks:
            # Route to appropriate agent
            agent = self.router.get_agent(task.type)
            
            # Execute
            result = agent.execute(task)
            results.append(result)
            
            # Monitor progress
            self.monitor.update(task, result)
        
        # Synthesize results
        return self.synthesize_results(results)
</code></pre>
<p><strong>2. Agent Layer</strong></p>
<pre><code class="language-python">class AnalyzerAgent:
    """Analyzes code quality and identifies issues"""
    
    def execute(self, task: Task) -&gt; Dict:
        # Parse code
        # Run static analysis
        # Identify issues
        # Prioritize findings
        pass

class FixerAgent:
    """Generates and applies fixes"""
    
    def execute(self, task: Task) -&gt; Dict:
        # Understand issue
        # Generate fix
        # Validate fix
        # Apply changes
        pass

class TesterAgent:
    """Writes tests for code"""
    
    def execute(self, task: Task) -&gt; Dict:
        # Analyze code
        # Identify test cases
        # Generate tests
        # Validate coverage
        pass

class RefactorerAgent:
    """Refactors code for quality"""
    
    def execute(self, task: Task) -&gt; Dict:
        # Identify code smells
        # Plan refactoring
        # Apply transformations
        # Verify behavior preserved
        pass

class ReviewerAgent:
    """Reviews code changes"""
    
    def execute(self, task: Task) -&gt; Dict:
        # Analyze diff
        # Check for issues
        # Suggest improvements
        # Approve or request changes
        pass
</code></pre>
<p><strong>3. Tool Layer</strong></p>
<pre><code class="language-python">class CodeTools:
    """Low-level code manipulation tools"""
    
    def parse_ast(self, code: str, language: str) -&gt; Dict:
        """Parse code into AST"""
        pass
    
    def execute_code(self, code: str, test_input: any) -&gt; any:
        """Execute code safely"""
        pass
    
    def run_linter(self, file_path: str) -&gt; List[Dict]:
        """Run linter on code"""
        pass
    
    def format_code(self, code: str, language: str) -&gt; str:
        """Format code"""
        pass
    
    def run_tests(self, test_file: str) -&gt; Dict:
        """Run test suite"""
        pass
    
    def git_diff(self, file_path: str) -&gt; str:
        """Get git diff"""
        pass
</code></pre>
<h2 id="tool-selection"><a class="header" href="#tool-selection">Tool Selection</a></h2>
<h3 id="required-tools"><a class="header" href="#required-tools">Required Tools</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Tool</th><th>Purpose</th><th>Integration</th></tr>
</thead>
<tbody>
<tr><td>AST Parser</td><td>Code structure analysis</td><td><code>ast</code> (Python), <code>tree-sitter</code> (multi-lang)</td></tr>
<tr><td>Static Analyzer</td><td>Bug detection</td><td><code>pylint</code>, <code>mypy</code>, <code>ruff</code></td></tr>
<tr><td>Code Executor</td><td>Validation</td><td>Docker sandbox</td></tr>
<tr><td>Test Framework</td><td>Test generation/running</td><td><code>pytest</code>, <code>unittest</code></td></tr>
<tr><td>Git Integration</td><td>Version control</td><td><code>GitPython</code></td></tr>
<tr><td>Vector DB</td><td>Code search</td><td><code>chromadb</code>, <code>pinecone</code></td></tr>
<tr><td>LLM API</td><td>Reasoning</td><td>OpenAI, Anthropic</td></tr>
</tbody>
</table>
</div>
<h3 id="tool-integration-strategy"><a class="header" href="#tool-integration-strategy">Tool Integration Strategy</a></h3>
<pre><code class="language-python">class ToolRegistry:
    """Registry of available tools"""
    
    def __init__(self):
        self.tools = {
            "parse_code": {
                "function": self.parse_code,
                "description": "Parse code into AST",
                "parameters": {"code": "str", "language": "str"}
            },
            "run_linter": {
                "function": self.run_linter,
                "description": "Run static analysis",
                "parameters": {"file_path": "str"}
            },
            "execute_code": {
                "function": self.execute_code,
                "description": "Execute code safely",
                "parameters": {"code": "str", "timeout": "int"}
            },
            "run_tests": {
                "function": self.run_tests,
                "description": "Run test suite",
                "parameters": {"test_path": "str"}
            },
            "search_similar_code": {
                "function": self.search_similar_code,
                "description": "Find similar code patterns",
                "parameters": {"query": "str", "limit": "int"}
            }
        }
    
    def get_tool_schemas(self) -&gt; List[Dict]:
        """Get OpenAI function schemas"""
        return [
            {
                "name": name,
                "description": tool["description"],
                "parameters": {
                    "type": "object",
                    "properties": {
                        param: {"type": ptype}
                        for param, ptype in tool["parameters"].items()
                    },
                    "required": list(tool["parameters"].keys())
                }
            }
            for name, tool in self.tools.items()
        ]
</code></pre>
<h2 id="safety-considerations"><a class="header" href="#safety-considerations">Safety Considerations</a></h2>
<h3 id="critical-safety-measures"><a class="header" href="#critical-safety-measures">Critical Safety Measures</a></h3>
<p><strong>1. Code Execution Sandbox</strong></p>
<pre><code class="language-python">import docker

class SafeExecutor:
    """Execute code in isolated container"""
    
    def __init__(self):
        self.client = docker.from_env()
    
    def execute(self, code: str, timeout: int = 30) -&gt; Dict:
        """Execute with resource limits"""
        
        container = self.client.containers.run(
            "python:3.11-slim",
            command=f"python -c '{code}'",
            detach=True,
            mem_limit="256m",
            cpu_quota=50000,
            network_disabled=True,
            remove=True
        )
        
        try:
            result = container.wait(timeout=timeout)
            logs = container.logs().decode()
            return {"success": True, "output": logs}
        except:
            container.kill()
            return {"success": False, "error": "Timeout or error"}
</code></pre>
<p><strong>2. Change Validation</strong></p>
<pre><code class="language-python">class ChangeValidator:
    """Validate code changes before applying"""
    
    def validate(self, original: str, modified: str) -&gt; Dict:
        """Multi-level validation"""
        
        checks = {
            "syntax": self.check_syntax(modified),
            "tests_pass": self.run_tests(modified),
            "no_security_issues": self.check_security(modified),
            "behavior_preserved": self.verify_behavior(original, modified)
        }
        
        return {
            "valid": all(checks.values()),
            "checks": checks
        }
</code></pre>
<p><strong>3. Human-in-the-Loop</strong></p>
<pre><code class="language-python">class ApprovalGate:
    """Require human approval for critical changes"""
    
    def requires_approval(self, change: Dict) -&gt; bool:
        """Determine if change needs approval"""
        
        critical_patterns = [
            "delete", "drop", "remove",
            "auth", "security", "password",
            "production", "deploy"
        ]
        
        return any(pattern in change["description"].lower() 
                  for pattern in critical_patterns)
</code></pre>
<h2 id="success-metrics-1"><a class="header" href="#success-metrics-1">Success Metrics</a></h2>
<h3 id="key-performance-indicators"><a class="header" href="#key-performance-indicators">Key Performance Indicators</a></h3>
<p><strong>Accuracy Metrics</strong>:</p>
<ul>
<li>Bug detection rate (precision/recall)</li>
<li>Fix success rate (% that work)</li>
<li>Test coverage achieved</li>
<li>False positive rate</li>
</ul>
<p><strong>Efficiency Metrics</strong>:</p>
<ul>
<li>Time to analyze file</li>
<li>Time to generate fix</li>
<li>Lines of code processed per minute</li>
<li>Token usage per task</li>
</ul>
<p><strong>Quality Metrics</strong>:</p>
<ul>
<li>Code quality improvement (linter score)</li>
<li>Test pass rate</li>
<li>User acceptance rate</li>
<li>Regression rate (fixes that break things)</li>
</ul>
<h3 id="measurement-strategy"><a class="header" href="#measurement-strategy">Measurement Strategy</a></h3>
<pre><code class="language-python">class MetricsCollector:
    """Collect and track metrics"""
    
    def __init__(self):
        self.metrics = {
            "bugs_detected": 0,
            "fixes_applied": 0,
            "fixes_successful": 0,
            "tests_generated": 0,
            "avg_analysis_time": [],
            "user_approvals": 0,
            "user_rejections": 0
        }
    
    def record_analysis(self, duration: float, bugs_found: int):
        """Record analysis metrics"""
        self.metrics["avg_analysis_time"].append(duration)
        self.metrics["bugs_detected"] += bugs_found
    
    def record_fix(self, success: bool):
        """Record fix attempt"""
        self.metrics["fixes_applied"] += 1
        if success:
            self.metrics["fixes_successful"] += 1
    
    def get_success_rate(self) -&gt; float:
        """Calculate fix success rate"""
        if self.metrics["fixes_applied"] == 0:
            return 0.0
        return self.metrics["fixes_successful"] / self.metrics["fixes_applied"]
</code></pre>
<h2 id="data-flow-design"><a class="header" href="#data-flow-design">Data Flow Design</a></h2>
<h3 id="request-processing-flow"><a class="header" href="#request-processing-flow">Request Processing Flow</a></h3>
<pre><code>User Request
    â†“
Parse Intent
    â†“
Create Plan (Task Decomposition)
    â†“
For each task:
    â†“
    Route to Specialized Agent
    â†“
    Execute with Tools
    â†“
    Validate Results
    â†“
    Store in Memory
    â†“
Synthesize Results
    â†“
Present to User
    â†“
Collect Feedback
    â†“
Update Models
</code></pre>
<h3 id="state-management-1"><a class="header" href="#state-management-1">State Management</a></h3>
<pre><code class="language-python">from dataclasses import dataclass
from typing import Optional
import json

@dataclass
class AgentState:
    """Current state of the agent"""
    current_task: Optional[Task]
    task_history: List[Dict]
    codebase_context: Dict
    user_preferences: Dict
    performance_metrics: Dict

class StateManager:
    """Manage agent state"""
    
    def __init__(self, state_file: str = "agent_state.json"):
        self.state_file = state_file
        self.state = self.load_state()
    
    def load_state(self) -&gt; AgentState:
        """Load state from disk"""
        try:
            with open(self.state_file, 'r') as f:
                data = json.load(f)
                return AgentState(**data)
        except:
            return AgentState(
                current_task=None,
                task_history=[],
                codebase_context={},
                user_preferences={},
                performance_metrics={}
            )
    
    def save_state(self):
        """Persist state to disk"""
        with open(self.state_file, 'w') as f:
            json.dump(self.state.__dict__, f, indent=2)
    
    def update_context(self, file_path: str, analysis: Dict):
        """Update codebase context"""
        self.state.codebase_context[file_path] = analysis
        self.save_state()
</code></pre>
<h2 id="memory-architecture"><a class="header" href="#memory-architecture">Memory Architecture</a></h2>
<h3 id="multi-level-memory-system"><a class="header" href="#multi-level-memory-system">Multi-Level Memory System</a></h3>
<p><strong>1. Working Memory</strong>: Current task context</p>
<pre><code class="language-python">class WorkingMemory:
    """Short-term task context"""
    
    def __init__(self, max_size: int = 10):
        self.max_size = max_size
        self.items = []
    
    def add(self, item: Dict):
        """Add to working memory"""
        self.items.append(item)
        if len(self.items) &gt; self.max_size:
            self.items.pop(0)
    
    def get_context(self) -&gt; str:
        """Get context for LLM"""
        return "\n".join([
            f"- {item['type']}: {item['content']}"
            for item in self.items
        ])
</code></pre>
<p><strong>2. Episodic Memory</strong>: Past tasks and solutions</p>
<pre><code class="language-python">class EpisodicMemory:
    """Remember past tasks"""
    
    def __init__(self):
        self.episodes = []
    
    def store_episode(self, task: Task, solution: Dict, outcome: Dict):
        """Store completed task"""
        self.episodes.append({
            "task": task,
            "solution": solution,
            "outcome": outcome,
            "timestamp": time.time()
        })
    
    def recall_similar(self, current_task: Task, limit: int = 5) -&gt; List[Dict]:
        """Recall similar past tasks"""
        # Use embedding similarity
        return self.episodes[-limit:]
</code></pre>
<p><strong>3. Semantic Memory</strong>: Codebase knowledge</p>
<pre><code class="language-python">import chromadb

class SemanticMemory:
    """Long-term codebase knowledge"""
    
    def __init__(self):
        self.client = chromadb.Client()
        self.collection = self.client.create_collection("codebase")
    
    def index_codebase(self, files: List[str]):
        """Index codebase for semantic search"""
        for file_path in files:
            with open(file_path, 'r') as f:
                code = f.read()
            
            self.collection.add(
                documents=[code],
                metadatas=[{"file_path": file_path}],
                ids=[file_path]
            )
    
    def search(self, query: str, n_results: int = 5) -&gt; List[Dict]:
        """Search for relevant code"""
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results
        )
        return results
</code></pre>
<h2 id="error-handling-strategy"><a class="header" href="#error-handling-strategy">Error Handling Strategy</a></h2>
<h3 id="graceful-degradation-1"><a class="header" href="#graceful-degradation-1">Graceful Degradation</a></h3>
<pre><code class="language-python">class RobustAgent:
    """Agent with comprehensive error handling"""
    
    def execute_with_fallbacks(self, task: Task) -&gt; Dict:
        """Execute with multiple fallback strategies"""
        
        strategies = [
            self.primary_strategy,
            self.simplified_strategy,
            self.conservative_strategy
        ]
        
        for strategy in strategies:
            try:
                result = strategy(task)
                if self.validate_result(result):
                    return result
            except Exception as e:
                self.log_error(strategy.__name__, e)
                continue
        
        return {
            "success": False,
            "error": "All strategies failed",
            "recommendation": "Manual intervention required"
        }
</code></pre>
<h2 id="design-decisions"><a class="header" href="#design-decisions">Design Decisions</a></h2>
<h3 id="key-choices"><a class="header" href="#key-choices">Key Choices</a></h3>
<p><strong>1. Multi-Agent vs Single Agent</strong></p>
<ul>
<li><strong>Choice</strong>: Multi-agent with specialized roles</li>
<li><strong>Rationale</strong>: Better separation of concerns, easier to test, more maintainable</li>
</ul>
<p><strong>2. Synchronous vs Asynchronous</strong></p>
<ul>
<li><strong>Choice</strong>: Asynchronous for I/O operations</li>
<li><strong>Rationale</strong>: Better performance, can analyze multiple files in parallel</li>
</ul>
<p><strong>3. Local vs Cloud Execution</strong></p>
<ul>
<li><strong>Choice</strong>: Hybrid (local analysis, cloud LLM)</li>
<li><strong>Rationale</strong>: Security for code, power for reasoning</li>
</ul>
<p><strong>4. Automatic vs Interactive</strong></p>
<ul>
<li><strong>Choice</strong>: Interactive with automatic mode option</li>
<li><strong>Rationale</strong>: Safety for critical changes, speed for routine tasks</li>
</ul>
<p><strong>5. Learning Strategy</strong></p>
<ul>
<li><strong>Choice</strong>: Few-shot + feedback learning</li>
<li><strong>Rationale</strong>: Fast adaptation without full retraining</li>
</ul>
<hr>
<blockquote>
<p><strong>âœ… Key Takeaways</strong></p>
<ul>
<li>Design requires balancing functional and non-functional requirements</li>
<li>Multi-agent architecture provides separation of concerns</li>
<li>Safety mechanisms are critical for code-modifying agents</li>
<li>Memory systems enable learning from past experiences</li>
<li>Tool selection impacts capabilities and complexity</li>
<li>Architecture decisions should align with use case constraints</li>
</ul>
</blockquote>
<h2 id="next-steps-23"><a class="header" href="#next-steps-23">Next Steps</a></h2>
<p>Now that we have the design, letâ€™s implement the Autonomous Software Engineering Agent!</p>
<p>In the next section, youâ€™ll build:</p>
<ul>
<li>Complete working implementation</li>
<li>All specialized agents</li>
<li>Tool integrations</li>
<li>Safety mechanisms</li>
<li>Real-world examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="implementation"><a class="header" href="#implementation">Implementation</a></h1>
<h2 id="building-the-autonomous-software-engineering-agent"><a class="header" href="#building-the-autonomous-software-engineering-agent">Building the Autonomous Software Engineering Agent</a></h2>
<p>Letâ€™s build the complete system step by step.</p>
<h2 id="project-setup-1"><a class="header" href="#project-setup-1">Project Setup</a></h2>
<pre><code class="language-bash"># Create project structure
mkdir autonomous-se-agent
cd autonomous-se-agent

# Create directories
mkdir -p src/{agents,tools,memory,orchestration}
mkdir -p tests
mkdir -p data/{cache,feedback}

# Install dependencies
pip install openai chromadb gitpython docker pytest pylint black ast-grep-py
</code></pre>
<h2 id="core-implementation"><a class="header" href="#core-implementation">Core Implementation</a></h2>
<h3 id="1-main-orchestrator"><a class="header" href="#1-main-orchestrator">1. Main Orchestrator</a></h3>
<pre><code class="language-python"># src/orchestration/orchestrator.py
from typing import Dict, List
from dataclasses import dataclass
from enum import Enum
import openai

class TaskType(Enum):
    ANALYZE = "analyze"
    FIX = "fix"
    TEST = "test"
    REFACTOR = "refactor"
    REVIEW = "review"

@dataclass
class Task:
    type: TaskType
    target: str
    description: str
    context: Dict

class SoftwareEngineeringAgent:
    """Main orchestrator for autonomous SE agent"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.analyzer = AnalyzerAgent()
        self.fixer = FixerAgent()
        self.tester = TesterAgent()
        self.memory = AgentMemory()
    
    def process_request(self, request: str, target_path: str) -&gt; Dict:
        """Process user request"""
        
        # Parse intent
        intent = self.parse_intent(request)
        
        # Create plan
        plan = self.create_plan(intent, target_path)
        
        # Execute plan
        results = self.execute_plan(plan)
        
        # Store in memory
        self.memory.store_episode(request, plan, results)
        
        return results
    
    def parse_intent(self, request: str) -&gt; Dict:
        """Parse user intent"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "system",
                "content": "Parse user intent. Return JSON with: task_type, target, requirements"
            }, {
                "role": "user",
                "content": request
            }],
            temperature=0.2
        )
        
        import json
        return json.loads(response.choices[0].message.content)
    
    def create_plan(self, intent: Dict, target_path: str) -&gt; List[Task]:
        """Create execution plan"""
        
        tasks = []
        task_type = TaskType(intent["task_type"])
        
        if task_type == TaskType.FIX:
            # Fix requires: analyze -&gt; fix -&gt; test
            tasks.append(Task(TaskType.ANALYZE, target_path, "Analyze code", {}))
            tasks.append(Task(TaskType.FIX, target_path, intent["requirements"], {}))
            tasks.append(Task(TaskType.TEST, target_path, "Validate fix", {}))
        
        elif task_type == TaskType.REFACTOR:
            # Refactor requires: analyze -&gt; refactor -&gt; test
            tasks.append(Task(TaskType.ANALYZE, target_path, "Analyze code", {}))
            tasks.append(Task(TaskType.REFACTOR, target_path, intent["requirements"], {}))
            tasks.append(Task(TaskType.TEST, target_path, "Validate refactor", {}))
        
        else:
            tasks.append(Task(task_type, target_path, intent["requirements"], {}))
        
        return tasks
    
    def execute_plan(self, plan: List[Task]) -&gt; Dict:
        """Execute task plan"""
        
        results = []
        context = {}
        
        for task in plan:
            task.context = context
            
            if task.type == TaskType.ANALYZE:
                result = self.analyzer.execute(task)
            elif task.type == TaskType.FIX:
                result = self.fixer.execute(task)
            elif task.type == TaskType.TEST:
                result = self.tester.execute(task)
            else:
                result = {"error": "Unknown task type"}
            
            results.append(result)
            context.update(result)
        
        return {"tasks": len(plan), "results": results}
</code></pre>
<h3 id="2-analyzer-agent"><a class="header" href="#2-analyzer-agent">2. Analyzer Agent</a></h3>
<pre><code class="language-python"># src/agents/analyzer.py
import ast
from typing import Dict, List

class AnalyzerAgent:
    """Analyzes code for issues"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def execute(self, task: Task) -&gt; Dict:
        """Analyze code file"""
        
        # Read code
        with open(task.target, 'r') as f:
            code = f.read()
        
        # Parse AST
        ast_analysis = self.analyze_ast(code)
        
        # Run static analysis
        static_issues = self.run_static_analysis(task.target)
        
        # LLM-based analysis
        llm_analysis = self.llm_analyze(code)
        
        return {
            "file": task.target,
            "ast_analysis": ast_analysis,
            "static_issues": static_issues,
            "llm_analysis": llm_analysis,
            "issues": self.consolidate_issues(static_issues, llm_analysis)
        }
    
    def analyze_ast(self, code: str) -&gt; Dict:
        """Analyze code structure"""
        
        try:
            tree = ast.parse(code)
            
            functions = [node.name for node in ast.walk(tree) 
                        if isinstance(node, ast.FunctionDef)]
            classes = [node.name for node in ast.walk(tree) 
                      if isinstance(node, ast.ClassDef)]
            
            return {
                "functions": functions,
                "classes": classes,
                "lines": len(code.split('\n'))
            }
        except SyntaxError as e:
            return {"error": str(e)}
    
    def run_static_analysis(self, file_path: str) -&gt; List[Dict]:
        """Run pylint"""
        
        import subprocess
        
        result = subprocess.run(
            ['pylint', file_path, '--output-format=json'],
            capture_output=True,
            text=True
        )
        
        import json
        try:
            return json.loads(result.stdout)
        except:
            return []
    
    def llm_analyze(self, code: str) -&gt; Dict:
        """LLM-based code analysis"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "system",
                "content": "You are an expert code reviewer. Analyze code for bugs, security issues, and improvements."
            }, {
                "role": "user",
                "content": f"Analyze this code:\n\n{code}"
            }],
            temperature=0.3
        )
        
        return {"analysis": response.choices[0].message.content}
    
    def consolidate_issues(self, static: List[Dict], llm: Dict) -&gt; List[Dict]:
        """Consolidate all issues"""
        
        issues = []
        
        # Add static analysis issues
        for issue in static:
            issues.append({
                "type": issue.get("type", "unknown"),
                "message": issue.get("message", ""),
                "line": issue.get("line", 0),
                "severity": issue.get("severity", "info"),
                "source": "static"
            })
        
        return issues
</code></pre>
<h3 id="3-fixer-agent"><a class="header" href="#3-fixer-agent">3. Fixer Agent</a></h3>
<pre><code class="language-python"># src/agents/fixer.py
from typing import Dict
import difflib

class FixerAgent:
    """Generates and applies fixes"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.validator = FixValidator()
    
    def execute(self, task: Task) -&gt; Dict:
        """Generate and apply fix"""
        
        # Read current code
        with open(task.target, 'r') as f:
            original_code = f.read()
        
        # Get issues from context
        issues = task.context.get("issues", [])
        
        # Generate fix
        fixed_code = self.generate_fix(original_code, issues, task.description)
        
        # Validate fix
        validation = self.validator.validate(original_code, fixed_code)
        
        if not validation["valid"]:
            return {
                "success": False,
                "error": "Validation failed",
                "details": validation
            }
        
        # Show diff
        diff = self.generate_diff(original_code, fixed_code)
        
        return {
            "success": True,
            "original_code": original_code,
            "fixed_code": fixed_code,
            "diff": diff,
            "validation": validation
        }
    
    def generate_fix(self, code: str, issues: List[Dict], description: str) -&gt; str:
        """Generate fixed code"""
        
        issues_text = "\n".join([
            f"- Line {i['line']}: {i['message']}"
            for i in issues[:5]  # Top 5 issues
        ])
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "system",
                "content": "You are an expert programmer. Fix code issues while preserving functionality."
            }, {
                "role": "user",
                "content": f"Fix these issues:\n{issues_text}\n\nRequirement: {description}\n\nOriginal code:\n{code}\n\nFixed code:"
            }],
            temperature=0.2
        )
        
        return self.extract_code(response.choices[0].message.content)
    
    def generate_diff(self, original: str, fixed: str) -&gt; str:
        """Generate unified diff"""
        
        diff = difflib.unified_diff(
            original.splitlines(keepends=True),
            fixed.splitlines(keepends=True),
            fromfile='original',
            tofile='fixed'
        )
        
        return ''.join(diff)
    
    def extract_code(self, text: str) -&gt; str:
        """Extract code from markdown"""
        import re
        pattern = r'```python\n(.*?)```'
        matches = re.findall(pattern, text, re.DOTALL)
        return matches[0] if matches else text

class FixValidator:
    """Validate fixes"""
    
    def validate(self, original: str, fixed: str) -&gt; Dict:
        """Multi-level validation"""
        
        return {
            "valid": self.check_syntax(fixed) and self.check_safety(fixed),
            "syntax_valid": self.check_syntax(fixed),
            "safety_passed": self.check_safety(fixed)
        }
    
    def check_syntax(self, code: str) -&gt; bool:
        """Check syntax"""
        try:
            ast.parse(code)
            return True
        except:
            return False
    
    def check_safety(self, code: str) -&gt; bool:
        """Check for unsafe patterns"""
        unsafe = ["eval(", "exec(", "__import__", "os.system"]
        return not any(pattern in code for pattern in unsafe)
</code></pre>
<h3 id="4-tester-agent"><a class="header" href="#4-tester-agent">4. Tester Agent</a></h3>
<pre><code class="language-python"># src/agents/tester.py
from typing import Dict, List

class TesterAgent:
    """Generates and runs tests"""
    
    def __init__(self):
        self.client = openai.OpenAI()
    
    def execute(self, task: Task) -&gt; Dict:
        """Generate tests for code"""
        
        # Read code
        with open(task.target, 'r') as f:
            code = f.read()
        
        # Generate tests
        tests = self.generate_tests(code)
        
        # Run tests
        results = self.run_tests(tests)
        
        return {
            "tests_generated": len(tests),
            "tests_passed": sum(1 for r in results if r["passed"]),
            "coverage": self.calculate_coverage(code, tests),
            "test_code": tests
        }
    
    def generate_tests(self, code: str) -&gt; str:
        """Generate test code"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "system",
                "content": "Generate comprehensive pytest tests. Include edge cases, error cases, and normal cases."
            }, {
                "role": "user",
                "content": f"Generate tests for:\n\n{code}"
            }],
            temperature=0.3
        )
        
        return response.choices[0].message.content
    
    def run_tests(self, test_code: str) -&gt; List[Dict]:
        """Run generated tests"""
        
        # Write to temp file
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(test_code)
            test_file = f.name
        
        # Run pytest
        import subprocess
        result = subprocess.run(
            ['pytest', test_file, '-v', '--json-report'],
            capture_output=True
        )
        
        return [{"passed": result.returncode == 0}]
    
    def calculate_coverage(self, code: str, tests: str) -&gt; float:
        """Estimate test coverage"""
        # Simplified coverage estimation
        return 0.85
</code></pre>
<h3 id="5-memory-system"><a class="header" href="#5-memory-system">5. Memory System</a></h3>
<pre><code class="language-python"># src/memory/agent_memory.py
import chromadb
from typing import Dict, List
import json

class AgentMemory:
    """Unified memory system"""
    
    def __init__(self):
        self.working_memory = []
        self.client = chromadb.Client()
        self.episodes = self.client.create_collection("episodes")
        self.codebase = self.client.create_collection("codebase")
    
    def store_episode(self, request: str, plan: List[Task], results: Dict):
        """Store completed episode"""
        
        episode = {
            "request": request,
            "plan": [{"type": t.type.value, "target": t.target} for t in plan],
            "results": results,
            "success": results.get("success", False)
        }
        
        self.episodes.add(
            documents=[json.dumps(episode)],
            metadatas=[{"request": request}],
            ids=[f"episode_{len(self.episodes.get()['ids'])}"]
        )
    
    def recall_similar_episodes(self, request: str, limit: int = 3) -&gt; List[Dict]:
        """Recall similar past episodes"""
        
        results = self.episodes.query(
            query_texts=[request],
            n_results=limit
        )
        
        return [json.loads(doc) for doc in results['documents'][0]]
    
    def index_file(self, file_path: str, code: str, analysis: Dict):
        """Index file in semantic memory"""
        
        self.codebase.add(
            documents=[code],
            metadatas=[{
                "file_path": file_path,
                "functions": json.dumps(analysis.get("functions", [])),
                "classes": json.dumps(analysis.get("classes", []))
            }],
            ids=[file_path]
        )
    
    def search_codebase(self, query: str, limit: int = 5) -&gt; List[Dict]:
        """Search codebase semantically"""
        
        results = self.codebase.query(
            query_texts=[query],
            n_results=limit
        )
        
        return results
</code></pre>
<h3 id="6-tool-layer"><a class="header" href="#6-tool-layer">6. Tool Layer</a></h3>
<pre><code class="language-python"># src/tools/code_tools.py
import ast
import subprocess
from typing import Dict, List

class CodeTools:
    """Low-level code manipulation tools"""
    
    @staticmethod
    def parse_python(code: str) -&gt; Dict:
        """Parse Python code"""
        
        try:
            tree = ast.parse(code)
            
            return {
                "valid": True,
                "functions": [n.name for n in ast.walk(tree) if isinstance(n, ast.FunctionDef)],
                "classes": [n.name for n in ast.walk(tree) if isinstance(n, ast.ClassDef)],
                "imports": [n.names[0].name for n in ast.walk(tree) if isinstance(n, ast.Import)]
            }
        except SyntaxError as e:
            return {"valid": False, "error": str(e)}
    
    @staticmethod
    def run_linter(file_path: str) -&gt; List[Dict]:
        """Run pylint"""
        
        result = subprocess.run(
            ['pylint', file_path, '--output-format=json'],
            capture_output=True,
            text=True
        )
        
        import json
        try:
            return json.loads(result.stdout)
        except:
            return []
    
    @staticmethod
    def format_code(code: str) -&gt; str:
        """Format with black"""
        
        result = subprocess.run(
            ['black', '-'],
            input=code,
            capture_output=True,
            text=True
        )
        
        return result.stdout if result.returncode == 0 else code
    
    @staticmethod
    def run_tests(test_path: str) -&gt; Dict:
        """Run pytest"""
        
        result = subprocess.run(
            ['pytest', test_path, '-v'],
            capture_output=True,
            text=True
        )
        
        return {
            "passed": result.returncode == 0,
            "output": result.stdout
        }

class SafeExecutor:
    """Execute code safely in Docker"""
    
    def __init__(self):
        import docker
        self.client = docker.from_env()
    
    def execute(self, code: str, timeout: int = 30) -&gt; Dict:
        """Execute in isolated container"""
        
        try:
            container = self.client.containers.run(
                "python:3.11-slim",
                command=['python', '-c', code],
                detach=True,
                mem_limit="256m",
                network_disabled=True,
                remove=True
            )
            
            result = container.wait(timeout=timeout)
            logs = container.logs().decode()
            
            return {"success": True, "output": logs, "exit_code": result['StatusCode']}
            
        except Exception as e:
            return {"success": False, "error": str(e)}
</code></pre>
<h3 id="7-complete-agent-implementation"><a class="header" href="#7-complete-agent-implementation">7. Complete Agent Implementation</a></h3>
<pre><code class="language-python"># src/agents/fixer.py (complete version)
from typing import Dict, List
import openai

class FixerAgent:
    """Generates and applies fixes"""
    
    def __init__(self):
        self.client = openai.OpenAI()
        self.tools = CodeTools()
    
    def execute(self, task: Task) -&gt; Dict:
        """Generate fix for issues"""
        
        # Read code
        with open(task.target, 'r') as f:
            original_code = f.read()
        
        # Get issues from context
        issues = task.context.get("issues", [])
        
        # Retrieve similar fixes from memory
        similar_fixes = self.recall_similar_fixes(issues)
        
        # Generate fix with context
        fixed_code = self.generate_fix(
            original_code, 
            issues, 
            task.description,
            similar_fixes
        )
        
        # Validate
        if not self.validate_fix(original_code, fixed_code):
            return {"success": False, "error": "Validation failed"}
        
        # Generate explanation
        explanation = self.explain_fix(original_code, fixed_code, issues)
        
        return {
            "success": True,
            "original_code": original_code,
            "fixed_code": fixed_code,
            "explanation": explanation,
            "issues_addressed": len(issues)
        }
    
    def generate_fix(self, 
                    code: str, 
                    issues: List[Dict],
                    description: str,
                    similar_fixes: List[Dict]) -&gt; str:
        """Generate fixed code"""
        
        issues_text = "\n".join([
            f"- Line {i['line']}: {i['message']} (severity: {i['severity']})"
            for i in issues[:10]
        ])
        
        context_text = ""
        if similar_fixes:
            context_text = "\n\nSimilar fixes from history:\n" + "\n".join([
                f"- {fix['description']}: {fix['approach']}"
                for fix in similar_fixes[:3]
            ])
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "system",
                "content": "Fix code issues while preserving functionality. Return only the fixed code."
            }, {
                "role": "user",
                "content": f"Issues:\n{issues_text}\n\nRequirement: {description}{context_text}\n\nCode:\n{code}\n\nFixed code:"
            }],
            temperature=0.2
        )
        
        return self.extract_code(response.choices[0].message.content)
    
    def validate_fix(self, original: str, fixed: str) -&gt; bool:
        """Validate fix"""
        
        # Check syntax
        parsed = self.tools.parse_python(fixed)
        if not parsed["valid"]:
            return False
        
        # Check no unsafe operations
        unsafe = ["eval(", "exec(", "os.system"]
        if any(op in fixed for op in unsafe):
            return False
        
        return True
    
    def explain_fix(self, original: str, fixed: str, issues: List[Dict]) -&gt; str:
        """Explain what was fixed"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"Explain changes:\n\nOriginal:\n{original[:500]}\n\nFixed:\n{fixed[:500]}\n\nIssues addressed: {len(issues)}"
            }],
            temperature=0.3
        )
        
        return response.choices[0].message.content
    
    def recall_similar_fixes(self, issues: List[Dict]) -&gt; List[Dict]:
        """Recall similar fixes from memory"""
        # Simplified - would use vector search
        return []
    
    def extract_code(self, text: str) -&gt; str:
        """Extract code from response"""
        import re
        pattern = r'```python\n(.*?)```'
        matches = re.findall(pattern, text, re.DOTALL)
        return matches[0] if matches else text
</code></pre>
<h3 id="8-cli-interface"><a class="header" href="#8-cli-interface">8. CLI Interface</a></h3>
<pre><code class="language-python"># src/cli.py
import click
from orchestration.orchestrator import SoftwareEngineeringAgent

@click.group()
def cli():
    """Autonomous Software Engineering Agent"""
    pass

@cli.command()
@click.argument('file_path')
def analyze(file_path):
    """Analyze code file"""
    agent = SoftwareEngineeringAgent()
    result = agent.process_request(f"Analyze {file_path}", file_path)
    click.echo(json.dumps(result, indent=2))

@cli.command()
@click.argument('file_path')
@click.option('--description', '-d', help='Fix description')
def fix(file_path, description):
    """Fix issues in code"""
    agent = SoftwareEngineeringAgent()
    result = agent.process_request(
        f"Fix issues: {description}" if description else "Fix all issues",
        file_path
    )
    
    if result['results'][-1]['success']:
        click.echo("âœ“ Fix generated successfully")
        click.echo("\nDiff:")
        click.echo(result['results'][-1]['diff'])
    else:
        click.echo("âœ— Fix failed")

@cli.command()
@click.argument('file_path')
def test(file_path):
    """Generate tests"""
    agent = SoftwareEngineeringAgent()
    result = agent.process_request(f"Generate tests for {file_path}", file_path)
    click.echo(f"Generated {result['results'][0]['tests_generated']} tests")

if __name__ == '__main__':
    cli()
</code></pre>
<h2 id="usage-examples"><a class="header" href="#usage-examples">Usage Examples</a></h2>
<h3 id="example-1-analyze-and-fix"><a class="header" href="#example-1-analyze-and-fix">Example 1: Analyze and Fix</a></h3>
<pre><code class="language-bash"># Analyze code
python src/cli.py analyze src/example.py

# Fix issues
python src/cli.py fix src/example.py --description "Fix type errors and add error handling"

# Generate tests
python src/cli.py test src/example.py
</code></pre>
<h3 id="example-2-programmatic-usage"><a class="header" href="#example-2-programmatic-usage">Example 2: Programmatic Usage</a></h3>
<pre><code class="language-python">from orchestration.orchestrator import SoftwareEngineeringAgent

# Initialize agent
agent = SoftwareEngineeringAgent()

# Analyze code
result = agent.process_request(
    "Analyze this file for bugs and security issues",
    "src/auth.py"
)

print(f"Found {len(result['results'][0]['issues'])} issues")

# Fix critical issues
fix_result = agent.process_request(
    "Fix all critical and high severity issues",
    "src/auth.py"
)

if fix_result['results'][-1]['success']:
    print("Fix applied successfully")
    print(fix_result['results'][-1]['explanation'])
</code></pre>
<h2 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h2>
<h3 id="learning-from-feedback-1"><a class="header" href="#learning-from-feedback-1">Learning from Feedback</a></h3>
<pre><code class="language-python">class FeedbackLearner:
    """Learn from user feedback"""
    
    def __init__(self):
        self.feedback_db = []
    
    def collect_feedback(self, task: Task, result: Dict, user_rating: int):
        """Collect user feedback"""
        
        self.feedback_db.append({
            "task": task,
            "result": result,
            "rating": user_rating,
            "timestamp": time.time()
        })
    
    def improve_from_feedback(self):
        """Analyze feedback and improve"""
        
        # Identify patterns in low-rated results
        low_rated = [f for f in self.feedback_db if f["rating"] &lt; 3]
        
        # Extract common issues
        # Adjust prompts or strategies
        # Update tool selection logic
        pass
</code></pre>
<h3 id="parallel-processing"><a class="header" href="#parallel-processing">Parallel Processing</a></h3>
<pre><code class="language-python">import asyncio
from typing import List

class ParallelAnalyzer:
    """Analyze multiple files in parallel"""
    
    async def analyze_files(self, file_paths: List[str]) -&gt; List[Dict]:
        """Analyze files concurrently"""
        
        tasks = [self.analyze_file(path) for path in file_paths]
        results = await asyncio.gather(*tasks)
        
        return results
    
    async def analyze_file(self, file_path: str) -&gt; Dict:
        """Analyze single file"""
        
        analyzer = AnalyzerAgent()
        task = Task(TaskType.ANALYZE, file_path, "Analyze", {})
        
        return analyzer.execute(task)

# Usage
async def main():
    analyzer = ParallelAnalyzer()
    results = await analyzer.analyze_files(['file1.py', 'file2.py', 'file3.py'])
    print(f"Analyzed {len(results)} files")

asyncio.run(main())
</code></pre>
<h2 id="testing-the-agent"><a class="header" href="#testing-the-agent">Testing the Agent</a></h2>
<h3 id="unit-tests"><a class="header" href="#unit-tests">Unit Tests</a></h3>
<pre><code class="language-python"># tests/test_analyzer.py
import pytest
from agents.analyzer import AnalyzerAgent
from orchestration.orchestrator import Task, TaskType

def test_analyzer_detects_issues():
    """Test analyzer finds issues"""
    
    agent = AnalyzerAgent()
    
    # Create test task
    task = Task(
        type=TaskType.ANALYZE,
        target="tests/fixtures/buggy_code.py",
        description="Analyze",
        context={}
    )
    
    result = agent.execute(task)
    
    assert "issues" in result
    assert len(result["issues"]) &gt; 0

def test_analyzer_handles_syntax_errors():
    """Test analyzer handles invalid syntax"""
    
    agent = AnalyzerAgent()
    
    # Write invalid code
    with open("tests/fixtures/invalid.py", "w") as f:
        f.write("def broken(\n")
    
    task = Task(TaskType.ANALYZE, "tests/fixtures/invalid.py", "Analyze", {})
    result = agent.execute(task)
    
    assert "error" in result["ast_analysis"]
</code></pre>
<h3 id="integration-tests-1"><a class="header" href="#integration-tests-1">Integration Tests</a></h3>
<pre><code class="language-python"># tests/test_integration.py
import pytest
from orchestration.orchestrator import SoftwareEngineeringAgent

def test_end_to_end_fix():
    """Test complete fix workflow"""
    
    agent = SoftwareEngineeringAgent()
    
    # Create buggy code
    buggy_code = '''
def divide(a, b):
    return a / b
'''
    
    with open("tests/fixtures/buggy.py", "w") as f:
        f.write(buggy_code)
    
    # Request fix
    result = agent.process_request(
        "Fix the division by zero bug",
        "tests/fixtures/buggy.py"
    )
    
    # Verify fix was generated
    assert result["results"][-1]["success"]
    assert "if b == 0" in result["results"][-1]["fixed_code"]
</code></pre>
<h2 id="deployment"><a class="header" href="#deployment">Deployment</a></h2>
<h3 id="docker-container"><a class="header" href="#docker-container">Docker Container</a></h3>
<pre><code class="language-dockerfile"># Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt

# Copy source
COPY src/ ./src/

# Expose API
EXPOSE 8000

CMD ["python", "-m", "uvicorn", "src.api:app", "--host", "0.0.0.0"]
</code></pre>
<h3 id="api-service"><a class="header" href="#api-service">API Service</a></h3>
<pre><code class="language-python"># src/api.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(title="Autonomous SE Agent API")

class AnalyzeRequest(BaseModel):
    file_path: str
    options: Dict = {}

class FixRequest(BaseModel):
    file_path: str
    description: str

@app.post("/analyze")
async def analyze_code(request: AnalyzeRequest):
    """Analyze code endpoint"""
    
    agent = SoftwareEngineeringAgent()
    result = agent.process_request(
        f"Analyze {request.file_path}",
        request.file_path
    )
    
    return result

@app.post("/fix")
async def fix_code(request: FixRequest):
    """Fix code endpoint"""
    
    agent = SoftwareEngineeringAgent()
    result = agent.process_request(
        f"Fix: {request.description}",
        request.file_path
    )
    
    return result

@app.get("/health")
async def health():
    """Health check"""
    return {"status": "healthy"}
</code></pre>
<h2 id="next-steps-24"><a class="header" href="#next-steps-24">Next Steps</a></h2>
<p>You now have a complete implementation! In the next section, weâ€™ll evaluate and iterate on the agent to make it production-ready.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="evaluation--iteration"><a class="header" href="#evaluation--iteration">Evaluation &amp; Iteration</a></h1>
<h2 id="evaluating-your-agent"><a class="header" href="#evaluating-your-agent">Evaluating Your Agent</a></h2>
<p>Now that youâ€™ve built the Autonomous Software Engineering Agent, letâ€™s evaluate its performance and iterate to improve it.</p>
<h2 id="evaluation-framework"><a class="header" href="#evaluation-framework">Evaluation Framework</a></h2>
<h3 id="test-suite-design"><a class="header" href="#test-suite-design">Test Suite Design</a></h3>
<pre><code class="language-python"># tests/evaluation/test_suite.py
from typing import Dict, List
from dataclasses import dataclass

@dataclass
class TestCase:
    name: str
    input_code: str
    expected_issues: List[str]
    expected_fix_pattern: str
    difficulty: str  # easy, medium, hard

class EvaluationSuite:
    """Comprehensive evaluation suite"""
    
    def __init__(self):
        self.test_cases = self.create_test_cases()
        self.results = []
    
    def create_test_cases(self) -&gt; List[TestCase]:
        """Create diverse test cases"""
        
        return [
            TestCase(
                name="Division by zero",
                input_code="def divide(a, b): return a / b",
                expected_issues=["ZeroDivisionError"],
                expected_fix_pattern="if b == 0",
                difficulty="easy"
            ),
            TestCase(
                name="SQL injection",
                input_code='query = f"SELECT * FROM users WHERE id = {user_id}"',
                expected_issues=["SQL injection"],
                expected_fix_pattern="parameterized",
                difficulty="medium"
            ),
            TestCase(
                name="Race condition",
                input_code="""
counter = 0
def increment():
    global counter
    temp = counter
    counter = temp + 1
""",
                expected_issues=["race condition"],
                expected_fix_pattern="lock",
                difficulty="hard"
            )
        ]
    
    def run_evaluation(self, agent) -&gt; Dict:
        """Run full evaluation"""
        
        results = {
            "total": len(self.test_cases),
            "passed": 0,
            "by_difficulty": {"easy": 0, "medium": 0, "hard": 0}
        }
        
        for test_case in self.test_cases:
            result = self.evaluate_test_case(agent, test_case)
            self.results.append(result)
            
            if result["passed"]:
                results["passed"] += 1
                results["by_difficulty"][test_case.difficulty] += 1
        
        results["accuracy"] = results["passed"] / results["total"]
        
        return results
    
    def evaluate_test_case(self, agent, test_case: TestCase) -&gt; Dict:
        """Evaluate single test case"""
        
        # Write test code to file
        test_file = f"tests/fixtures/{test_case.name.replace(' ', '_')}.py"
        with open(test_file, 'w') as f:
            f.write(test_case.input_code)
        
        # Run agent
        result = agent.process_request(
            f"Analyze and fix issues in {test_file}",
            test_file
        )
        
        # Check if issues detected
        issues_found = result["results"][0].get("issues", [])
        detected_expected = any(
            expected in str(issues_found).lower()
            for expected in test_case.expected_issues
        )
        
        # Check if fix applied correctly
        fixed_code = result["results"][1].get("fixed_code", "")
        fix_correct = test_case.expected_fix_pattern.lower() in fixed_code.lower()
        
        return {
            "test_case": test_case.name,
            "passed": detected_expected and fix_correct,
            "issues_detected": detected_expected,
            "fix_correct": fix_correct,
            "difficulty": test_case.difficulty
        }
</code></pre>
<h3 id="performance-benchmarks"><a class="header" href="#performance-benchmarks">Performance Benchmarks</a></h3>
<pre><code class="language-python"># tests/evaluation/benchmarks.py
import time
from typing import Dict

class PerformanceBenchmark:
    """Benchmark agent performance"""
    
    def __init__(self):
        self.metrics = {}
    
    def benchmark_analysis_speed(self, agent, file_sizes: List[int]) -&gt; Dict:
        """Benchmark analysis speed"""
        
        results = {}
        
        for size in file_sizes:
            # Generate code of specific size
            code = self.generate_code(size)
            test_file = f"tests/fixtures/size_{size}.py"
            
            with open(test_file, 'w') as f:
                f.write(code)
            
            # Time analysis
            start = time.time()
            agent.process_request(f"Analyze {test_file}", test_file)
            duration = time.time() - start
            
            results[size] = {
                "duration": duration,
                "lines_per_second": size / duration
            }
        
        return results
    
    def benchmark_fix_quality(self, agent, test_cases: List[TestCase]) -&gt; Dict:
        """Benchmark fix quality"""
        
        metrics = {
            "fixes_attempted": 0,
            "fixes_successful": 0,
            "fixes_optimal": 0,
            "avg_fix_time": []
        }
        
        for test_case in test_cases:
            start = time.time()
            
            # Generate fix
            result = agent.process_request(
                f"Fix issues in {test_case.name}",
                test_case.name
            )
            
            duration = time.time() - start
            metrics["avg_fix_time"].append(duration)
            metrics["fixes_attempted"] += 1
            
            if result["results"][-1]["success"]:
                metrics["fixes_successful"] += 1
                
                # Check if optimal
                if self.is_optimal_fix(result["results"][-1]["fixed_code"]):
                    metrics["fixes_optimal"] += 1
        
        return metrics
    
    def generate_code(self, lines: int) -&gt; str:
        """Generate code of specific size"""
        return "\n".join([f"# Line {i}" for i in range(lines)])
    
    def is_optimal_fix(self, code: str) -&gt; bool:
        """Check if fix is optimal"""
        # Simplified check
        return "try" in code or "if" in code
</code></pre>
<h2 id="real-world-testing"><a class="header" href="#real-world-testing">Real-World Testing</a></h2>
<h3 id="beta-testing-strategy"><a class="header" href="#beta-testing-strategy">Beta Testing Strategy</a></h3>
<pre><code class="language-python">class BetaTester:
    """Coordinate beta testing"""
    
    def __init__(self):
        self.testers = []
        self.feedback = []
    
    def run_beta_test(self, agent, duration_days: int = 7) -&gt; Dict:
        """Run beta test program"""
        
        print(f"Starting {duration_days}-day beta test...")
        
        # Collect usage data
        usage_data = self.collect_usage_data(agent, duration_days)
        
        # Collect feedback
        feedback = self.collect_feedback()
        
        # Analyze results
        analysis = self.analyze_beta_results(usage_data, feedback)
        
        return analysis
    
    def collect_usage_data(self, agent, days: int) -&gt; Dict:
        """Collect usage metrics"""
        
        return {
            "total_requests": 0,
            "successful_requests": 0,
            "avg_response_time": 0,
            "most_common_tasks": [],
            "error_rate": 0
        }
    
    def collect_feedback(self) -&gt; List[Dict]:
        """Collect user feedback"""
        
        return [
            {
                "user": "tester1",
                "rating": 4,
                "comments": "Works well for simple bugs",
                "issues": ["Slow on large files"]
            }
        ]
    
    def analyze_beta_results(self, usage: Dict, feedback: List[Dict]) -&gt; Dict:
        """Analyze beta test results"""
        
        avg_rating = sum(f["rating"] for f in feedback) / len(feedback)
        
        return {
            "usage_stats": usage,
            "avg_rating": avg_rating,
            "key_issues": self.extract_key_issues(feedback),
            "recommendations": self.generate_recommendations(usage, feedback)
        }
    
    def extract_key_issues(self, feedback: List[Dict]) -&gt; List[str]:
        """Extract common issues"""
        
        all_issues = []
        for f in feedback:
            all_issues.extend(f.get("issues", []))
        
        # Count frequency
        from collections import Counter
        return [issue for issue, count in Counter(all_issues).most_common(5)]
    
    def generate_recommendations(self, usage: Dict, feedback: List[Dict]) -&gt; List[str]:
        """Generate improvement recommendations"""
        
        recommendations = []
        
        if usage["error_rate"] &gt; 0.1:
            recommendations.append("Improve error handling")
        
        if usage["avg_response_time"] &gt; 10:
            recommendations.append("Optimize performance")
        
        return recommendations
</code></pre>
<h2 id="iteration-process"><a class="header" href="#iteration-process">Iteration Process</a></h2>
<h3 id="continuous-improvement-loop"><a class="header" href="#continuous-improvement-loop">Continuous Improvement Loop</a></h3>
<pre><code class="language-python">class ImprovementLoop:
    """Continuous improvement system"""
    
    def __init__(self, agent):
        self.agent = agent
        self.version = 1
        self.performance_history = []
    
    def iterate(self, evaluation_results: Dict) -&gt; Dict:
        """Improve based on evaluation"""
        
        # Identify weaknesses
        weaknesses = self.identify_weaknesses(evaluation_results)
        
        # Generate improvements
        improvements = self.generate_improvements(weaknesses)
        
        # Apply improvements
        self.apply_improvements(improvements)
        
        # Re-evaluate
        new_results = self.evaluate()
        
        # Track progress
        self.performance_history.append({
            "version": self.version,
            "results": new_results
        })
        
        self.version += 1
        
        return {
            "improvements_made": len(improvements),
            "performance_change": self.calculate_improvement(evaluation_results, new_results)
        }
    
    def identify_weaknesses(self, results: Dict) -&gt; List[str]:
        """Identify areas needing improvement"""
        
        weaknesses = []
        
        if results["accuracy"] &lt; 0.8:
            weaknesses.append("low_accuracy")
        
        if results.get("avg_response_time", 0) &gt; 10:
            weaknesses.append("slow_performance")
        
        if results.get("error_rate", 0) &gt; 0.05:
            weaknesses.append("high_error_rate")
        
        return weaknesses
    
    def generate_improvements(self, weaknesses: List[str]) -&gt; List[Dict]:
        """Generate improvement strategies"""
        
        improvements = []
        
        for weakness in weaknesses:
            if weakness == "low_accuracy":
                improvements.append({
                    "area": "prompts",
                    "action": "Refine analysis prompts with more examples"
                })
            
            elif weakness == "slow_performance":
                improvements.append({
                    "area": "caching",
                    "action": "Add caching for repeated analyses"
                })
            
            elif weakness == "high_error_rate":
                improvements.append({
                    "area": "error_handling",
                    "action": "Add more robust error handling"
                })
        
        return improvements
    
    def apply_improvements(self, improvements: List[Dict]):
        """Apply improvements to agent"""
        
        for improvement in improvements:
            print(f"Applying: {improvement['action']}")
            # Apply improvement
            # In practice, would modify agent configuration or code
    
    def evaluate(self) -&gt; Dict:
        """Run evaluation"""
        suite = EvaluationSuite()
        return suite.run_evaluation(self.agent)
    
    def calculate_improvement(self, old: Dict, new: Dict) -&gt; float:
        """Calculate improvement percentage"""
        
        old_acc = old.get("accuracy", 0)
        new_acc = new.get("accuracy", 0)
        
        return ((new_acc - old_acc) / old_acc * 100) if old_acc &gt; 0 else 0
</code></pre>
<h2 id="production-deployment"><a class="header" href="#production-deployment">Production Deployment</a></h2>
<h3 id="deployment-checklist"><a class="header" href="#deployment-checklist">Deployment Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox"> All tests passing</li>
<li><input disabled="" type="checkbox"> Performance benchmarks met</li>
<li><input disabled="" type="checkbox"> Security audit completed</li>
<li><input disabled="" type="checkbox"> Documentation updated</li>
<li><input disabled="" type="checkbox"> Monitoring configured</li>
<li><input disabled="" type="checkbox"> Rollback plan ready</li>
<li><input disabled="" type="checkbox"> User training completed</li>
<li><input disabled="" type="checkbox"> Feedback system active</li>
</ul>
<h3 id="monitoring-setup"><a class="header" href="#monitoring-setup">Monitoring Setup</a></h3>
<pre><code class="language-python"># src/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# Define metrics
requests_total = Counter('agent_requests_total', 'Total requests', ['task_type'])
request_duration = Histogram('agent_request_duration_seconds', 'Request duration')
active_tasks = Gauge('agent_active_tasks', 'Active tasks')
errors_total = Counter('agent_errors_total', 'Total errors', ['error_type'])

class MonitoredAgent:
    """Agent with monitoring"""
    
    def __init__(self, agent):
        self.agent = agent
    
    def process_request(self, request: str, target: str) -&gt; Dict:
        """Process with monitoring"""
        
        active_tasks.inc()
        start = time.time()
        
        try:
            result = self.agent.process_request(request, target)
            
            # Record metrics
            requests_total.labels(task_type=result.get("task_type", "unknown")).inc()
            request_duration.observe(time.time() - start)
            
            return result
            
        except Exception as e:
            errors_total.labels(error_type=type(e).__name__).inc()
            raise
        
        finally:
            active_tasks.dec()
</code></pre>
<h3 id="logging-strategy"><a class="header" href="#logging-strategy">Logging Strategy</a></h3>
<pre><code class="language-python"># src/monitoring/logging_config.py
import logging
import json

class StructuredLogger:
    """Structured logging for agent"""
    
    def __init__(self):
        self.logger = logging.getLogger("se_agent")
        self.logger.setLevel(logging.INFO)
        
        handler = logging.FileHandler("agent.log")
        handler.setFormatter(logging.Formatter('%(message)s'))
        self.logger.addHandler(handler)
    
    def log_request(self, request: str, target: str):
        """Log incoming request"""
        self.logger.info(json.dumps({
            "event": "request",
            "request": request,
            "target": target,
            "timestamp": time.time()
        }))
    
    def log_result(self, result: Dict):
        """Log result"""
        self.logger.info(json.dumps({
            "event": "result",
            "success": result.get("success"),
            "timestamp": time.time()
        }))
    
    def log_error(self, error: Exception):
        """Log error"""
        self.logger.error(json.dumps({
            "event": "error",
            "error_type": type(error).__name__,
            "error_message": str(error),
            "timestamp": time.time()
        }))
</code></pre>
<h2 id="user-feedback-collection"><a class="header" href="#user-feedback-collection">User Feedback Collection</a></h2>
<h3 id="feedback-system"><a class="header" href="#feedback-system">Feedback System</a></h3>
<pre><code class="language-python"># src/feedback/collector.py
from typing import Dict, Optional
import sqlite3

class FeedbackCollector:
    """Collect and analyze user feedback"""
    
    def __init__(self, db_path: str = "data/feedback.db"):
        self.db_path = db_path
        self.init_db()
    
    def init_db(self):
        """Initialize feedback database"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS feedback (
                id INTEGER PRIMARY KEY,
                task_id TEXT,
                rating INTEGER,
                comments TEXT,
                accepted BOOLEAN,
                timestamp REAL
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def collect(self, task_id: str, rating: int, comments: str, accepted: bool):
        """Store feedback"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO feedback (task_id, rating, comments, accepted, timestamp)
            VALUES (?, ?, ?, ?, ?)
        ''', (task_id, rating, comments, accepted, time.time()))
        
        conn.commit()
        conn.close()
    
    def analyze_feedback(self) -&gt; Dict:
        """Analyze collected feedback"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get statistics
        cursor.execute('SELECT AVG(rating), COUNT(*) FROM feedback')
        avg_rating, total = cursor.fetchone()
        
        cursor.execute('SELECT COUNT(*) FROM feedback WHERE accepted = 1')
        accepted = cursor.fetchone()[0]
        
        conn.close()
        
        return {
            "avg_rating": avg_rating,
            "total_feedback": total,
            "acceptance_rate": accepted / total if total &gt; 0 else 0
        }
    
    def get_improvement_suggestions(self) -&gt; List[str]:
        """Extract improvement suggestions from feedback"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get low-rated feedback
        cursor.execute('SELECT comments FROM feedback WHERE rating &lt; 3')
        low_rated = cursor.fetchall()
        
        conn.close()
        
        # Extract common themes
        suggestions = []
        for (comment,) in low_rated:
            if comment:
                suggestions.append(comment)
        
        return suggestions
</code></pre>
<h2 id="ab-testing-1"><a class="header" href="#ab-testing-1">A/B Testing</a></h2>
<h3 id="comparing-agent-versions"><a class="header" href="#comparing-agent-versions">Comparing Agent Versions</a></h3>
<pre><code class="language-python">class ABTester:
    """A/B test different agent versions"""
    
    def __init__(self, agent_a, agent_b):
        self.agent_a = agent_a
        self.agent_b = agent_b
        self.results_a = []
        self.results_b = []
    
    def run_ab_test(self, test_cases: List[TestCase]) -&gt; Dict:
        """Run A/B test"""
        
        import random
        
        for test_case in test_cases:
            # Randomly assign to A or B
            if random.random() &lt; 0.5:
                result = self.test_agent(self.agent_a, test_case)
                self.results_a.append(result)
            else:
                result = self.test_agent(self.agent_b, test_case)
                self.results_b.append(result)
        
        # Compare results
        return self.compare_results()
    
    def test_agent(self, agent, test_case: TestCase) -&gt; Dict:
        """Test single agent"""
        
        start = time.time()
        result = agent.process_request(test_case.name, test_case.name)
        duration = time.time() - start
        
        return {
            "success": result.get("success", False),
            "duration": duration
        }
    
    def compare_results(self) -&gt; Dict:
        """Compare A vs B"""
        
        a_success = sum(1 for r in self.results_a if r["success"]) / len(self.results_a)
        b_success = sum(1 for r in self.results_b if r["success"]) / len(self.results_b)
        
        a_speed = sum(r["duration"] for r in self.results_a) / len(self.results_a)
        b_speed = sum(r["duration"] for r in self.results_b) / len(self.results_b)
        
        return {
            "agent_a": {"success_rate": a_success, "avg_duration": a_speed},
            "agent_b": {"success_rate": b_success, "avg_duration": b_speed},
            "winner": "A" if a_success &gt; b_success else "B"
        }
</code></pre>
<h2 id="iteration-examples"><a class="header" href="#iteration-examples">Iteration Examples</a></h2>
<h3 id="iteration-1-improve-accuracy"><a class="header" href="#iteration-1-improve-accuracy">Iteration 1: Improve Accuracy</a></h3>
<p><strong>Problem</strong>: Agent missing 30% of bugs</p>
<p><strong>Analysis</strong>:</p>
<pre><code class="language-python"># Analyze false negatives
false_negatives = [
    "Off-by-one errors",
    "Null pointer issues",
    "Type mismatches"
]
</code></pre>
<p><strong>Solution</strong>:</p>
<pre><code class="language-python"># Enhanced analysis prompt
enhanced_prompt = """Analyze code for:
1. Logic errors (off-by-one, boundary conditions)
2. Null/None handling
3. Type safety
4. Resource leaks
5. Concurrency issues

Be thorough and check edge cases."""

# Update analyzer
analyzer.system_prompt = enhanced_prompt
</code></pre>
<p><strong>Result</strong>: Accuracy improved from 70% â†’ 85%</p>
<h3 id="iteration-2-optimize-performance"><a class="header" href="#iteration-2-optimize-performance">Iteration 2: Optimize Performance</a></h3>
<p><strong>Problem</strong>: Analysis takes 15s per file (target: &lt;5s)</p>
<p><strong>Analysis</strong>:</p>
<pre><code class="language-python"># Profile performance
import cProfile

profiler = cProfile.Profile()
profiler.enable()
agent.process_request("Analyze file.py", "file.py")
profiler.disable()
profiler.print_stats(sort='cumtime')
</code></pre>
<p><strong>Solution</strong>:</p>
<pre><code class="language-python"># Add caching
class CachedAnalyzer:
    def __init__(self):
        self.cache = {}
    
    def analyze(self, file_path: str) -&gt; Dict:
        # Check cache
        file_hash = self.hash_file(file_path)
        
        if file_hash in self.cache:
            return self.cache[file_hash]
        
        # Analyze
        result = self.do_analysis(file_path)
        
        # Cache result
        self.cache[file_hash] = result
        
        return result
</code></pre>
<p><strong>Result</strong>: Analysis time reduced to 3s per file</p>
<h3 id="iteration-3-reduce-false-positives"><a class="header" href="#iteration-3-reduce-false-positives">Iteration 3: Reduce False Positives</a></h3>
<p><strong>Problem</strong>: 40% of reported issues are false positives</p>
<p><strong>Analysis</strong>:</p>
<pre><code class="language-python"># Analyze false positives
fp_analysis = {
    "style_issues_as_bugs": 15,
    "context_misunderstanding": 12,
    "overly_strict_checks": 8
}
</code></pre>
<p><strong>Solution</strong>:</p>
<pre><code class="language-python"># Add confidence scoring
class ConfidenceScorer:
    def score_issue(self, issue: Dict) -&gt; float:
        """Score issue confidence"""
        
        score = 0.5  # Base
        
        # Increase for multiple sources
        if issue["source"] == "static" and issue.get("llm_confirmed"):
            score += 0.3
        
        # Increase for severity
        if issue["severity"] == "critical":
            score += 0.2
        
        return min(score, 1.0)

# Filter low-confidence issues
filtered_issues = [i for i in issues if scorer.score_issue(i) &gt; 0.6]
</code></pre>
<p><strong>Result</strong>: False positive rate reduced from 40% â†’ 15%</p>
<h2 id="production-metrics"><a class="header" href="#production-metrics">Production Metrics</a></h2>
<h3 id="key-metrics-to-track"><a class="header" href="#key-metrics-to-track">Key Metrics to Track</a></h3>
<pre><code class="language-python">class ProductionMetrics:
    """Track production metrics"""
    
    def __init__(self):
        self.metrics = {
            "requests_per_day": 0,
            "success_rate": 0,
            "avg_response_time": 0,
            "user_satisfaction": 0,
            "bugs_fixed": 0,
            "tests_generated": 0,
            "code_quality_improvement": 0
        }
    
    def daily_report(self) -&gt; Dict:
        """Generate daily metrics report"""
        
        return {
            "date": time.strftime("%Y-%m-%d"),
            "metrics": self.metrics,
            "alerts": self.check_alerts()
        }
    
    def check_alerts(self) -&gt; List[str]:
        """Check for metric alerts"""
        
        alerts = []
        
        if self.metrics["success_rate"] &lt; 0.9:
            alerts.append("Success rate below threshold")
        
        if self.metrics["avg_response_time"] &gt; 10:
            alerts.append("Response time above threshold")
        
        return alerts
</code></pre>
<h2 id="final-evaluation"><a class="header" href="#final-evaluation">Final Evaluation</a></h2>
<h3 id="comprehensive-assessment"><a class="header" href="#comprehensive-assessment">Comprehensive Assessment</a></h3>
<pre><code class="language-python">def final_evaluation(agent) -&gt; Dict:
    """Comprehensive final evaluation"""
    
    # Run test suite
    suite = EvaluationSuite()
    test_results = suite.run_evaluation(agent)
    
    # Run benchmarks
    benchmark = PerformanceBenchmark()
    perf_results = benchmark.benchmark_analysis_speed(agent, [100, 500, 1000])
    
    # Analyze feedback
    feedback = FeedbackCollector()
    feedback_analysis = feedback.analyze_feedback()
    
    # Generate report
    report = {
        "test_results": test_results,
        "performance": perf_results,
        "user_feedback": feedback_analysis,
        "overall_score": calculate_overall_score(test_results, perf_results, feedback_analysis)
    }
    
    return report

def calculate_overall_score(tests: Dict, perf: Dict, feedback: Dict) -&gt; float:
    """Calculate overall score"""
    
    # Weighted average
    test_score = tests["accuracy"] * 0.4
    perf_score = (1.0 if perf[100]["duration"] &lt; 5 else 0.5) * 0.3
    feedback_score = feedback["acceptance_rate"] * 0.3
    
    return test_score + perf_score + feedback_score
</code></pre>
<h2 id="congratulations"><a class="header" href="#congratulations">Congratulations!</a></h2>
<p>Youâ€™ve completed the capstone project! Youâ€™ve built a sophisticated Autonomous Software Engineering Agent that:</p>
<p>âœ… Analyzes code for bugs and quality issues
âœ… Generates fixes with explanations
âœ… Writes comprehensive tests
âœ… Operates safely with validation
âœ… Learns from feedback
âœ… Scales to production workloads</p>
<h3 id="what-youve-learned"><a class="header" href="#what-youve-learned">What Youâ€™ve Learned</a></h3>
<p>Throughout this course, youâ€™ve mastered:</p>
<ul>
<li><strong>Foundations</strong>: Agent architecture and LLM fundamentals</li>
<li><strong>Building</strong>: ReAct patterns and tool integration</li>
<li><strong>Advanced Patterns</strong>: Planning, memory, multi-agent systems</li>
<li><strong>Tools</strong>: Code execution, data access, web interaction</li>
<li><strong>Production</strong>: Reliability, testing, monitoring</li>
<li><strong>Specialization</strong>: Coding, research, automation agents</li>
<li><strong>Advanced Topics</strong>: Learning, multimodal, frameworks</li>
<li><strong>Enterprise</strong>: Architecture, security, cost optimization</li>
<li><strong>Research</strong>: Frontier capabilities, emerging paradigms</li>
<li><strong>Capstone</strong>: Complete production-ready agent</li>
</ul>
<h3 id="next-steps-25"><a class="header" href="#next-steps-25">Next Steps</a></h3>
<ol>
<li><strong>Deploy your agent</strong>: Put it into production</li>
<li><strong>Contribute</strong>: Share your implementation</li>
<li><strong>Research</strong>: Explore open problems</li>
<li><strong>Build more</strong>: Create specialized agents</li>
<li><strong>Teach</strong>: Share your knowledge</li>
</ol>
<p>Thank you for completing the AI Agents: Zero to Hero course!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="tools--libraries"><a class="header" href="#tools--libraries">Tools &amp; Libraries</a></h1>
<h2 id="core-libraries"><a class="header" href="#core-libraries">Core Libraries</a></h2>
<h3 id="llm-apis"><a class="header" href="#llm-apis">LLM APIs</a></h3>
<p><strong>OpenAI</strong></p>
<pre><code class="language-bash">pip install openai
</code></pre>
<pre><code class="language-python">from openai import OpenAI
client = OpenAI(api_key="your-key")
</code></pre>
<ul>
<li>Models: GPT-4, GPT-3.5-turbo</li>
<li>Function calling support</li>
<li>Streaming responses</li>
<li><a href="https://platform.openai.com/docs">Documentation</a></li>
</ul>
<p><strong>Anthropic Claude</strong></p>
<pre><code class="language-bash">pip install anthropic
</code></pre>
<pre><code class="language-python">import anthropic
client = anthropic.Anthropic(api_key="your-key")
</code></pre>
<ul>
<li>Models: Claude 3 (Opus, Sonnet, Haiku)</li>
<li>Long context windows (200K tokens)</li>
<li><a href="https://docs.anthropic.com">Documentation</a></li>
</ul>
<p><strong>AWS Bedrock</strong></p>
<pre><code class="language-bash">pip install boto3
</code></pre>
<pre><code class="language-python">import boto3
bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')
</code></pre>
<ul>
<li>Multiple model providers</li>
<li>Enterprise features</li>
<li><a href="https://docs.aws.amazon.com/bedrock">Documentation</a></li>
</ul>
<h3 id="agent-frameworks"><a class="header" href="#agent-frameworks">Agent Frameworks</a></h3>
<p><strong>LangChain</strong></p>
<pre><code class="language-bash">pip install langchain langchain-openai
</code></pre>
<ul>
<li>Chains, agents, tools</li>
<li>Memory management</li>
<li><a href="https://python.langchain.com">Documentation</a></li>
</ul>
<p><strong>LangGraph</strong></p>
<pre><code class="language-bash">pip install langgraph
</code></pre>
<ul>
<li>Graph-based workflows</li>
<li>State management</li>
<li><a href="https://langchain-ai.github.io/langgraph">Documentation</a></li>
</ul>
<p><strong>AutoGPT</strong></p>
<pre><code class="language-bash">git clone https://github.com/Significant-Gravitas/AutoGPT
</code></pre>
<ul>
<li>Autonomous task execution</li>
<li>Plugin system</li>
</ul>
<p><strong>CrewAI</strong></p>
<pre><code class="language-bash">pip install crewai
</code></pre>
<ul>
<li>Multi-agent orchestration</li>
<li>Role-based agents</li>
</ul>
<h3 id="vector-databases"><a class="header" href="#vector-databases">Vector Databases</a></h3>
<p><strong>ChromaDB</strong></p>
<pre><code class="language-bash">pip install chromadb
</code></pre>
<pre><code class="language-python">import chromadb
client = chromadb.Client()
collection = client.create_collection("docs")
</code></pre>
<ul>
<li>Embedded database</li>
<li>Simple API</li>
</ul>
<p><strong>Pinecone</strong></p>
<pre><code class="language-bash">pip install pinecone-client
</code></pre>
<ul>
<li>Managed service</li>
<li>High performance</li>
<li>Scalable</li>
</ul>
<p><strong>Weaviate</strong></p>
<pre><code class="language-bash">pip install weaviate-client
</code></pre>
<ul>
<li>Open source</li>
<li>Hybrid search</li>
<li>GraphQL API</li>
</ul>
<h3 id="code-analysis"><a class="header" href="#code-analysis">Code Analysis</a></h3>
<p><strong>AST Tools</strong></p>
<pre><code class="language-bash">pip install ast-grep-py
</code></pre>
<ul>
<li>Python: Built-in <code>ast</code> module</li>
<li>Multi-language: tree-sitter</li>
</ul>
<p><strong>Linters</strong></p>
<pre><code class="language-bash">pip install pylint ruff mypy
</code></pre>
<ul>
<li>pylint: Comprehensive checking</li>
<li>ruff: Fast linting</li>
<li>mypy: Type checking</li>
</ul>
<p><strong>Formatters</strong></p>
<pre><code class="language-bash">pip install black isort
</code></pre>
<ul>
<li>black: Code formatting</li>
<li>isort: Import sorting</li>
</ul>
<h3 id="testing"><a class="header" href="#testing">Testing</a></h3>
<p><strong>pytest</strong></p>
<pre><code class="language-bash">pip install pytest pytest-asyncio pytest-cov
</code></pre>
<ul>
<li>Unit testing</li>
<li>Async support</li>
<li>Coverage reports</li>
</ul>
<p><strong>unittest</strong></p>
<ul>
<li>Built-in Python testing</li>
<li>Standard library</li>
</ul>
<h3 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h3>
<p><strong>Prometheus</strong></p>
<pre><code class="language-bash">pip install prometheus-client
</code></pre>
<ul>
<li>Metrics collection</li>
<li>Time series data</li>
</ul>
<p><strong>OpenTelemetry</strong></p>
<pre><code class="language-bash">pip install opentelemetry-api opentelemetry-sdk
</code></pre>
<ul>
<li>Distributed tracing</li>
<li>Metrics and logs</li>
</ul>
<h3 id="utilities"><a class="header" href="#utilities">Utilities</a></h3>
<p><strong>Docker SDK</strong></p>
<pre><code class="language-bash">pip install docker
</code></pre>
<ul>
<li>Container management</li>
<li>Safe code execution</li>
</ul>
<p><strong>GitPython</strong></p>
<pre><code class="language-bash">pip install gitpython
</code></pre>
<ul>
<li>Git operations</li>
<li>Repository management</li>
</ul>
<p><strong>Requests</strong></p>
<pre><code class="language-bash">pip install requests httpx
</code></pre>
<ul>
<li>HTTP requests</li>
<li>API integration</li>
</ul>
<h2 id="development-tools"><a class="header" href="#development-tools">Development Tools</a></h2>
<h3 id="ides--editors"><a class="header" href="#ides--editors">IDEs &amp; Editors</a></h3>
<ul>
<li><strong>VS Code</strong>: Python, Jupyter extensions</li>
<li><strong>PyCharm</strong>: Professional Python IDE</li>
<li><strong>Cursor</strong>: AI-powered editor</li>
<li><strong>Jupyter</strong>: Interactive notebooks</li>
</ul>
<h3 id="debugging"><a class="header" href="#debugging">Debugging</a></h3>
<ul>
<li><strong>pdb</strong>: Python debugger</li>
<li><strong>ipdb</strong>: Enhanced debugger</li>
<li><strong>pytest-pdb</strong>: Test debugging</li>
</ul>
<h3 id="documentation"><a class="header" href="#documentation">Documentation</a></h3>
<ul>
<li><strong>Sphinx</strong>: Python documentation</li>
<li><strong>MkDocs</strong>: Markdown documentation</li>
<li><strong>mdBook</strong>: Rust-based book tool</li>
</ul>
<h2 id="deployment-tools"><a class="header" href="#deployment-tools">Deployment Tools</a></h2>
<h3 id="containerization"><a class="header" href="#containerization">Containerization</a></h3>
<ul>
<li><strong>Docker</strong>: Container platform</li>
<li><strong>Docker Compose</strong>: Multi-container apps</li>
</ul>
<h3 id="orchestration"><a class="header" href="#orchestration">Orchestration</a></h3>
<ul>
<li><strong>Kubernetes</strong>: Container orchestration</li>
<li><strong>AWS ECS</strong>: Managed containers</li>
<li><strong>AWS Lambda</strong>: Serverless functions</li>
</ul>
<h3 id="cicd"><a class="header" href="#cicd">CI/CD</a></h3>
<ul>
<li><strong>GitHub Actions</strong>: Automated workflows</li>
<li><strong>GitLab CI</strong>: Integrated CI/CD</li>
<li><strong>AWS CodePipeline</strong>: AWS-native CI/CD</li>
</ul>
<h2 id="quick-start-template"><a class="header" href="#quick-start-template">Quick Start Template</a></h2>
<pre><code class="language-python"># requirements.txt
openai==1.12.0
langchain==0.1.0
chromadb==0.4.22
fastapi==0.109.0
uvicorn==0.27.0
pytest==8.0.0
</code></pre>
<pre><code class="language-python"># agent.py
from openai import OpenAI

class SimpleAgent:
    def __init__(self):
        self.client = OpenAI()
    
    def run(self, task: str) -&gt; str:
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": task}]
        )
        return response.choices[0].message.content

agent = SimpleAgent()
result = agent.run("Hello!")
print(result)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="resources"><a class="header" href="#resources">Resources</a></h1>
<h2 id="research-papers"><a class="header" href="#research-papers">Research Papers</a></h2>
<h3 id="foundational-papers"><a class="header" href="#foundational-papers">Foundational Papers</a></h3>
<p><strong>ReAct: Synergizing Reasoning and Acting in Language Models</strong></p>
<ul>
<li>Authors: Yao et al. (2022)</li>
<li><a href="https://arxiv.org/abs/2210.03629">Paper</a></li>
<li>Key contribution: Reasoning + Acting pattern</li>
</ul>
<p><strong>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</strong></p>
<ul>
<li>Authors: Wei et al. (2022)</li>
<li><a href="https://arxiv.org/abs/2201.11903">Paper</a></li>
<li>Key contribution: Step-by-step reasoning</li>
</ul>
<p><strong>Toolformer: Language Models Can Teach Themselves to Use Tools</strong></p>
<ul>
<li>Authors: Schick et al. (2023)</li>
<li><a href="https://arxiv.org/abs/2302.04761">Paper</a></li>
<li>Key contribution: Self-taught tool use</li>
</ul>
<p><strong>Generative Agents: Interactive Simulacra of Human Behavior</strong></p>
<ul>
<li>Authors: Park et al. (2023)</li>
<li><a href="https://arxiv.org/abs/2304.03442">Paper</a></li>
<li>Key contribution: Memory and planning</li>
</ul>
<h3 id="recent-advances"><a class="header" href="#recent-advances">Recent Advances</a></h3>
<p><strong>GPT-4 Technical Report</strong></p>
<ul>
<li>OpenAI (2023)</li>
<li><a href="https://arxiv.org/abs/2303.08774">Paper</a></li>
</ul>
<p><strong>Constitutional AI: Harmlessness from AI Feedback</strong></p>
<ul>
<li>Anthropic (2022)</li>
<li><a href="https://arxiv.org/abs/2212.08073">Paper</a></li>
</ul>
<p><strong>Tree of Thoughts: Deliberate Problem Solving with Large Language Models</strong></p>
<ul>
<li>Yao et al. (2023)</li>
<li><a href="https://arxiv.org/abs/2305.10601">Paper</a></li>
</ul>
<h2 id="books"><a class="header" href="#books">Books</a></h2>
<p><strong>Artificial Intelligence: A Modern Approach</strong></p>
<ul>
<li>Authors: Russell &amp; Norvig</li>
<li>Classic AI textbook</li>
<li>Agent architectures</li>
</ul>
<p><strong>Deep Learning</strong></p>
<ul>
<li>Authors: Goodfellow, Bengio, Courville</li>
<li>Neural network foundations</li>
<li><a href="https://www.deeplearningbook.org">Free online</a></li>
</ul>
<p><strong>Reinforcement Learning: An Introduction</strong></p>
<ul>
<li>Authors: Sutton &amp; Barto</li>
<li>RL fundamentals</li>
<li><a href="http://incompleteideas.net/book">Free online</a></li>
</ul>
<h2 id="online-courses"><a class="header" href="#online-courses">Online Courses</a></h2>
<p><strong>DeepLearning.AI</strong></p>
<ul>
<li>LangChain courses</li>
<li>AI agent specializations</li>
<li><a href="https://www.deeplearning.ai">Website</a></li>
</ul>
<p><strong>Fast.ai</strong></p>
<ul>
<li>Practical deep learning</li>
<li>Free courses</li>
<li><a href="https://www.fast.ai">Website</a></li>
</ul>
<p><strong>Stanford CS224N</strong></p>
<ul>
<li>NLP with Deep Learning</li>
<li><a href="https://web.stanford.edu/class/cs224n">Course page</a></li>
</ul>
<h2 id="blogs--tutorials"><a class="header" href="#blogs--tutorials">Blogs &amp; Tutorials</a></h2>
<p><strong>Lilian Wengâ€™s Blog</strong></p>
<ul>
<li><a href="https://lilianweng.github.io">lilianweng.github.io</a></li>
<li>Excellent agent overviews</li>
<li>Research summaries</li>
</ul>
<p><strong>Anthropic Research</strong></p>
<ul>
<li><a href="https://www.anthropic.com/research">anthropic.com/research</a></li>
<li>Constitutional AI</li>
<li>Safety research</li>
</ul>
<p><strong>OpenAI Blog</strong></p>
<ul>
<li><a href="https://openai.com/blog">openai.com/blog</a></li>
<li>Model releases</li>
<li>Research updates</li>
</ul>
<p><strong>Hugging Face Blog</strong></p>
<ul>
<li><a href="https://huggingface.co/blog">huggingface.co/blog</a></li>
<li>Model tutorials</li>
<li>Community projects</li>
</ul>
<h2 id="communities"><a class="header" href="#communities">Communities</a></h2>
<p><strong>Discord Servers</strong></p>
<ul>
<li>LangChain Discord</li>
<li>OpenAI Developer Community</li>
<li>AI Agent Builders</li>
</ul>
<p><strong>Reddit</strong></p>
<ul>
<li>r/MachineLearning</li>
<li>r/LanguageTechnology</li>
<li>r/artificial</li>
</ul>
<p><strong>GitHub</strong></p>
<ul>
<li>Awesome-LLM repositories</li>
<li>Agent implementations</li>
<li>Open source projects</li>
</ul>
<h2 id="conferences"><a class="header" href="#conferences">Conferences</a></h2>
<p><strong>NeurIPS</strong> - Neural Information Processing Systems</p>
<ul>
<li>December annually</li>
<li>Top ML conference</li>
</ul>
<p><strong>ICML</strong> - International Conference on Machine Learning</p>
<ul>
<li>July annually</li>
<li>Core ML research</li>
</ul>
<p><strong>ICLR</strong> - International Conference on Learning Representations</p>
<ul>
<li>May annually</li>
<li>Deep learning focus</li>
</ul>
<p><strong>ACL</strong> - Association for Computational Linguistics</p>
<ul>
<li>July annually</li>
<li>NLP research</li>
</ul>
<h2 id="datasets--benchmarks"><a class="header" href="#datasets--benchmarks">Datasets &amp; Benchmarks</a></h2>
<p><strong>HumanEval</strong></p>
<ul>
<li>Code generation benchmark</li>
<li><a href="https://github.com/openai/human-eval">GitHub</a></li>
</ul>
<p><strong>MMLU</strong> - Massive Multitask Language Understanding</p>
<ul>
<li>Knowledge benchmark</li>
<li>57 subjects</li>
</ul>
<p><strong>BIG-bench</strong></p>
<ul>
<li>Diverse task benchmark</li>
<li><a href="https://github.com/google/BIG-bench">GitHub</a></li>
</ul>
<p><strong>AgentBench</strong></p>
<ul>
<li>Agent capability benchmark</li>
<li>Multi-environment testing</li>
</ul>
<h2 id="tools--platforms"><a class="header" href="#tools--platforms">Tools &amp; Platforms</a></h2>
<p><strong>Weights &amp; Biases</strong></p>
<ul>
<li>Experiment tracking</li>
<li><a href="https://wandb.ai">wandb.ai</a></li>
</ul>
<p><strong>LangSmith</strong></p>
<ul>
<li>LangChain debugging</li>
<li>Trace visualization</li>
</ul>
<p><strong>Helicone</strong></p>
<ul>
<li>LLM observability</li>
<li>Cost tracking</li>
</ul>
<p><strong>PromptLayer</strong></p>
<ul>
<li>Prompt management</li>
<li>Version control</li>
</ul>
<h2 id="code-repositories"><a class="header" href="#code-repositories">Code Repositories</a></h2>
<p><strong>LangChain</strong></p>
<ul>
<li><a href="https://github.com/langchain-ai/langchain">github.com/langchain-ai/langchain</a></li>
</ul>
<p><strong>AutoGPT</strong></p>
<ul>
<li><a href="https://github.com/Significant-Gravitas/AutoGPT">github.com/Significant-Gravitas/AutoGPT</a></li>
</ul>
<p><strong>BabyAGI</strong></p>
<ul>
<li><a href="https://github.com/yoheinakajima/babyagi">github.com/yoheinakajima/babyagi</a></li>
</ul>
<p><strong>AgentGPT</strong></p>
<ul>
<li><a href="https://github.com/reworkd/AgentGPT">github.com/reworkd/AgentGPT</a></li>
</ul>
<h2 id="stay-updated"><a class="header" href="#stay-updated">Stay Updated</a></h2>
<p><strong>Newsletters</strong></p>
<ul>
<li>The Batch (DeepLearning.AI)</li>
<li>Import AI</li>
<li>TLDR AI</li>
</ul>
<p><strong>Twitter/X Accounts</strong></p>
<ul>
<li>@AndrewYNg</li>
<li>@karpathy</li>
<li>@ylecun</li>
<li>@goodfellow_ian</li>
</ul>
<p><strong>YouTube Channels</strong></p>
<ul>
<li>Andrej Karpathy</li>
<li>Two Minute Papers</li>
<li>Yannic Kilcher</li>
</ul>
<h2 id="practice-platforms"><a class="header" href="#practice-platforms">Practice Platforms</a></h2>
<p><strong>Kaggle</strong></p>
<ul>
<li>Competitions</li>
<li>Datasets</li>
<li>Notebooks</li>
</ul>
<p><strong>HuggingFace Spaces</strong></p>
<ul>
<li>Deploy demos</li>
<li>Share models</li>
</ul>
<p><strong>Replicate</strong></p>
<ul>
<li>Run models</li>
<li>API access</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="glossary"><a class="header" href="#glossary">Glossary</a></h1>
<h2 id="a"><a class="header" href="#a">A</a></h2>
<p><strong>Agent</strong> - An autonomous system that perceives its environment and takes actions to achieve goals.</p>
<p><strong>Agentic Framework</strong> - A software framework designed for building AI agents (e.g., LangChain, AutoGPT).</p>
<p><strong>API (Application Programming Interface)</strong> - Interface for software components to communicate.</p>
<p><strong>AST (Abstract Syntax Tree)</strong> - Tree representation of code structure.</p>
<h2 id="b"><a class="header" href="#b">B</a></h2>
<p><strong>Backoff</strong> - Strategy for retrying failed operations with increasing delays.</p>
<p><strong>Benchmark</strong> - Standardized test for measuring performance.</p>
<p><strong>Beam Search</strong> - Search algorithm that explores multiple paths simultaneously.</p>
<h2 id="c"><a class="header" href="#c">C</a></h2>
<p><strong>Chain-of-Thought (CoT)</strong> - Prompting technique that encourages step-by-step reasoning.</p>
<p><strong>Checkpoint</strong> - Saved state of a model or agent for recovery.</p>
<p><strong>Context Window</strong> - Maximum amount of text an LLM can process at once.</p>
<p><strong>Constitutional AI</strong> - Approach to align AI behavior with principles.</p>
<h2 id="d"><a class="header" href="#d">D</a></h2>
<p><strong>Deterministic</strong> - Producing the same output given the same input.</p>
<p><strong>Distributed Tracing</strong> - Tracking requests across multiple services.</p>
<p><strong>Docker</strong> - Platform for containerizing applications.</p>
<h2 id="e"><a class="header" href="#e">E</a></h2>
<p><strong>Embedding</strong> - Vector representation of text or data.</p>
<p><strong>Episodic Memory</strong> - Memory of specific past events or experiences.</p>
<p><strong>Evaluation Metric</strong> - Quantitative measure of performance.</p>
<h2 id="f"><a class="header" href="#f">F</a></h2>
<p><strong>Few-Shot Learning</strong> - Learning from a small number of examples.</p>
<p><strong>Fine-Tuning</strong> - Training a pre-trained model on specific data.</p>
<p><strong>Function Calling</strong> - LLM capability to invoke external functions.</p>
<h2 id="g"><a class="header" href="#g">G</a></h2>
<p><strong>Generalization</strong> - Ability to perform well on unseen data.</p>
<p><strong>Guardrails</strong> - Safety mechanisms to prevent harmful behavior.</p>
<p><strong>GPU (Graphics Processing Unit)</strong> - Hardware for parallel computation.</p>
<h2 id="h"><a class="header" href="#h">H</a></h2>
<p><strong>Hallucination</strong> - When LLMs generate false or nonsensical information.</p>
<p><strong>Human-in-the-Loop (HITL)</strong> - System requiring human approval for decisions.</p>
<p><strong>Hyperparameter</strong> - Configuration parameter for model training.</p>
<h2 id="i"><a class="header" href="#i">I</a></h2>
<p><strong>Inference</strong> - Using a trained model to make predictions.</p>
<p><strong>Interpretability</strong> - Ability to understand model decisions.</p>
<h2 id="k"><a class="header" href="#k">K</a></h2>
<p><strong>Kubernetes (K8s)</strong> - Container orchestration platform.</p>
<h2 id="l"><a class="header" href="#l">L</a></h2>
<p><strong>Latency</strong> - Time delay between request and response.</p>
<p><strong>LLM (Large Language Model)</strong> - Neural network trained on vast text data.</p>
<p><strong>Long-Horizon Planning</strong> - Planning over extended time periods.</p>
<h2 id="m"><a class="header" href="#m">M</a></h2>
<p><strong>Memory System</strong> - Component for storing and retrieving information.</p>
<p><strong>Meta-Learning</strong> - Learning how to learn.</p>
<p><strong>Microservices</strong> - Architecture pattern with independent services.</p>
<p><strong>Multimodal</strong> - Processing multiple types of data (text, images, audio).</p>
<h2 id="n"><a class="header" href="#n">N</a></h2>
<p><strong>Neural Network</strong> - Computing system inspired by biological brains.</p>
<p><strong>NLP (Natural Language Processing)</strong> - Processing and understanding human language.</p>
<h2 id="o"><a class="header" href="#o">O</a></h2>
<p><strong>Observability</strong> - Ability to understand system internal state from outputs.</p>
<p><strong>Orchestration</strong> - Coordinating multiple components or agents.</p>
<h2 id="p"><a class="header" href="#p">P</a></h2>
<p><strong>Perception-Reasoning-Action Loop</strong> - Core agent cycle: observe, think, act.</p>
<p><strong>Prompt Engineering</strong> - Crafting effective prompts for LLMs.</p>
<p><strong>Production</strong> - Live environment serving real users.</p>
<h2 id="r"><a class="header" href="#r">R</a></h2>
<p><strong>RAG (Retrieval-Augmented Generation)</strong> - Combining retrieval with generation.</p>
<p><strong>ReAct</strong> - Pattern combining reasoning and acting.</p>
<p><strong>Reinforcement Learning (RL)</strong> - Learning through rewards and penalties.</p>
<p><strong>RLHF (Reinforcement Learning from Human Feedback)</strong> - Training with human preferences.</p>
<h2 id="s"><a class="header" href="#s">S</a></h2>
<p><strong>Sandbox</strong> - Isolated environment for safe code execution.</p>
<p><strong>Semantic Memory</strong> - Memory of facts and knowledge.</p>
<p><strong>Semantic Search</strong> - Search based on meaning, not keywords.</p>
<p><strong>Self-Improvement</strong> - Agentâ€™s ability to improve its own capabilities.</p>
<p><strong>Streaming</strong> - Sending responses incrementally as generated.</p>
<h2 id="t"><a class="header" href="#t">T</a></h2>
<p><strong>Temperature</strong> - Parameter controlling randomness in LLM outputs (0=deterministic, 1=creative).</p>
<p><strong>Token</strong> - Unit of text processed by LLMs (roughly 0.75 words).</p>
<p><strong>Tool</strong> - External function or API an agent can use.</p>
<p><strong>Tree of Thoughts</strong> - Exploring multiple reasoning paths.</p>
<h2 id="v"><a class="header" href="#v">V</a></h2>
<p><strong>Vector Database</strong> - Database optimized for similarity search on embeddings.</p>
<p><strong>Validation</strong> - Checking if outputs meet requirements.</p>
<h2 id="w"><a class="header" href="#w">W</a></h2>
<p><strong>Working Memory</strong> - Short-term memory for current task.</p>
<h2 id="z"><a class="header" href="#z">Z</a></h2>
<p><strong>Zero-Shot</strong> - Performing tasks without specific training examples.</p>
<hr>
<h2 id="common-acronyms"><a class="header" href="#common-acronyms">Common Acronyms</a></h2>
<ul>
<li><strong>AI</strong> - Artificial Intelligence</li>
<li><strong>API</strong> - Application Programming Interface</li>
<li><strong>AST</strong> - Abstract Syntax Tree</li>
<li><strong>CI/CD</strong> - Continuous Integration/Continuous Deployment</li>
<li><strong>CoT</strong> - Chain-of-Thought</li>
<li><strong>GPU</strong> - Graphics Processing Unit</li>
<li><strong>HITL</strong> - Human-in-the-Loop</li>
<li><strong>LLM</strong> - Large Language Model</li>
<li><strong>ML</strong> - Machine Learning</li>
<li><strong>NLP</strong> - Natural Language Processing</li>
<li><strong>RAG</strong> - Retrieval-Augmented Generation</li>
<li><strong>RL</strong> - Reinforcement Learning</li>
<li><strong>RLHF</strong> - Reinforcement Learning from Human Feedback</li>
<li><strong>SLA</strong> - Service Level Agreement</li>
<li><strong>ToT</strong> - Tree of Thoughts</li>
<li><strong>UI/UX</strong> - User Interface/User Experience</li>
</ul>
<h2 id="model-parameters"><a class="header" href="#model-parameters">Model Parameters</a></h2>
<p><strong>Temperature</strong> - Controls randomness (0.0-2.0)</p>
<ul>
<li>0.0-0.3: Focused, deterministic</li>
<li>0.4-0.7: Balanced</li>
<li>0.8-1.0: Creative</li>
<li>1.0+: Very random</li>
</ul>
<p><strong>Top-p (Nucleus Sampling)</strong> - Alternative to temperature (0.0-1.0)</p>
<ul>
<li>0.1: Very focused</li>
<li>0.5: Balanced</li>
<li>0.9: Diverse</li>
</ul>
<p><strong>Max Tokens</strong> - Maximum length of response</p>
<p><strong>Frequency Penalty</strong> - Reduces repetition (-2.0 to 2.0)</p>
<p><strong>Presence Penalty</strong> - Encourages new topics (-2.0 to 2.0)</p>
<h2 id="http-status-codes"><a class="header" href="#http-status-codes">HTTP Status Codes</a></h2>
<ul>
<li><strong>200</strong> - Success</li>
<li><strong>400</strong> - Bad Request</li>
<li><strong>401</strong> - Unauthorized</li>
<li><strong>429</strong> - Rate Limited</li>
<li><strong>500</strong> - Server Error</li>
<li><strong>503</strong> - Service Unavailable</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="contributing"><a class="header" href="#contributing">Contributing</a></h1>
<p>Thank you for your interest in improving this course! Contributions are welcome and appreciated.</p>
<h2 id="how-to-contribute"><a class="header" href="#how-to-contribute">How to Contribute</a></h2>
<h3 id="reporting-issues"><a class="header" href="#reporting-issues">Reporting Issues</a></h3>
<p>Found an error or have a suggestion?</p>
<ol>
<li>Check <a href="https://github.com/ekyawthan/ai-agents-course/issues">existing issues</a></li>
<li>Create a new issue with:
<ul>
<li>Clear description</li>
<li>Module and section reference</li>
<li>Expected vs actual behavior</li>
<li>Suggested fix (if applicable)</li>
</ul>
</li>
</ol>
<h3 id="suggesting-improvements"><a class="header" href="#suggesting-improvements">Suggesting Improvements</a></h3>
<p>Have ideas for new content or improvements?</p>
<ol>
<li>Open a <a href="https://github.com/ekyawthan/ai-agents-course/discussions">discussion</a></li>
<li>Describe your suggestion</li>
<li>Explain the value it would add</li>
</ol>
<h3 id="contributing-content"><a class="header" href="#contributing-content">Contributing Content</a></h3>
<p>Want to contribute code, examples, or content?</p>
<p><strong>Process</strong>:</p>
<ol>
<li>Fork the repository</li>
<li>Create a feature branch: <code>git checkout -b feature/your-feature</code></li>
<li>Make your changes</li>
<li>Test locally: <code>mdbook serve</code></li>
<li>Commit: <code>git commit -m "Add: your feature"</code></li>
<li>Push: <code>git push origin feature/your-feature</code></li>
<li>Open a Pull Request</li>
</ol>
<p><strong>Guidelines</strong>:</p>
<ul>
<li>Follow existing code style</li>
<li>Include working code examples</li>
<li>Add comments and explanations</li>
<li>Test all code before submitting</li>
<li>Keep examples concise but complete</li>
</ul>
<h2 id="content-guidelines"><a class="header" href="#content-guidelines">Content Guidelines</a></h2>
<h3 id="code-examples"><a class="header" href="#code-examples">Code Examples</a></h3>
<ul>
<li>Use Python 3.9+ syntax</li>
<li>Include type hints</li>
<li>Add docstrings</li>
<li>Handle errors gracefully</li>
<li>Keep examples under 100 lines when possible</li>
</ul>
<h3 id="writing-style"><a class="header" href="#writing-style">Writing Style</a></h3>
<ul>
<li>Clear and concise</li>
<li>Explain â€œwhyâ€ not just â€œhowâ€</li>
<li>Use active voice</li>
<li>Include practical examples</li>
<li>Link to related sections</li>
</ul>
<h3 id="structure"><a class="header" href="#structure">Structure</a></h3>
<ul>
<li>Start with learning objectives</li>
<li>Provide context before code</li>
<li>Explain code after showing it</li>
<li>End with key takeaways</li>
<li>Link to next steps</li>
</ul>
<h2 id="types-of-contributions"><a class="header" href="#types-of-contributions">Types of Contributions</a></h2>
<h3 id="high-priority"><a class="header" href="#high-priority">High Priority</a></h3>
<ul>
<li>Fixing errors or bugs in code</li>
<li>Improving unclear explanations</li>
<li>Adding missing error handling</li>
<li>Updating deprecated APIs</li>
</ul>
<h3 id="medium-priority"><a class="header" href="#medium-priority">Medium Priority</a></h3>
<ul>
<li>Adding practice exercises</li>
<li>Creating additional examples</li>
<li>Improving diagrams</li>
<li>Expanding explanations</li>
</ul>
<h3 id="nice-to-have"><a class="header" href="#nice-to-have">Nice to Have</a></h3>
<ul>
<li>Translations</li>
<li>Video tutorials</li>
<li>Interactive demos</li>
<li>Community showcases</li>
</ul>
<h2 id="code-of-conduct"><a class="header" href="#code-of-conduct">Code of Conduct</a></h2>
<ul>
<li>Be respectful and constructive</li>
<li>Welcome newcomers</li>
<li>Focus on improving the content</li>
<li>Give credit where due</li>
<li>Assume good intentions</li>
</ul>
<h2 id="recognition"><a class="header" href="#recognition">Recognition</a></h2>
<p>Contributors will be acknowledged in:</p>
<ul>
<li>GitHub contributors list</li>
<li>Course acknowledgments section</li>
<li>Release notes</li>
</ul>
<h2 id="questions"><a class="header" href="#questions">Questions?</a></h2>
<p>Open a <a href="https://github.com/ekyawthan/ai-agents-course/discussions">discussion</a> or reach out via GitHub issues.</p>
<p>Thank you for helping make this course better! ğŸ™</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace-2a3cd908.js"></script>
        <script src="mode-rust-2c9d5c9a.js"></script>
        <script src="editor-16ca416c.js"></script>
        <script src="theme-dawn-4493f9c8.js"></script>
        <script src="theme-tomorrow_night-9dbe62a9.js"></script>

        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->
        <script src="theme/mermaid-init-e567e1e5.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
